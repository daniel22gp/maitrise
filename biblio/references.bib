

@article{gatt18,
	Author = {Gatt, Albert and Krahmer, Emiel},
	Date-Added = {2018-03-19 15:51:05 +0000},
	Date-Modified = {2018-03-19 15:51:05 +0000},
	Journal = {Journal of Artificial Intelligence Research},
	Keywords = {NLG},
	Pages = {65--170},
	Title = {Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation},
	Volume = {61},
	Year = {2018},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QIy4uLy4uLy4uLy4uL2JpYmxpby9maWxlcy9nYXR0MTgucGRm0hcLGBlXTlMuZGF0YU8RAX4AAAAAAX4AAgAAAkhEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANKmdm1IKwAAADhwDgpnYXR0MTgucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC85nU1tWNSAAAAAAAAAAAAAQAAwAACSAAAAAAAAAAAAAAAAAAAAAFZmlsZXMAABAACAAA0qa8vQAAABEACAAA1tXFiAAAAAEAGAA4cA4AOG2sADhtnAAYVSEAGFS2AAAAfAACADtIRDpVc2VyczoAZnJhbmNvaXM6AERyb3Bib3g6AGpvYjoAYmlibGlvOgBmaWxlczoAZ2F0dDE4LnBkZgAADgAWAAoAZwBhAHQAdAAxADgALgBwAGQAZgAPAAYAAgBIAEQAEgAyVXNlcnMvZnJhbmNvaXMvRHJvcGJveC9qb2IvYmlibGlvL2ZpbGVzL2dhdHQxOC5wZGYAEwABLwAAFQACAA///wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgC0ALkAwQJDAkUCSgJVAl4CbAJwAncCgAKFApIClQKnAqoCrwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKx}}

@article{MillerWordNetLexicalDatabase1995,
	Author = {Miller, George A.},
	Doi = {10.1145/219717.219748},
	Issn = {0001-0782},
	Journal = {Commun. ACM},
	Month = nov,
	Number = {11},
	Pages = {39--41},
	Title = {{{WordNet}}: {{A Lexical Database}} for {{English}}},
	Volume = {38},
	Year = {1995},
	Bdsk-Url-1 = {https://dx.doi.org/10.1145/219717.219748}}

@phdthesis{SchulerVerbnetBroadcoverageComprehensive2005,
	Address = {Philadelphia, PA, USA},
	Author = {Schuler, Karin Kipper},
	School = {University of Pennsylvania},
	Title = {Verbnet: {{A Broad}}-Coverage, {{Comprehensive Verb Lexicon}}},
	Type = {{{PhD Thesis}}},
	Year = {2005},
	Annote = {AAI3179808}}

@inproceedings{Shi:2005:PPT:2132047.2132058,
	Acmid = {2132058},
	Address = {Mexico City, Mexico},
	Author = {Shi, Lei and Mihalcea, Rada},
	Booktitle = {Proceedings of the 6th {{International Conference}} on {{Computational Linguistics}} and {{Intelligent Text Processing}}},
	Doi = {10.1007/978-3-540-30586-6_9},
	File = {C:\\Users\\MSI\\Zotero\\storage\\7W3TJ67M\\shi.cicling05.pdf},
	Isbn = {3-540-24523-5 978-3-540-24523-0},
	Numpages = {12},
	Pages = {100--111},
	Publisher = {{Springer-Verlag}},
	Series = {CICLing'05},
	Title = {Putting {{Pieces Together}}: {{Combining FrameNet}}, {{VerbNet}} and {{WordNet}} for {{Robust Semantic Parsing}}},
	Year = {2005},
	Bdsk-Url-1 = {https://dx.doi.org/10.1007/978-3-540-30586-6_9}}

@inproceedings{Grishman:1994:CSB:991886.991931,
	Acmid = {991931},
	Address = {Kyoto, Japan},
	Author = {Grishman, Ralph and Macleod, Catherine and Meyers, Adam},
	Booktitle = {Proceedings of the 15th {{Conference}} on {{Computational Linguistics}} - {{Volume}} 1},
	Doi = {10.3115/991886.991931},
	File = {C:\\Users\\MSI\\Zotero\\storage\\ZIXFC3Q4\\p268-grishman.pdf},
	Numpages = {5},
	Pages = {268--272},
	Publisher = {{Association for Computational Linguistics}},
	Series = {COLING '94},
	Title = {Comlex {{Syntax}}: {{Building}} a {{Computational Lexicon}}},
	Year = {1994},
	Bdsk-Url-1 = {https://dx.doi.org/10.3115/991886.991931}}

@inproceedings{Hensman:2004:CCG:1614038.1614047,
	Acmid = {1614047},
	Address = {Boston, Massachusetts},
	Author = {Hensman, Svetlana},
	Booktitle = {Proceedings of the {{Student Research Workshop}} at {{HLT}}-{{NAACL}} 2004},
	Numpages = {6},
	Pages = {49--54},
	Publisher = {{Association for Computational Linguistics}},
	Series = {HLT-SRWS '04},
	Title = {Construction of {{Conceptual Graph Representation}} of {{Texts}}},
	Year = {2004}}

@book{verb-classes.levin.1993,
	Author = {Levin, Beth},
	Biburl = {https://www.bibsonomy.org/bibtex/255ee14790a0bc144b9105ab5258f4b81/huiyangsfsu},
	Editor = {{of Chicago Press}, University},
	Interhash = {63590b8294dc585bda3a9d19a3a9ff5c},
	Intrahash = {55ee14790a0bc144b9105ab5258f4b81},
	Keywords = {CAT CAT-NLP CAT-VERBNET classes verb},
	Title = {English Verb Classes and Alternations : A Preliminary Investigation},
	Year = {1993}}

@inproceedings{Novischi:2006:QAL:1220175.1220288,
	Acmid = {1220288},
	Address = {Sydney, Australia},
	Author = {Novischi, Adrian and Moldovan, Dan},
	Booktitle = {Proceedings of the 21st {{International Conference}} on {{Computational Linguistics}} and the 44th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
	Doi = {10.3115/1220175.1220288},
	File = {C:\\Users\\MSI\\Zotero\\storage\\IHTGE9PD\\2fb69531b03f309ef45bf32b8bac5cc8becd.pdf},
	Numpages = {8},
	Pages = {897--904},
	Publisher = {{Association for Computational Linguistics}},
	Series = {ACL-44},
	Title = {Question {{Answering}} with {{Lexical Chains Propagating Verb Arguments}}},
	Year = {2006},
	Bdsk-Url-1 = {https://dx.doi.org/10.3115/1220175.1220288}}

@article{journals/nle/PalmerDF07,
	Author = {Palmer, Martha and Dang, Hoa Trang and Fellbaum, Christiane},
	Biburl = {https://www.bibsonomy.org/bibtex/2eae9f06d8678fe1aab86c818f59dd935/dblp},
	Description = {dblp},
	Ee = {http://dx.doi.org/10.1017/S135132490500402X},
	Interhash = {b0e1a496ede803d50ea581d5ff26a50b},
	Intrahash = {eae9f06d8678fe1aab86c818f59dd935},
	Journal = {Natural Language Engineering},
	Keywords = {dblp},
	Month = may,
	Number = {2},
	Pages = {137--163},
	Title = {Making Fine-Grained and Coarse-Grained Sense Distinctions, Both Manually and Automatically.},
	Volume = {13},
	Year = {2009}}

@inproceedings{Dusek2015TrainingAN,
	Author = {Dusek, Ondrej and Jurc{\'\i}cek, Filip},
	Booktitle = {{{ACL}}},
	Title = {Training a {{Natural Language Generator From Unaligned Data}}},
	Year = {2015}}

@inproceedings{Belz2012TheSR,
	Author = {Belz, Anja and Bohnet, Bernd and Mille, Simon and Wanner, Leo and White, Michael Rh},
	Booktitle = {{{INLG}}},
	Title = {The {{Surface Realisation Task}}: {{Recent Developments}} and {{Future Plans}}},
	Year = {2012}}

@inproceedings{TraumGenerationLexicalConceptual2000,
	Address = {Stroudsburg, PA, USA},
	Author = {Traum, David and Habash, Nizar},
	Booktitle = {Proceedings of the 2000 {{NAACL}}-{{ANLP Workshop}} on {{Applied Interlinguas}}: {{Practical Applications}} of {{Interlingual Approaches}} to {{NLP}} - {{Volume}} 2},
	Doi = {10.3115/1117554.1117561},
	File = {C:\\Users\\MSI\\Zotero\\storage\\9F5TJJFE\\Traum and Habash - 2000 - Generation from Lexical Conceptual Structures.pdf},
	Pages = {52--59},
	Publisher = {{Association for Computational Linguistics}},
	Series = {NAACL-ANLP-Interlinguas '00},
	Title = {Generation from {{Lexical Conceptual Structures}}},
	Year = {2000},
	Abstract = {This paper describes a system for generating natural language sentences from an interlingual representation, Lexical Conceptual Structure (LCS). This system has been developed as part of a Chinese-English Machine Translation system, however, it promises to be useful for many other MT language pairs. The generation system has also been used in Cross-Language information retrieval research (Levow et al., 2000).},
	Bdsk-Url-1 = {https://dx.doi.org/10.3115/1117554.1117561}}

@article{MoensTemporalOntologyTemporal1988,
	Author = {Moens, Marc and Steedman, Mark},
	File = {C:\\Users\\MSI\\Zotero\\storage\\LMRG4VG6\\Moens and Steedman - 1988 - Temporal Ontology and Temporal Reference.pdf},
	Issn = {0891-2017},
	Journal = {Comput. Linguist.},
	Month = jun,
	Number = {2},
	Pages = {15--28},
	Title = {Temporal {{Ontology}} and {{Temporal Reference}}},
	Volume = {14},
	Year = {1988},
	Abstract = {A semantics of temporal categories in language and a theory of their use in defining the temporal relations between events both require a more complex structure on the domain underlying the meaning representations than is commonly assumed. This paper proposes an ontology based on such notions as causation and consequence, rather than on purely temporal primitives. A central notion in the ontology is that of an elementary event-complex called a "nucleus." A nucleus can be thought of as an association of a goal event, or "culmination," with a "preparatory process" by which it is accomplished, and a "consequent state," which ensues. Natural-language categories like aspects, futurates, adverbials, and when-clauses are argued to change the temporal/aspectual category of propositions under the control of such a nucleic knowledge representation structure. The same concept of a nucleus plays a central role in a theory of temporal reference, and of the semantics of tense, which we follow McCawley, Partee, and Isard in regarding as an anaphoric category. We claim that any manageable formalism for natural-language temporal descriptions will have to embody such an ontology, as will any usable temporal database for knowledge about events which is to be interrogated using natural language.}}

@inproceedings{verbnet.2006,
	Author = {Kipper, Karen and Korhonen, Anna and Ryant, Neville and Palmer, Martha},
	Biburl = {https://www.bibsonomy.org/bibtex/22b205aaeb7c9c2c6be479db6d48420be/huiyangsfsu},
	Booktitle = {Proceedings of the {{Fifth International Conference}} on {{Language Resources}} and {{Evaluation}} -- {{LREC}}'06 ({{http://verbs.colorado.edu/}}~Mpalmer/Projects/Verbnet.Html)},
	Interhash = {c4040236f9c42b6de5413352c8030eb0},
	Intrahash = {2b205aaeb7c9c2c6be479db6d48420be},
	Keywords = {CAT CAT-NLP-verb bk-ngx verbnet},
	Title = {Extending {{VerbNet}} with {{Novel Verb Classes}}},
	Year = {2006},
	Abstract = {Lexical classifications have proved useful in supporting various natural language processing (NLP) tasks. The largest verb classification for English is Levin's (1993) work which defined groupings of verbs based on syntactic properties. VerbNet (Kipper et al., 2000; Kipper-Schuler, 2005) \textendash{} the largest computational verb lexicon currently available for English \textendash{} provides detailed syntactic-semantic descriptions of Levin classes. While the classes included are extensive enough for some NLP use, they are not comprehensive. Korhonen and Briscoe (2004) have proposed a significant extension of Levin's classification which incorporates 57 novel classes for verbs not covered (comprehensively) by Levin. This paper describes the integration of these classes into VerbNet. The result is the most extensive Levin-style classification for English verbs which can be highly useful for practical applications.}}

@inproceedings{CopestakeACQUILEXLKBrepresentation1992,
	Author = {Copestake, Ann},
	Booktitle = {Proceedings of the 3rd {{Conference}} on {{Applied Natural Language Processing}} ({{ANLP}}-92},
	File = {C:\\Users\\MSI\\Zotero\\storage\\LMMZ52MX\\Copestake - 1992 - The ACQUILEX LKB representation issues in semi-au.pdf;C:\\Users\\MSI\\Zotero\\storage\\U28QB5UR\\summary.html},
	Pages = {88--96},
	Shorttitle = {The {{ACQUILEX LKB}}},
	Title = {The {{ACQUILEX LKB}}: Representation Issues in Semi-Automatic Acquisition of Large Lexicons},
	Year = {1992},
	Abstract = {We describe the lexical knowledge base sys-  tem (LKB) which has been designed and implemented  as part of the ACQUILEX project x  to allow the representation of multilingual syn-  tactic and semantic information extracted from  machine readable dictionaries (MRDs), in such  a way that it is usable by natural language  processing (NLP) systems. The LKB's lexical  representation language (LRL) augments  typed graph-based unification with default inheritance,  formalised in terms of default unifi-  cation of feature structures. We evaluate how  well the LRL meets the practical requirements  arising from the semi-automatic construction of  a large scale, multilingual lexicon. The system  as described is fully implemented and is being  used to represent substantial amounts of information  automatically extracted from MRDs.}}

@article{PustejovskyGenerativeLexicon1991,
	Author = {Pustejovsky, James},
	File = {C:\\Users\\MSI\\Zotero\\storage\\NZQXS24K\\Pustejovsky - 1991 - The Generative Lexicon.pdf},
	Issn = {0891-2017},
	Journal = {Comput. Linguist.},
	Month = dec,
	Number = {4},
	Pages = {409--441},
	Title = {The {{Generative Lexicon}}},
	Volume = {17},
	Year = {1991},
	Abstract = {In this paper, I will discuss four major topics relating to current research in lexical semantics: methodology, descriptive coverage, adequacy of the representation, and the computational usefulness of representations. In addressing these issues, I will discuss what I think are some of the central problems facing the lexical semantics community, and suggest ways of best approaching these issues. Then, I will provide a method for the decomposition of lexical categories and outline a theory of lexical semantics embodying a notion of cocompositionality and type coercion, as well as several levels of semantic description, where the semantic load is spread more evenly throughout the lexicon. I argue that lexical decomposition is possible if it is performed generatively. Rather than assuming a fixed set of primitives. I will assume a fixed number of generative devices that can be seen as constructing semantic expressions. I develop a theory of Qualia Structure, a representation language for lexical items, which renders much lexical ambiguity in the lexicon unnecessary, while still explaining the systematic polysemy that words carry. Finally, I discuss how individual lexical structures can be integrated into the larger lexical knowledge base through a theory of lexical inheritance. This provides us with the necessary principles of global organization for the lexicon, enabling us to fully integrate our natural language lexicon into a conceptual whole.}}

@article{SagotLeffffreelyavailable2010,
	Author = {Sagot, Beno{\^\i}t},
	Journal = {7th international conference on Language Resources and Evaluation (LREC 2010)},
	Month = may,
	Title = {The {{Lefff}}, a Freely Available and Large-Coverage Morphological and Syntactic Lexicon for {{French}}},
	Year = {2010},
	Abstract = {In this paper, we introduce the Lefff , a freely available, accurate and large-coverage morphological and syntactic lexicon for French, used in many NLP tools such as large-coverage parsers. We first describe Alexina, the lexical framework in which the Lefff is developed as well as the linguistic notions and formalisms it is based on. Next, we describe the various sources of lexical data we used for building the Lefff , in particular semi-automatic lexical development techniques and conversion and merging of existing resources. Finally, we illustrate the coverage and precision of the resource by comparing it with other resources and by assessing its impact in various NLP tools.}}

@inproceedings{KipperClassBasedConstructionVerb2000,
	Author = {Kipper, Karin and Dang, Hoa Trang and Palmer, Martha},
	Booktitle = {Proceedings of the {{Seventeenth National Conference}} on {{Artificial Intelligence}} and {{Twelfth Conference}} on {{Innovative Applications}} of {{Artificial Intelligence}}},
	Isbn = {978-0-262-51112-4},
	Pages = {691--696},
	Publisher = {{AAAI Press}},
	Title = {Class-{{Based Construction}} of a {{Verb Lexicon}}},
	Year = {2000}}

@inproceedings{BakerBerkeleyFrameNetProject1998,
	Address = {Stroudsburg, PA, USA},
	Author = {Baker, Collin F. and Fillmore, Charles J. and Lowe, John B.},
	Booktitle = {Proceedings of the 17th {{International Conference}} on {{Computational Linguistics}} - {{Volume}} 1},
	Doi = {10.3115/980451.980860},
	File = {C:\\Users\\MSI\\Zotero\\storage\\4ZHIGPBN\\Baker et al. - 1998 - The Berkeley FrameNet Project.pdf},
	Pages = {86--90},
	Publisher = {{Association for Computational Linguistics}},
	Series = {COLING '98},
	Title = {The {{Berkeley FrameNet Project}}},
	Year = {1998},
	Abstract = {FrameNet is a three-year NSF-supported project in corpus-based computational lexicography, now in its second year (NSF IRI-9618838, "Tools for Lexicon Building"). The project's key features are (a) a commitment to corpus evidence for semantic and syntactic generalizations, and (b) the representation of the valences of its target words (mostly nouns, adjectives, and verbs) in which the semantic portion makes use of frame semantics. The resulting database will contain (a) descriptions of the semantic frames underlying the meanings of the words described, and (b) the valence representation (semantic and syntactic) of several thousand words and phrases, each accompanied by (c) a representative collection of annotated corpus attestations, which jointly exemplify the observed linkings between "frame elements" and their syntactic realizations (e.g. grammatical function, phrase type, and other syntactic traits). This report will present the project's goals and workflow, and information about the computational tools that have been adapted or created in-house for this work.},
	Bdsk-Url-1 = {https://dx.doi.org/10.3115/980451.980860}}

@inproceedings{lareau18,
	Address = {Miyazaki},
	Author = {Lareau, Fran{\c c}ois and Lambrey, Florie and Dubinskaite, Ieva and Galarreta-Piquette, Daniel and Nejat, Maryam},
	Booktitle = {Proceedings of 11th Edition of the {{Language Resources}} and {{Evaluation Conference}} ({{LREC}})},
	Title = {{{GenDR}}: {{A Generic Deep Realizer}} with {{Complex Lexicalization}}},
	Year = {2018}}

@article{cawsey00,
	Author = {Cawsey, A.J. and Jones, R.B. and Pearson, J.},
	Journal = {User Modeling and User-Adapted Interaction},
	Number = {1},
	Pages = {47--72},
	Title = {The {{Evaluation}} of a {{Personalised Health Information System}} for {{Patients}} with {{Cancer}}},
	Volume = {10},
	Year = {2000}}

@inproceedings{callaway03,
	Address = {San Francisco},
	Author = {Callaway, Charles B.},
	Booktitle = {{{IJCAI}}'03: {{Proceedings}} of the 18th International Joint Conference on {{Artificial}} Intelligence},
	Pages = {811--816},
	Publisher = {{Morgan Kaufmann Publishers Inc.}},
	Title = {Evaluating Coverage for Large Symbolic {{NLG}} Grammars},
	Year = {2003}}

@article{ReiterInvestigationValidityMetrics2009,
	Author = {Reiter, Ehud and Belz, Anja},
	Doi = {10.1162/coli.2009.35.4.35405},
	File = {C:\\Users\\MSI\\Zotero\\storage\\762E23A4\\Reiter and Belz - 2009 - An Investigation into the Validity of Some Metrics.pdf;C:\\Users\\MSI\\Zotero\\storage\\IX64S23Z\\coli.2009.35.4.html},
	Issn = {0891-2017},
	Journal = {Computational Linguistics},
	Month = oct,
	Number = {4},
	Pages = {529--558},
	Title = {An {{Investigation}} into the {{Validity}} of {{Some Metrics}} for {{Automatically Evaluating Natural Language Generation Systems}}},
	Volume = {35},
	Year = {2009},
	Abstract = {There is growing interest in using automatically computed corpus-based evaluation metrics to evaluate Natural Language Generation (NLG) systems, because these are often considerably cheaper than the human-based evaluations which have traditionally been used in NLG. We review previous work on NLG evaluation and on validation of automatic metrics in NLP, and then present the results of two studies of how well some metrics which are popular in other areas of NLP (notably BLEU and ROUGE) correlate with human judgments in the domain of computer-generated weather forecasts. Our results suggest that, at least in this domain, metrics may provide a useful measure of language quality, although the evidence for this is not as strong as we would ideally like to see; however, they do not provide a useful measure of content quality. We also discuss a number of caveats which must be kept in mind when interpreting this and other validation studies.},
	Bdsk-Url-1 = {https://dx.doi.org/10.1162/coli.2009.35.4.35405}}

@article{Vicentegeneracionlenguajenatural2015,
	Author = {Vicente, Marta and Barros, Cristina and Peregrino Torregrosa, Fernando and Agull{\'o} Antol{\'\i}n, Francisco and Lloret, Elena},
	Copyright = {\textcopyright{} Computaci{\'o}n y Sistemas},
	Doi = {10.13053/CyS-19-4-2196},
	File = {C:\\Users\\MSI\\Zotero\\storage\\BJDWKIRE\\Vicente et al. - 2015 - La generaci{\'o}n de lenguaje natural an{\'a}lisis del es.pdf;C:\\Users\\MSI\\Zotero\\storage\\5U762MLS\\52480.html},
	Issn = {2007-9737},
	Language = {spa},
	Shorttitle = {{La generaci{\'o}n de lenguaje natural}},
	Title = {{La generaci{\'o}n de lenguaje natural: an{\'a}lisis del estado actual}},
	Year = {2015},
	Abstract = {El ser humano se comunica y expresa a trav{\'e}s del lenguaje. Para conseguirlo, ha de desarrollar una serie de habilidades de alto nivel cognitivo cuya complejidad se pone de manifiesto en la tarea de automatizar el proceso, tanto cuando se trata de producir lenguaje como de interpretarlo. Cuando la acci{\'o}n comunicativa ocurre entre una persona y un ordenador y {\'e}ste {\'u}ltimo es el destinatario de la acci{\'o}n, se emplean lenguajes computacionales que, como norma general, est{\'a}n sujetos a un conjunto de reglas fuertemente tipadas, acotadas y sin ambig{\"u}edad. Sin embargo, cuando el sentido de la comunicaci{\'o}n es el contrario y la m{\'a}quina ha de transmitir informaci{\'o}n a la persona, si el mensaje se quiere transmitir en lenguaje natural, el procedimiento para generarlo debe lidiar con la flexibilidad y la ambig{\"u}edad que lo caracterizan, dando lugar a una tarea de alto nivel de complejidad. Para que las m{\'a}quinas sean capaces de manejar el lenguaje humano se hacen necesarias t{\'e}cnicas de Ling{\"u}{\'\i}stica Computacional. Dentro de esta disciplina, el campo que se encarga de crear textos en lenguaje natural se denomina Generaci{\'o}n de Lenguaje Natural (GLN). En este art{\'\i}culo se va a hacer un recorrido exhaustivo de este campo. Se describen las fases en las que se suelen descomponer los sistemas de GLN junto a las t{\'e}cnicas que se aplican y se analiza con detalle la situaci{\'o}n actual de esta {\'a}rea de investigaci{\'o}n y su problem{\'a}tica, as{\'\i} como los recursos m{\'a}s relevantes y las t{\'e}cnicas que se est{\'a}n empleando para evaluar la calidad de los sistemas.},
	Bdsk-Url-1 = {https://dx.doi.org/10.13053/CyS-19-4-2196}}

@book{Fellbaum1998,
	Address = {Cambridge, MA},
	Biburl = {https://www.bibsonomy.org/bibtex/28472b4f9d7f2bfc4a97ffd4a023facc6/flint63},
	Editor = {Fellbaum, Christiane},
	File = {C:\\Users\\MSI\\Zotero\\storage\\LVM4UDRS\\5papers.pdf},
	Interhash = {42daa1681607dd1d3f3234c605d84ec3},
	Intrahash = {8472b4f9d7f2bfc4a97ffd4a023facc6},
	Isbn = {978-0-262-06197-1},
	Keywords = {01821 101 mitpress book shelf ai language processing ontology lexicon},
	Publisher = {{MIT Press}},
	Series = {Language, Speech, and Communication},
	Title = {{{WordNet}}: {{An Electronic Lexical Database}}},
	Username = {flint63},
	Year = {1998},
	Abstract = {WordNet, an electronic lexical database, is considered to be the most important resource available to researchers in computational linguistics, text analysis, and many related areas. Its design is inspired by current psycholinguistic and computational theories of human lexical memory. English nouns, verbs, adjectives, and adverbs are organized into synonym sets, each representing one underlying lexicalized concept. Different relations link the synonym sets. The purpose of this volume is twofold. First, it discusses the design of WordNet and the theoretical motivations behind it. Second, it provides a survey of representative applications, including word sense identification, information retrieval, selectional preferences of verbs, and lexical chains.}}

@article{ResearchGroupLexicalizedTreeAdjoining2001,
	Author = {Research Group, The XTAG},
	File = {C:\\Users\\MSI\\Zotero\\storage\\NAV729BR\\8.html},
	Journal = {IRCS Technical Reports Series},
	Month = feb,
	Title = {A {{Lexicalized Tree Adjoining Grammar}} for {{English}}},
	Year = {2001}}

@inproceedings{W04-3326,
	Address = {Vancouver, Canada},
	Author = {Ryant, Neville and Kipper, Karin},
	Booktitle = {Proceedings of the 7th {{International Workshop}} on {{Tree Adjoining Grammar}} and {{Related Formalisms}}},
	File = {C:\\Users\\MSI\\Zotero\\storage\\G9JYLLQZ\\W04-3326.pdf},
	Pages = {194--198},
	Title = {Assigning {{XTAG Trees}} to {{VerbNet}}},
	Year = {2004}}

@article{DorrUseLexicalSemantics1992,
	Author = {Dorr, Bonnie J.},
	File = {C:\\Users\\MSI\\Zotero\\storage\\GLECJMX7\\Dorr - 1992 - The Use of Lexical Semantics in Interlingual Machi.pdf},
	Issn = {0922-6567},
	Journal = {Machine Translation},
	Number = {3},
	Pages = {135--193},
	Title = {The {{Use}} of {{Lexical Semantics}} in {{Interlingual Machine Translation}}},
	Volume = {7},
	Year = {1992},
	Abstract = {This paper describes the lexical-semantic basis for UNITRAN, an implemented scheme for translating Spanish, English, and German bidirectionally. Two claims made here are that the current representation handles many distinctions (or "divergences") across languages without recourse to language-specific rules and that the lexical-semantic framework provides the basis for a systematic mapping between the interlingua and the syntactic structure. The representation adopted is an extended version of "lexical conceptual structure" which is suitable to the task of translating between divergent structures for two reasons: (1) it provides an abstraction of language-independent properties from structural idiosyncrasies; and (2) it is compositional in nature. The lexical-semantic approach ad- dresses the divergence problem by using a linguistically grounded mapping that has access to parameter settings in the lexicon. We will examine a number of relevant issues including the problem of defining primitives, the issue of interlinguality, the cross-linguistic cover- age of the system, and the mapping between the syntactic structure and the interlingua. A detailed example of lexical-semantic composition will be presented.}}

@article{MacLeod1997,
	Author = {MacLeod, Catherine and Grishman, Ralph and Meyers, Adam},
	Day = {01},
	Doi = {10.1023/A:1001142417369},
	File = {C:\\Users\\MSI\\Zotero\\storage\\DR2LQI6B\\10.1023A1001142417369.pdf},
	Issn = {1572-8412},
	Journal = {Computers and the Humanities},
	Month = nov,
	Number = {6},
	Pages = {459--481},
	Title = {{{COMLEX Syntax}} -- {{A Large Syntactic Dictionary}} for {{Natural Language Processing}}},
	Volume = {31},
	Year = {1997},
	Abstract = {This article is a detailed account of COMLEX Syntax, an on-line syntactic dictionary of English, developed by the Proteus Project at New York University under the auspices of the Linguistics Data Consortium. This lexicon was intended to be used for a variety of tasks in natural language processing by computer and as such has very detailed classes with a large number of syntactic features and complements for the major parts of speech and is, as far as possible, theory neutral. The dictionary was entered by hand with reference to hard copy dictionaries, an on-line concordance and native speakers`intuition. Thus it is without prior encumbrances and can be used for both pure research and commercial purposes.},
	Bdsk-Url-1 = {https://dx.doi.org/10.1023/A:1001142417369}}

@inproceedings{McFateExpandingVerbCoverage2010,
	Address = {Stroudsburg, PA, USA},
	Author = {McFate, Clifton J.},
	Booktitle = {Proceedings of the {{ACL}} 2010 {{Student Research Workshop}}},
	File = {C:\\Users\\MSI\\Zotero\\storage\\XTIWF5G7\\McFate - 2010 - Expanding Verb Coverage in Cyc with VerbNet.pdf},
	Pages = {61--66},
	Publisher = {{Association for Computational Linguistics}},
	Series = {ACLstudent '10},
	Title = {Expanding {{Verb Coverage}} in {{Cyc}} with {{VerbNet}}},
	Year = {2010},
	Abstract = {A robust dictionary of semantic frames is an essential element of natural language understanding systems that use ontologies. However, creating lexical resources that accurately capture semantic representations en masse is a persistent problem. Where the sheer amount of content makes hand creation inefficient, computerized approaches often suffer from over generality and difficulty with sense disambiguation. This paper describes a semi-automatic method to create verb semantic frames in the Cyc ontology by converting the information contained in VerbNet into a Cyc usable format. This method captures the differences in meaning between types of verbs, and uses existing connections between WordNet, VerbNet, and Cyc to specify distinctions between individual verbs when available. This method provides 27,909 frames to OpenCyc which currently has none and can be used to extend ResearchCyc as well. We show that these frames lead to a 20\% increase in sample sentences parsed over the Research Cyc verb lexicon.}}

@inproceedings{HensmanAutomaticallyBuildingConceptual2004,
	Address = {Las Vegas, Nevada, USA},
	Author = {Hensman, Svetlana and Dunnion, John},
	Booktitle = {Proceedings of the 2004 {{International Symposium}} on {{Information}} and {{Communication Technologies}}},
	File = {C:\\Users\\MSI\\Zotero\\storage\\Y8BY3HAP\\Hensman and Dunnion - 2004 - Automatically Building Conceptual Graphs Using Ver.pdf},
	Isbn = {978-1-59593-170-2},
	Pages = {115--120},
	Publisher = {{Trinity College Dublin}},
	Series = {ISICT '04},
	Title = {Automatically {{Building Conceptual Graphs Using VerbNet}} and {{WordNet}}},
	Year = {2004},
	Abstract = {With the huge number of documents becoming available in electronic form, finding the right information in a large corpus is becoming an increasingly important and difficult task. We believe that semantic processing is required for accurate information retrieval.This paper describes a framework for the automatic creation of semantic markup and its insertion into XML documents. The availability of such semantic annotation would be of great help when the documents are queried, and, in particular, would facilitate the application of inference techniques, therefore allowing the system to deduce information not explicitly mentioned in the text.}}

@inproceedings{BrownVerbNetClassAssignment2011,
	Address = {Stroudsburg, PA, USA},
	Author = {Brown, Susan Windisch and Dligach, Dmitriy and Palmer, Martha},
	Booktitle = {Proceedings of the {{Ninth International Conference}} on {{Computational Semantics}}},
	File = {C:\\Users\\MSI\\Zotero\\storage\\749LVGDU\\Brown et al. - 2011 - VerbNet Class Assignment As a WSD Task.pdf},
	Pages = {85--94},
	Publisher = {{Association for Computational Linguistics}},
	Series = {IWCS '11},
	Title = {{{VerbNet Class Assignment As}} a {{WSD Task}}},
	Year = {2011},
	Abstract = {The VerbNet lexical resource classifies English verbs based on semantic and syntactic regularities and has been used for numerous NLP tasks, most notably, semantic role labeling. Since, in addition to thematic roles, it also provides semantic predicates, it can serve as a foundation for further inferencing. Many verbs belong to multiple VerbNet classes, with each class membership corresponding roughly to a different sense of the verb. A VerbNet token classifier is essential for current applications using the resource and could provide the basis for a deep semantic parsing system, one that made full use of VerbNet's extensive syntactic and semantic information. We describe our VerbNet classifier, which uses rich syntactic and semantic features to label verb instances with their appropriate VerbNet class. It achieves an accuracy of 88.67\% with multiclass verbs, which is a 49\% error reduction over the most frequent class baseline.}}

@inproceedings{Korhonenlargesubcategorizationlexicon2006,
	Author = {Korhonen, Anna and Krymolowski, Yuval and Briscoe, Ted},
	Booktitle = {In {{Proceedings}} of {{LREC}}},
	File = {C:\\Users\\MSI\\Zotero\\storage\\QQHCTZ8G\\Korhonen et al. - 2006 - A large subcategorization lexicon for natural lang.pdf},
	Title = {A Large Subcategorization Lexicon for Natural Language Processing Applications},
	Year = {2006},
	Abstract = {We introduce a large computational subcategorization lexicon which includes subcategorization frame (SCF) and frequency information for 6,397 English verbs. This extensive lexicon was acquired automatically from five corpora and the Web using the current version of the comprehensive subcategorization acquisition system of Briscoe and Carroll (1997). The lexicon is provided freely for research use, along with a script which can be used to filter and build sub-lexicons suited for different natural language processing (NLP) purposes. Documentation is also provided which explains each sub-lexicon option and evaluates its accuracy. 1.}}

@inproceedings{MessiantSubcategorizationAcquisitionSystem2008,
	Address = {Stroudsburg, PA, USA},
	Author = {Messiant, C{\'e}dric},
	Booktitle = {Proceedings of the 46th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} on {{Human Language Technologies}}: {{Student Research Workshop}}},
	File = {C:\\Users\\MSI\\Zotero\\storage\\6TMRWYXW\\Messiant - 2008 - A Subcategorization Acquisition System for French .pdf},
	Pages = {55--60},
	Publisher = {{Association for Computational Linguistics}},
	Series = {HLT-SRWS '08},
	Title = {A {{Subcategorization Acquisition System}} for {{French Verbs}}},
	Year = {2008},
	Abstract = {This paper presents a system capable of automatically acquiring subcategorization frames (SCFs) for French verbs from the analysis of large corpora. We applied the system to a large newspaper corpus (consisting of 10 years of the French newspaper 'Le Monde') and acquired subcategorization information for 3267 verbs. The system learned 286 SCF types for these verbs. From the analysis of 25 representative verbs, we obtained 0.82 precision, 0.59 recall and 0.69 F-measure. These results are comparable with those reported in recent related work.}}

@article{asmussen2005a,
	Author = {Asmussen, J{\o}rg and {\O}rsnes, Bjarne},
	Editor = {{Kiefer, F., Kiss G. Pajzs J{\'u}lia}},
	Journal = {Papers in Computational Lexicography},
	Language = {English},
	Title = {Valency Information for Dictionaries and {{NLP}} Lexicons},
	Year = {2005}}

@inproceedings{DoranXTAGSystemWide1994,
	Address = {Stroudsburg, PA, USA},
	Author = {Doran, Christy and Egedi, Dania and Hockey, Beth Ann and Srinivas, B. and Zaidel, Martin},
	Booktitle = {Proceedings of the 15th {{Conference}} on {{Computational Linguistics}} - {{Volume}} 2},
	Doi = {10.3115/991250.991297},
	File = {C:\\Users\\MSI\\Zotero\\storage\\MJAKTU9D\\Doran et al. - 1994 - XTAG System A Wide Coverage Grammar for English.pdf},
	Pages = {922--928},
	Publisher = {{Association for Computational Linguistics}},
	Series = {COLING '94},
	Shorttitle = {{{XTAG System}}},
	Title = {{{XTAG System}}: {{A Wide Coverage Grammar}} for {{English}}},
	Year = {1994},
	Abstract = {This paper present the XTAG system, a grammar development tool based on the Tree Adjoining Grammar (TAG) formalism that includes a wide-coverage syntactic grammar for English. The various components of the system are discussed and preliminary evaluation results from the parsing of various corpora are given. Results from the comparison of XTAG against the IBM statistical parser and the Alvey Natural Language Tool parser are also given.},
	Bdsk-Url-1 = {https://dx.doi.org/10.3115/991250.991297}}

@techreport{xtag-2001,
	Author = {{XTAG Research Group}},
	Biburl = {http://sandbox.academic-puma.de/bibtex/24e57db5127da28382c02956a2a07a334/alistair},
	Institution = {{IRCS, University of Pennsylvania}},
	Interhash = {bb5698d870802b339d0d32f79e3498c1},
	Intrahash = {4e57db5127da28382c02956a2a07a334},
	Keywords = {grammar linguistic},
	Number = {IRCS-01-03},
	Title = {A {{Lexicalized Tree Adjoining Grammar}} for {{English}}},
	Topics = {area.analysis},
	Year = {2001}}

@article{citeulike:6058251,
	Author = {Fellbaum, Christiane},
	Biburl = {https://www.bibsonomy.org/bibtex/21b15f18548f5ad117f7564b25c04de51/baisemain},
	Citeulike-Article-Id = {6058251},
	Citeulike-Linkout-0 = {http://dx.doi.org/10.1093/ijl/3.4.278},
	Citeulike-Linkout-1 = {http://ijl.oxfordjournals.org/content/3/4/278.abstract},
	Citeulike-Linkout-2 = {http://ijl.oxfordjournals.org/content/3/4/278.full.pdf},
	Day = {21},
	Doi = {10.1093/ijl/3.4.278},
	Interhash = {0cd3a505c3964ed7deae5e5293ebdde2},
	Intrahash = {1b15f18548f5ad117f7564b25c04de51},
	Journal = {International Journal of Lexicography},
	Keywords = {ijl,lexicography},
	Month = dec,
	Number = {4},
	Pages = {278--301},
	Posted-At = {2011-04-28 20:07:59},
	Priority = {2},
	Title = {English {{Verbs}} as a {{Semantic Net}}},
	Volume = {3},
	Year = {1990},
	Abstract = {This paper describes the semantic network of English verbs in WordNet. The semantic relations used to build networks of nouns and adjectives cannot be applied without modification, but have to be adapted to fit the semantics of verbs, which differ substantially from those of the other lexical categories. The nature of these relations is discussed, as is their distribution throughout different semantic groups of verbs, which determines certain idiosyneratic patterns of lexicalization. In addition, four variants of lexical entailment are distinguished, which interact in systematic ways with the semantic relations. Finally, the lexical properties of the different verb groups are outlined.},
	Bdsk-Url-1 = {https://dx.doi.org/10.1093/ijl/3.4.278}}

@inproceedings{AyanGeneratingParsingLexicon2002a,
	Author = {Ayan, Necip Faz{\i}l and Dorr, Bonnie J.},
	Booktitle = {In: {{Proceedings}} of the {{LREC}}-2002 {{Workshop}} on {{Linguistic Knowledge Acquisition}} and {{Representation}}, {{Las Palmas}}, {{Canary Islands}}},
	File = {C:\\Users\\MSI\\Zotero\\storage\\HSIMCWCE\\Ayan and Dorr - 2002 - Generating A Parsing Lexicon from an LCS-Based Lex.pdf},
	Pages = {4352},
	Title = {Generating {{A Parsing Lexicon}} from an {{LCS}}-{{Based Lexicon}}},
	Year = {2002},
	Abstract = {This paper describes a technique for generating parsing lexicons for a principle-based parser (Minipar). Our approach maps lexical entries in a large LCS-based repository of semantically classified verbs to their corresponding syntactic patterns. A by-product of this mapping is a lexicon that is directly usable in the Minipar system. We evaluate the accuracy and coverage of this lexicon using LDOCE syntactic codes as a gold standard. We show that this lexicon is comparable to the hand-generated Minipar lexicon (i.e., similar recall and precision values). In a later experiment, we automate the process of mapping between the LCS-based repository and syntactic patterns. The advantage of automating the process is that the same technique can be applied directly to lexicons we have for other languages, for example, Arabic, Chinese, and Spanish. 1.}}

@inproceedings{MESSIANT08.142,
	Address = {Marrakech, Morocco},
	Author = {C{\'e}dric Messiant, Thierry Poibeau and Korhonen, Anna},
	Booktitle = {Proceedings of the {{Sixth International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}'08)},
	Editor = {{Nicoletta Calzolari (Conference Chair), Khalid Choukri, Bente Maegaard Joseph Mariani Jan Odijk Stelios Piperidis Daniel Tapias}},
	Isbn = {2-9517408-4-0},
	Month = may,
	Note = {http://www.lrec-conf.org/proceedings/lrec2008/},
	Publisher = {{European Language Resources Association (ELRA)}},
	Title = {{{LexSchem}}: A {{Large Subcategorization Lexicon}} for {{French Verbs}}},
	Year = {2008}}

@inproceedings{PROISL10.62,
	Address = {Valletta, Malta},
	Author = {Proisl, Thomas and Kabashi, Besim},
	Booktitle = {Proceedings of the {{Seventh International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}'10)},
	Editor = {Chair), Nicoletta Calzolari (Conference and Choukri, Khalid and Maegaard, Bente and Mariani, Joseph and Odijk, Jan and Piperidis, Stelios and Rosner, Mike and Tapias, Daniel},
	Isbn = {2-9517408-6-7},
	Month = may,
	Publisher = {{European Language Resources Association (ELRA)}},
	Title = {Using {{High}}-{{Quality Resources}} in {{NLP}}: {{The Valency Dictionary}} of {{English}} as a {{Resource}} for {{Left}}-{{Associative Grammars}}},
	Year = {2010}}

@inproceedings{BriscoeSecondReleaseRASP2006,
	Address = {Stroudsburg, PA, USA},
	Author = {Briscoe, Ted and Carroll, John and Watson, Rebecca},
	Booktitle = {Proceedings of the {{COLING}}/{{ACL}} on {{Interactive Presentation Sessions}}},
	Doi = {10.3115/1225403.1225423},
	File = {C:\\Users\\MSI\\Zotero\\storage\\JT6XELXG\\Briscoe et al. - 2006 - The Second Release of the RASP System.pdf},
	Pages = {77--80},
	Publisher = {{Association for Computational Linguistics}},
	Series = {COLING-ACL '06},
	Title = {The {{Second Release}} of the {{RASP System}}},
	Year = {2006},
	Abstract = {We describe the new release of the RASP (robust accurate statistical parsing) system, designed for syntactic annotation of free text. The new version includes a revised and more semantically-motivated output representation, an enhanced grammar and part-of-speech tagger lexicon, and a more flexible and semi-supervised training method for the structural parse ranking model. We evaluate the released version on the WSJ using a relational evaluation scheme, and describe how the new release allows users to enhance performance using (in-domain) lexical information.},
	Bdsk-Url-1 = {https://dx.doi.org/10.3115/1225403.1225423}}

@inproceedings{verbalex,
	Author = {Hlav{\'a}{\v c}kov{\'a}, Dana},
	Booktitle = {In {{Proceedings}} of the {{Slovko Conference}}},
	Title = {Verbalex \textendash{} New Comprehensive Lexicon of Verb Valencies for Czech},
	Year = {2005}}

@inproceedings{AbendSupervisedAlgorithmVerb2008,
	Address = {Stroudsburg, PA, USA},
	Author = {Abend, Omri and Reichart, Roi and Rappoport, Ari},
	Booktitle = {Proceedings of the {{22Nd International Conference}} on {{Computational Linguistics}} - {{Volume}} 1},
	File = {C:\\Users\\MSI\\Zotero\\storage\\PRCSK2Q5\\Abend et al. - 2008 - A Supervised Algorithm for Verb Disambiguation int.pdf},
	Isbn = {978-1-905593-44-6},
	Pages = {9--16},
	Publisher = {{Association for Computational Linguistics}},
	Series = {COLING '08},
	Title = {A {{Supervised Algorithm}} for {{Verb Disambiguation}} into {{VerbNet Classes}}},
	Year = {2008},
	Abstract = {VerbNet (VN) is a major large-scale English verb lexicon. Mapping verb instances to their VN classes has been proven useful for several NLP tasks. However, verbs are polysemous with respect to their VN classes. We introduce a novel supervised learning model for mapping verb instances to VN classes, using rich syntactic features and class membership constraints. We evaluate the algorithm in both in-domain and corpus adaptation scenarios. In both cases, we use the manually tagged Semlink WSJ corpus as training data. For indomain (testing on Semlink WSJ data), we achieve 95.9\% accuracy, 35.1\% error reduction (ER) over a strong baseline. For adaptation, we test on the GENIA corpus and achieve 72.4\% accuracy with 10.7\% ER. This is the first large-scale experimentation with automatic algorithms for this task.}}

@inproceedings{DBLP:conf/acl/KlebanovLGSF16,
	Author = {Klebanov, Beata Beigman and Leong, Chee Wee and Guti{\'e}rrez, E. Dario and Shutova, Ekaterina and Flor, Michael},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/conf/acl/KlebanovLGSF16},
	Booktitle = {Proceedings of the 54th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}, {{ACL}} 2016, {{August}} 7-12, 2016, {{Berlin}}, {{Germany}}, {{Volume}} 2: {{Short Papers}}},
	Crossref = {DBLP:conf/acl/2016-2},
	Title = {Semantic Classifications for Detection of Verb Metaphors},
	Year = {2016}}

@book{DBLP:conf/acl/2016-2,
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/conf/acl/2016-2},
	Isbn = {978-1-945626-01-2},
	Publisher = {{The Association for Computer Linguistics}},
	Title = {Proceedings of the 54th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}, {{ACL}} 2016, {{August}} 7-12, 2016, {{Berlin}}, {{Germany}}, {{Volume}} 2: {{Short Papers}}},
	Year = {2016}}

@article{DusekSequencetoSequenceGenerationSpoken2016,
	Archiveprefix = {arXiv},
	Author = {Du{\v s}ek, Ond{\v r}ej and Jur{\v c}{\'\i}{\v c}ek, Filip},
	Doi = {10.18653/v1/P16-2008},
	Eprint = {1606.05491},
	Eprinttype = {arxiv},
	File = {C:\\Users\\MSI\\Zotero\\storage\\P6GV3NIF\\Du{\v s}ek and Jur{\v c}{\'\i}{\v c}ek - 2016 - Sequence-to-Sequence Generation for Spoken Dialogu.pdf;C:\\Users\\MSI\\Zotero\\storage\\R48PCS3J\\1606.html},
	Journal = {arXiv:1606.05491 [cs]},
	Keywords = {Computer Science - Computation and Language,I.2.7},
	Pages = {45--51},
	Primaryclass = {cs},
	Title = {Sequence-to-{{Sequence Generation}} for {{Spoken Dialogue}} via {{Deep Syntax Trees}} and {{Strings}}},
	Year = {2016},
	Abstract = {We present a natural language generator based on the sequence-to-sequence approach that can be trained to produce natural language strings as well as deep syntax dependency trees from input dialogue acts, and we use it to directly compare two-step generation with separate sentence planning and surface realization stages to a joint, one-step approach. We were able to train both setups successfully using very little training data. The joint setup offers better performance, surpassing state-of-the-art with regards to n-gram-based scores while providing more relevant outputs.},
	Annote = {Comment: Accepted as a short paper for ACL 2016},
	Bdsk-Url-1 = {https://dx.doi.org/10.18653/v1/P16-2008}}

@phdthesis{PfeilAlgorithmsResourcesScalable2016,
	Author = {Pfeil, Jonathan W.},
	File = {C:\\Users\\MSI\\Zotero\\storage\\9FET5SSM\\Pfeil - 2016 - Algorithms and Resources for Scalable Natural Lang.pdf;C:\\Users\\MSI\\Zotero\\storage\\ZM4XXJAS\\pg_10.html},
	School = {Case Western Reserve University},
	Title = {Algorithms and {{Resources}} for {{Scalable Natural Language Generation}}},
	Year = {2016}}

@inproceedings{GalanisGeneratingMultilingualDescriptions2007,
	Address = {Stroudsburg, PA, USA},
	Author = {Galanis, Dimitrios and Androutsopoulos, Ion},
	Booktitle = {Proceedings of the {{Eleventh European Workshop}} on {{Natural Language Generation}}},
	File = {C:\\Users\\MSI\\Zotero\\storage\\GHPWRVNT\\Galanis and Androutsopoulos - 2007 - Generating Multilingual Descriptions from Linguist.pdf},
	Pages = {143--146},
	Publisher = {{Association for Computational Linguistics}},
	Series = {ENLG '07},
	Shorttitle = {Generating {{Multilingual Descriptions}} from {{Linguistically Annotated OWL Ontologies}}},
	Title = {Generating {{Multilingual Descriptions}} from {{Linguistically Annotated OWL Ontologies}}: {{The NaturalOWL System}}},
	Year = {2007},
	Abstract = {We introduce NaturalOWL, an open-source multilingual natural language generator that produces descriptions of instances and classes, starting from a linguistically annotated ontology. The generator is heavily based on ideas from ILEX and M-PIRO, but it is in many ways simpler and it provides full support for OWL DL ontologies with RDF linguistic annotations. NaturalOWL is written in Java, and it is supported by M-PIRO's authoring tool, as well as an alternative plug-in for the Prot{\'e}g{\'e} ontology editor.}}

@inproceedings{W05-1602,
	Author = {Biller, Ofer and Elhadad, Michael and Netzer, Yael},
	Booktitle = {Proceedings of the {{Tenth European Workshop}} on {{Natural Language Generation}} ({{ENLG}}-05)},
	File = {C:\\Users\\MSI\\Zotero\\storage\\5SMAS7UE\\W05-1602.pdf},
	Title = {Interactive {{Authoring}} of {{Logical Forms}} for {{Multilingual Generation}}},
	Year = {2005}}

@article{GattSurveyStateArt2017,
	Archiveprefix = {arXiv},
	Author = {Gatt, Albert and Krahmer, Emiel},
	Eprint = {1703.09902},
	Eprinttype = {arxiv},
	File = {C:\\Users\\MSI\\Zotero\\storage\\F2TUIDBY\\Gatt and Krahmer - 2017 - Survey of the State of the Art in Natural Language.pdf;C:\\Users\\MSI\\Zotero\\storage\\EX4468RS\\1703.html},
	Journal = {arXiv:1703.09902 [cs]},
	Keywords = {Computer Science - Computation and Language,I.2.7,Computer Science - Artificial Intelligence,Computer Science - Neural and Evolutionary Computing,H.5},
	Month = mar,
	Primaryclass = {cs},
	Shorttitle = {Survey of the {{State}} of the {{Art}} in {{Natural Language Generation}}},
	Title = {Survey of the {{State}} of the {{Art}} in {{Natural Language Generation}}: {{Core}} Tasks, Applications and Evaluation},
	Year = {2017},
	Abstract = {This paper surveys the current state of the art in Natural Language Generation (NLG), defined as the task of generating text or speech from non-linguistic input. A survey of NLG is timely in view of the changes that the field has undergone over the past decade or so, especially in relation to new (usually data-driven) methods, as well as new applications of NLG technology. This survey therefore aims to (a) give an up-to-date synthesis of research on the core tasks in NLG and the architectures adopted in which such tasks are organised; (b) highlight a number of relatively recent research topics that have arisen partly as a result of growing synergies between NLG and other areas of artificial intelligence; (c) draw attention to the challenges in NLG evaluation, relating them to similar challenges faced in other areas of Natural Language Processing, with an emphasis on different evaluation methods and the relationships between them.},
	Annote = {Comment: Published in Journal of AI Research (JAIR), volume 61, pp 75-170. 118 pages, 8 figures, 1 table}}

@incollection{fillmore:case,
	Address = {New York},
	Author = {Fillmore, Charles J.},
	Biburl = {https://www.bibsonomy.org/bibtex/2bec94321ea706cd7b383ca9287413139/idsia},
	Booktitle = {Universals in {{Linguistic Theory}}},
	Citeulike-Article-Id = {2376632},
	Editor = {Bach, Emmon and Harms, Robert T.},
	Interhash = {103bf01751708ebaeb99980e6fa368b8},
	Intrahash = {bec94321ea706cd7b383ca9287413139},
	Keywords = {nn},
	Pages = {0--88},
	Priority = {2},
	Publisher = {{Holt, Rinehart and Winston}},
	Title = {The {{Case}} for {{Case}}},
	Year = {1968}}

@book{Jackendoff1972-JACSII-2,
	Author = {Jackendoff, Ray},
	Publisher = {{Cambridge: Mass., Mit Press}},
	Title = {Semantic {{Interpretation}} in {{Generative Grammar}}},
	Year = {1972}}

@article{PalmerPropositionBankAnnotated2005,
	Author = {Palmer, Martha and Gildea, Daniel and Kingsbury, Paul},
	Doi = {10.1162/0891201053630264},
	File = {C:\\Users\\MSI\\Zotero\\storage\\JH2QLB7Y\\Palmer et al. - 2005 - The Proposition Bank An Annotated Corpus of Seman.pdf},
	Issn = {0891-2017},
	Journal = {Comput. Linguist.},
	Month = mar,
	Number = {1},
	Pages = {71--106},
	Shorttitle = {The {{Proposition Bank}}},
	Title = {The {{Proposition Bank}}: {{An Annotated Corpus}} of {{Semantic Roles}}},
	Volume = {31},
	Year = {2005},
	Abstract = {The Proposition Bank project takes a practical approach to semantic representation, adding a layer of predicate-argument information, or semantic role labels, to the syntactic structures of the Penn Treebank. The resulting resource can be thought of as shallow, in that it does not represent coreference, quantification, and many other higher-order phenomena, but also broad, in that it covers every instance of every verb in the corpus and allows representative statistics to be calculated.We discuss the criteria used to define the sets of semantic roles used in the annotation process and to analyze the frequency of syntactic/semantic alternations in the corpus. We describe an automatic system for semantic role tagging trained on the corpus and discuss the effect on its performance of various types of information, including a comparison of full syntactic parsing with a flat representation and the contribution of the empty ''trace'' categories of the treebank.},
	Bdsk-Url-1 = {https://dx.doi.org/10.1162/0891201053630264}}

@misc{ehudreiterNaturalLanguageGeneration2016,
	Author = {{ehudreiter}},
	File = {C:\\Users\\MSI\\Zotero\\storage\\HKVVGTEV\\nlg-and-ml.html},
	Journal = {Ehud Reiter's Blog},
	Language = {en},
	Month = dec,
	Title = {Natural {{Language Generation}} and {{Machine Learning}}},
	Year = {2016},
	Abstract = {Machine Learning and statistical corpus techniques are often very useful in Natural Language Generation, but they are not the best way to solve all NLG problems.}}

@article{11403/dicovalence/v1,
	Author = {{D{\'e}partement de linguistique}},
	Copyright = {Licence Publique G{\'e}n{\'e}rale Amoindrie GNU pour les Ressources linguistiques},
	Note = {ORTOLANG (Open Resources and TOols for LANGuage) \textendash{}www.ortolang.fr},
	Title = {Dicovalence},
	Year = {2017}}

@article{faucris.1039365,
	Author = {Herbst, Thomas and Uhrig, Peter},
	Faupublication = {yes},
	Keywords = {pattern - construction - valency},
	Peerreviewed = {automatic},
	Title = {Erlangen {{Valency Patternbank}}. {{A}} Corpus-Based Research Tool for Work on Valency and Argument Structure Constructions.},
	Year = {2009},
	Abstract = {The patternbank is a \&nbsp;research tool for all linguists and psychologists doing research on valency paterns of English verbs, nouns and adjectives.}}

@book{HerbstValencyDictionaryEnglish2004,
	Address = {Berlin, Boston},
	Author = {Herbst, Thomas and Heath, David and Roe, Ian F. and G{\"o}tz, Dieter},
	Doi = {10.1515/9783110892581},
	Isbn = {978-3-11-089258-1},
	Keywords = {English/language,valency/lexicon; dictionary},
	Publisher = {{De Gruyter Mouton}},
	Title = {A {{Valency Dictionary}} of {{English}}, {{A Corpus}}-{{Based Analysis}} of the {{Complementation Patterns}} of {{English Verbs}}, {{Nouns}} and {{Adjectives}}},
	Year = {2004},
	Abstract = {This dictionary provides a valency description of English verbs, nouns and adjectives. Each entry contains a comprehensive list of the complementation patterns identified on the basis of the largest corpus of English available at the present time. All examples are taken directly from the COBUILD/Birmingham corpus. The valency description comprises statements about the quantitative valency of the lexical units established, an inventory of their obligatory, contextually optional and purely optional complements as well as systematic information on the semantic and collocational properties of the complements. An outline of the model of valency theory used in this dictionary is provided in the introduction.},
	Bdsk-Url-1 = {https://dx.doi.org/10.1515/9783110892581}}

@book{mel2012semantics,
	Author = {Mel'cuk, I.A. and Beck, D. and Polgu{\`e}re, A.},
	Isbn = {978-90-272-0596-4},
	Lccn = {2012017459},
	Number = {v. 1},
	Publisher = {{John Benjamins Publishing Company}},
	Series = {Semantics: From Meaning to Text},
	Title = {Semantics: {{From Meaning}} to {{Text}}},
	Year = {2012}}

@inproceedings{BelzSystemBuildingCost2009,
	Address = {Stroudsburg, PA, USA},
	Author = {Belz, Anja and Kow, Eric},
	Booktitle = {Proceedings of the 12th {{European Workshop}} on {{Natural Language Generation}}},
	File = {C:\\Users\\MSI\\Zotero\\storage\\5MJIQX9C\\Belz and Kow - 2009 - System Building Cost vs. Output Quality in Data-to.pdf},
	Pages = {16--24},
	Publisher = {{Association for Computational Linguistics}},
	Series = {ENLG '09},
	Title = {System {{Building Cost}} vs. {{Output Quality}} in {{Data}}-to-Text {{Generation}}},
	Year = {2009},
	Abstract = {Data-to-text generation systems tend to be knowledge-based and manually built, which limits their reusability and makes them time and cost-intensive to create and maintain. Methods for automating (part of) the system building process exist, but do such methods risk a loss in output quality? In this paper, we investigate the cost/quality trade-off in generation system building. We compare four new data-to-text systems which were created by predominantly automatic techniques against six existing systems for the same domain which were created by predominantly manual techniques. We evaluate the ten systems using intrinsic automatic metrics and human quality ratings. We find that increasing the degree to which system building is automated does not necessarily result in a reduction in output quality. We find furthermore that standard automatic evaluation metrics underestimate the quality of handcrafted systems and over-estimate the quality of automatically created systems.}}

@inproceedings{MilleLargeCoverageDetailed2015,
	Address = {Edinburgh, Scotland},
	Author = {Mille, Simon and Wanner, Leo},
	Booktitle = {Proceedings of the {{First International Workshop}} on {{D2T Generation}}},
	File = {C:\\Users\\MSI\\Zotero\\storage\\BCNETQ6X\\d2t_MilleWanner.pdf},
	Title = {Towards {{Large Coverage Detailed Lexical Resources}} for {{Data}}-to-{{Text Generation}}.},
	Year = {2015}}

@article{ScartoncrosslinguisticVerbNetstylelexicon,
	Author = {Scarton, Carolina and Alu, Sandra},
	File = {C:\\Users\\MSI\\Zotero\\storage\\C6GPDN9L\\Scarton and Alu - Towards a cross-linguistic VerbNet-style lexicon f.pdf},
	Pages = {8},
	Title = {Towards a Cross-Linguistic {{VerbNet}}-Style Lexicon for {{Brazilian Portuguese}}},
	Abstract = {This paper presents preliminary results of the Brazilian Portuguese Verbnet (VerbNet.Br). This resource is being built by using other existing Computational Lexical Resources via a semi-automatic method. We identified, automatically, 5688 verbs as candidate members of VerbNet.Br, which are distributed in 257 classes inherited from VerbNet. These preliminary results give us some directions of future work and, since the results were automatically generated, a manual revision of the complete resource is highly desirable.}}

@article{DanlosVerscreationVerb,
	Author = {Danlos, Laurence and Nakamura, Takuya and Pradet, Quentin and Paris-Est, IGM-LabInfo Universit{\'e} and Cedex, Marne-la-Vall{\'e}e},
	File = {C:\\Users\\MSI\\Zotero\\storage\\PU54M2KX\\Danlos et al. - Vers la cr{\'e}ation d'un Verb net du fran{\c c}ais.pdf},
	Pages = {6},
	Title = {Vers La Cr{\'e}ation d'un {{Verb}} Net Du Fran{\c c}ais},
	Abstract = {VerbNet is an English lexical resource that has proven useful for NLP due to its high coverage and coherent classification. Such a resource doesn't exist for French, despite some (mostly automatic and unsupervised) attempts. We show how to semi-automatically adapt VerbNet using existing lexical resources, namely LVF (Les Verbes Fran{\c c}ais) and LG (Lexique-Grammaire).}}

@article{BussoItalianVerbNetConstructionbased,
	Author = {Busso, Lucia and Lenci, Alessandro},
	File = {C:\\Users\\MSI\\Zotero\\storage\\8ZCXB93Q\\Busso and Lenci - Italian VerbNet A Construction-based Approach to .pdf},
	Pages = {10},
	Title = {Italian {{VerbNet}}: {{A Construction}}-Based {{Approach}} to {{Italian Verb Classification}}},
	Abstract = {This paper proposes a new method for Italian verb classification -and a preliminary example of resulting classes- inspired by Levin (1993) and VerbNet (Kipper-Schuler, 2005), yet partially independent from these resources; we achieved such a result by integrating Levin and VerbNet's models of classification with other theoretic frameworks and resources. The classification is rooted in the constructionist framework (Goldberg, 1995; 2006) and is distribution-based. It is also semantically characterized by a link to FrameNet'ssemanticframesto represent the event expressed by a class. However, the new Italian classes maintain the hierarchic ``tree'' structure and monotonic nature of VerbNet's classes, and, where possible, the original names (e.g.: Verbs of Killing, Verbs of Putting, etc.). We therefore propose here a taxonomy compatible with VerbNet but at the same time adapted to Italian syntax and semantics. It also addresses a number of problems intrinsic to the original classifications, such as the role of argument alternations, here regarded simply as epiphenomena, consistently with the constructionist approach.}}

@inproceedings{DBLP:conf/semeval/MilleCBW17,
	Author = {Mille, Simon and Carlini, Roberto and Burga, Alicia and Wanner, Leo},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/conf/semeval/MilleCBW17},
	Booktitle = {Proceedings of the 11th {{International Workshop}} on {{Semantic Evaluation}}, {{SemEval}}@{{ACL}} 2017, {{Vancouver}}, {{Canada}}, {{August}} 3-4, 2017},
	Crossref = {DBLP:conf/semeval/2017},
	Doi = {10.18653/v1/S17-2158},
	Pages = {920--923},
	Title = {{{FORGe}} at {{SemEval}}-2017 {{Task}} 9: {{Deep}} Sentence Generation Based on a Sequence of Graph Transducers},
	Year = {2017},
	Bdsk-Url-1 = {https://dx.doi.org/10.18653/v1/S17-2158}}

@inproceedings{DBLP:conf/nlpke/WenJH08,
	Author = {Wen, Dunwei and Jiang, Shen and He, Yangjian},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/conf/nlpke/WenJH08},
	Booktitle = {Proceedings of the 4th {{International Conference}} on {{Natural Language Processing}} and {{Knowledge Engineering}}, {{NLPKE}} 2008, {{Beijing}}, {{China}}, {{October}} 19-22, 2008},
	Crossref = {DBLP:conf/nlpke/2008},
	Doi = {10.1109/NLPKE.2008.4906769},
	Pages = {1--8},
	Title = {A Question Answering System Based on {{VerbNet}} Frames},
	Year = {2008},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/NLPKE.2008.4906769}}

@article{DanlosPresentationmodelegeneration1983,
	Author = {Danlos, Laurence},
	Doi = {10.7202/602510ar},
	File = {C:\\Users\\MSI\\Zotero\\storage\\DEAT2QVJ\\Danlos - 1983 - Pr{\'e}sentation d'un mod{\`e}le de g{\'e}n{\'e}ration automatique.pdf;C:\\Users\\MSI\\Zotero\\storage\\MUI9JJ5H\\602510ar.html},
	Issn = {0710-0167, 1705-4591},
	Journal = {Revue qu{\'e}b{\'e}coise de linguistique},
	Language = {fr},
	Number = {1},
	Pages = {203--228},
	Title = {{Pr{\'e}sentation d'un mod{\`e}le de g{\'e}n{\'e}ration automatique}},
	Volume = {13},
	Year = {1983},
	Abstract = {An article from Revue qu{\'e}b{\'e}coise de linguistique, on {\'E}rudit.},
	Bdsk-Url-1 = {https://dx.doi.org/10.7202/602510ar}}

@article{CallawayEvaluatingCoverageLarge,
	Author = {Callaway, Charles B and Istituto, ITC-irst},
	File = {C:\\Users\\MSI\\Zotero\\storage\\3RWJRA26\\Callaway and Istituto - Evaluating Coverage for Large Symbolic NLG Grammar.pdf},
	Pages = {6},
	Title = {Evaluating {{Coverage}} for {{Large Symbolic NLG Grammars}}},
	Abstract = {After many successes, statistical approaches that have been popular in the parsing community are now making headway into Natural Language Generation (NLG). These systems are aimed mainly at surface realization, and promise the same advantages that make statistics valuable for parsing: robustness, wide coverage and domain independence. A recent experiment aimed to empirically verify the linguistic coverage for such a statistical surface realization component by generating transformed sentences from the Penn TreeBank corpus. This article presents the empirical results of a similar experiment to evaluate the coverage of a purely symbolic surface realizer. We present the problems facing a symbolic approach on the same task, describe the results of its evaluation, and contrast them with the results of the statistical method to help quantitatively determine the level of coverage currently obtained by NLG surface realizers.}}

@book{ReiterBuildingNaturalLanguage2000,
	Address = {New York, NY, USA},
	Author = {Reiter, Ehud and Dale, Robert},
	Isbn = {978-0-521-62036-9},
	Publisher = {{Cambridge University Press}},
	Title = {Building {{Natural Language Generation Systems}}},
	Year = {2000}}

@phdthesis{LambreyImplementationcollocationspour2017,
	Author = {Lambrey, Florie},
	File = {C:\\Users\\MSI\\Zotero\\storage\\2AKM9PFR\\Lambrey - 2017 - Impl{\'e}mentation des collocations pour la r{\'e}alisatio.pdf;C:\\Users\\MSI\\Zotero\\storage\\BXHESZPY\\18769.html},
	Month = mar,
	School = {Universit{\'e} de Montr{\'e}al},
	Title = {Impl{\'e}mentation Des Collocations Pour La R{\'e}alisation de Texte Multilingue},
	Year = {2017}}
