
@article{MillerWordNetLexicalDatabase1995,
  title = {{{WordNet}}: {{A Lexical Database}} for {{English}}},
  volume = {38},
  issn = {0001-0782},
  doi = {10.1145/219717.219748},
  number = {11},
  journal = {Commun. ACM},
  author = {Miller, George A.},
  month = nov,
  year = {1995},
  pages = {39--41}
}

@phdthesis{SchulerVerbnetBroadcoverageComprehensive2005,
  address = {Philadelphia, PA, USA},
  type = {{{PhD Thesis}}},
  title = {Verbnet: {{A Broad}}-Coverage, {{Comprehensive Verb Lexicon}}},
  school = {University of Pennsylvania},
  author = {Schuler, Karin Kipper},
  year = {2005},
  annote = {AAI3179808}
}

@inproceedings{Shi:2005:PPT:2132047.2132058,
  address = {Mexico City, Mexico},
  series = {CICLing'05},
  title = {Putting {{Pieces Together}}: {{Combining FrameNet}}, {{VerbNet}} and {{WordNet}} for {{Robust Semantic Parsing}}},
  isbn = {3-540-24523-5 978-3-540-24523-0},
  doi = {10.1007/978-3-540-30586-6_9},
  booktitle = {Proceedings of the 6th {{International Conference}} on {{Computational Linguistics}} and {{Intelligent Text Processing}}},
  publisher = {{Springer-Verlag}},
  author = {Shi, Lei and Mihalcea, Rada},
  year = {2005},
  pages = {100--111},
  file = {C:\\Users\\MSI\\Zotero\\storage\\7W3TJ67M\\shi.cicling05.pdf},
  numpages = {12},
  acmid = {2132058}
}

@inproceedings{Grishman:1994:CSB:991886.991931,
  address = {Kyoto, Japan},
  series = {COLING '94},
  title = {Comlex {{Syntax}}: {{Building}} a {{Computational Lexicon}}},
  doi = {10.3115/991886.991931},
  booktitle = {Proceedings of the 15th {{Conference}} on {{Computational Linguistics}} - {{Volume}} 1},
  publisher = {{Association for Computational Linguistics}},
  author = {Grishman, Ralph and Macleod, Catherine and Meyers, Adam},
  year = {1994},
  pages = {268--272},
  file = {C:\\Users\\MSI\\Zotero\\storage\\ZIXFC3Q4\\p268-grishman.pdf},
  numpages = {5},
  acmid = {991931}
}

@inproceedings{Hensman:2004:CCG:1614038.1614047,
  address = {Boston, Massachusetts},
  series = {HLT-SRWS '04},
  title = {Construction of {{Conceptual Graph Representation}} of {{Texts}}},
  booktitle = {Proceedings of the {{Student Research Workshop}} at {{HLT}}-{{NAACL}} 2004},
  publisher = {{Association for Computational Linguistics}},
  author = {Hensman, Svetlana},
  year = {2004},
  pages = {49--54},
  numpages = {6},
  acmid = {1614047}
}

@book{verb-classes.levin.1993,
  title = {English Verb Classes and Alternations : A Preliminary Investigation},
  author = {Levin, Beth},
  editor = {{of Chicago Press}, University},
  year = {1993},
  keywords = {CAT CAT-NLP CAT-VERBNET classes verb},
  biburl = {https://www.bibsonomy.org/bibtex/255ee14790a0bc144b9105ab5258f4b81/huiyangsfsu},
  interhash = {63590b8294dc585bda3a9d19a3a9ff5c},
  intrahash = {55ee14790a0bc144b9105ab5258f4b81}
}

@inproceedings{Novischi:2006:QAL:1220175.1220288,
  address = {Sydney, Australia},
  series = {ACL-44},
  title = {Question {{Answering}} with {{Lexical Chains Propagating Verb Arguments}}},
  doi = {10.3115/1220175.1220288},
  booktitle = {Proceedings of the 21st {{International Conference}} on {{Computational Linguistics}} and the 44th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Novischi, Adrian and Moldovan, Dan},
  year = {2006},
  pages = {897--904},
  file = {C:\\Users\\MSI\\Zotero\\storage\\IHTGE9PD\\2fb69531b03f309ef45bf32b8bac5cc8becd.pdf},
  numpages = {8},
  acmid = {1220288}
}

@article{journals/nle/PalmerDF07,
  title = {Making Fine-Grained and Coarse-Grained Sense Distinctions, Both Manually and Automatically.},
  volume = {13},
  number = {2},
  journal = {Natural Language Engineering},
  author = {Palmer, Martha and Dang, Hoa Trang and Fellbaum, Christiane},
  month = may,
  year = {2009},
  keywords = {dblp},
  pages = {137--163},
  biburl = {https://www.bibsonomy.org/bibtex/2eae9f06d8678fe1aab86c818f59dd935/dblp},
  description = {dblp},
  ee = {http://dx.doi.org/10.1017/S135132490500402X},
  interhash = {b0e1a496ede803d50ea581d5ff26a50b},
  intrahash = {eae9f06d8678fe1aab86c818f59dd935}
}

@inproceedings{Dusek2015TrainingAN,
  title = {Training a {{Natural Language Generator From Unaligned Data}}},
  booktitle = {{{ACL}}},
  author = {Dusek, Ondrej and Jurc{\'\i}cek, Filip},
  year = {2015}
}

@inproceedings{TraumGenerationLexicalConceptual2000,
  address = {Stroudsburg, PA, USA},
  series = {NAACL-ANLP-Interlinguas '00},
  title = {Generation from {{Lexical Conceptual Structures}}},
  doi = {10.3115/1117554.1117561},
  abstract = {This paper describes a system for generating natural language sentences from an interlingual representation, Lexical Conceptual Structure (LCS). This system has been developed as part of a Chinese-English Machine Translation system, however, it promises to be useful for many other MT language pairs. The generation system has also been used in Cross-Language information retrieval research (Levow et al., 2000).},
  booktitle = {Proceedings of the 2000 {{NAACL}}-{{ANLP Workshop}} on {{Applied Interlinguas}}: {{Practical Applications}} of {{Interlingual Approaches}} to {{NLP}} - {{Volume}} 2},
  publisher = {{Association for Computational Linguistics}},
  author = {Traum, David and Habash, Nizar},
  year = {2000},
  pages = {52--59},
  file = {C:\\Users\\MSI\\Zotero\\storage\\9F5TJJFE\\Traum and Habash - 2000 - Generation from Lexical Conceptual Structures.pdf}
}

@article{MoensTemporalOntologyTemporal1988,
  title = {Temporal {{Ontology}} and {{Temporal Reference}}},
  volume = {14},
  issn = {0891-2017},
  abstract = {A semantics of temporal categories in language and a theory of their use in defining the temporal relations between events both require a more complex structure on the domain underlying the meaning representations than is commonly assumed. This paper proposes an ontology based on such notions as causation and consequence, rather than on purely temporal primitives. A central notion in the ontology is that of an elementary event-complex called a "nucleus." A nucleus can be thought of as an association of a goal event, or "culmination," with a "preparatory process" by which it is accomplished, and a "consequent state," which ensues. Natural-language categories like aspects, futurates, adverbials, and when-clauses are argued to change the temporal/aspectual category of propositions under the control of such a nucleic knowledge representation structure. The same concept of a nucleus plays a central role in a theory of temporal reference, and of the semantics of tense, which we follow McCawley, Partee, and Isard in regarding as an anaphoric category. We claim that any manageable formalism for natural-language temporal descriptions will have to embody such an ontology, as will any usable temporal database for knowledge about events which is to be interrogated using natural language.},
  number = {2},
  journal = {Comput. Linguist.},
  author = {Moens, Marc and Steedman, Mark},
  month = jun,
  year = {1988},
  pages = {15--28},
  file = {C:\\Users\\MSI\\Zotero\\storage\\LMRG4VG6\\Moens and Steedman - 1988 - Temporal Ontology and Temporal Reference.pdf}
}

@inproceedings{verbnet.2006,
  title = {Extending {{VerbNet}} with {{Novel Verb Classes}}},
  abstract = {Lexical classifications have proved useful in supporting various natural language processing (NLP) tasks. The largest verb classification for English is Levin's (1993) work which defined groupings of verbs based on syntactic properties. VerbNet (Kipper et al., 2000; Kipper-Schuler, 2005) \textendash{} the largest computational verb lexicon currently available for English \textendash{} provides detailed syntactic-semantic descriptions of Levin classes. While the classes included are extensive enough for some NLP use, they are not comprehensive. Korhonen and Briscoe (2004) have proposed a significant extension of Levin's classification which incorporates 57 novel classes for verbs not covered (comprehensively) by Levin. This paper describes the integration of these classes into VerbNet. The result is the most extensive Levin-style classification for English verbs which can be highly useful for practical applications.},
  booktitle = {Proceedings of the {{Fifth International Conference}} on {{Language Resources}} and {{Evaluation}} -- {{LREC}}'06 ({{http://verbs.colorado.edu/}}~Mpalmer/Projects/Verbnet.Html)},
  author = {Kipper, Karen and Korhonen, Anna and Ryant, Neville and Palmer, Martha},
  year = {2006},
  keywords = {CAT CAT-NLP-verb bk-ngx verbnet},
  biburl = {https://www.bibsonomy.org/bibtex/22b205aaeb7c9c2c6be479db6d48420be/huiyangsfsu},
  interhash = {c4040236f9c42b6de5413352c8030eb0},
  intrahash = {2b205aaeb7c9c2c6be479db6d48420be}
}

@inproceedings{CopestakeACQUILEXLKBrepresentation1992,
  title = {The {{ACQUILEX LKB}}: Representation Issues in Semi-Automatic Acquisition of Large Lexicons},
  shorttitle = {The {{ACQUILEX LKB}}},
  abstract = {We describe the lexical knowledge base sys-  tem (LKB) which has been designed and implemented  as part of the ACQUILEX project x  to allow the representation of multilingual syn-  tactic and semantic information extracted from  machine readable dictionaries (MRDs), in such  a way that it is usable by natural language  processing (NLP) systems. The LKB's lexical  representation language (LRL) augments  typed graph-based unification with default inheritance,  formalised in terms of default unifi-  cation of feature structures. We evaluate how  well the LRL meets the practical requirements  arising from the semi-automatic construction of  a large scale, multilingual lexicon. The system  as described is fully implemented and is being  used to represent substantial amounts of information  automatically extracted from MRDs.},
  booktitle = {Proceedings of the 3rd {{Conference}} on {{Applied Natural Language Processing}} ({{ANLP}}-92},
  author = {Copestake, Ann},
  year = {1992},
  pages = {88--96},
  file = {C:\\Users\\MSI\\Zotero\\storage\\LMMZ52MX\\Copestake - 1992 - The ACQUILEX LKB representation issues in semi-au.pdf;C:\\Users\\MSI\\Zotero\\storage\\U28QB5UR\\summary.html}
}

@article{PustejovskyGenerativeLexicon1991,
  title = {The {{Generative Lexicon}}},
  volume = {17},
  issn = {0891-2017},
  abstract = {In this paper, I will discuss four major topics relating to current research in lexical semantics: methodology, descriptive coverage, adequacy of the representation, and the computational usefulness of representations. In addressing these issues, I will discuss what I think are some of the central problems facing the lexical semantics community, and suggest ways of best approaching these issues. Then, I will provide a method for the decomposition of lexical categories and outline a theory of lexical semantics embodying a notion of cocompositionality and type coercion, as well as several levels of semantic description, where the semantic load is spread more evenly throughout the lexicon. I argue that lexical decomposition is possible if it is performed generatively. Rather than assuming a fixed set of primitives. I will assume a fixed number of generative devices that can be seen as constructing semantic expressions. I develop a theory of Qualia Structure, a representation language for lexical items, which renders much lexical ambiguity in the lexicon unnecessary, while still explaining the systematic polysemy that words carry. Finally, I discuss how individual lexical structures can be integrated into the larger lexical knowledge base through a theory of lexical inheritance. This provides us with the necessary principles of global organization for the lexicon, enabling us to fully integrate our natural language lexicon into a conceptual whole.},
  number = {4},
  journal = {Comput. Linguist.},
  author = {Pustejovsky, James},
  month = dec,
  year = {1991},
  pages = {409--441},
  file = {C:\\Users\\MSI\\Zotero\\storage\\NZQXS24K\\Pustejovsky - 1991 - The Generative Lexicon.pdf}
}

@article{SagotLeffffreelyavailable2010,
  title = {The {{Lefff}}, a Freely Available and Large-Coverage Morphological and Syntactic Lexicon for {{French}}},
  abstract = {In this paper, we introduce the Lefff , a freely available, accurate and large-coverage morphological and syntactic lexicon for French, used in many NLP tools such as large-coverage parsers. We first describe Alexina, the lexical framework in which the Lefff is developed as well as the linguistic notions and formalisms it is based on. Next, we describe the various sources of lexical data we used for building the Lefff , in particular semi-automatic lexical development techniques and conversion and merging of existing resources. Finally, we illustrate the coverage and precision of the resource by comparing it with other resources and by assessing its impact in various NLP tools.},
  journal = {7th international conference on Language Resources and Evaluation (LREC 2010)},
  author = {Sagot, Beno{\^\i}t},
  month = may,
  year = {2010}
}

@inproceedings{KipperClassBasedConstructionVerb2000,
  title = {Class-{{Based Construction}} of a {{Verb Lexicon}}},
  isbn = {978-0-262-51112-4},
  booktitle = {Proceedings of the {{Seventeenth National Conference}} on {{Artificial Intelligence}} and {{Twelfth Conference}} on {{Innovative Applications}} of {{Artificial Intelligence}}},
  publisher = {{AAAI Press}},
  author = {Kipper, Karin and Dang, Hoa Trang and Palmer, Martha},
  year = {2000},
  pages = {691--696}
}

@inproceedings{BakerBerkeleyFrameNetProject1998,
  address = {Stroudsburg, PA, USA},
  series = {COLING '98},
  title = {The {{Berkeley FrameNet Project}}},
  doi = {10.3115/980451.980860},
  abstract = {FrameNet is a three-year NSF-supported project in corpus-based computational lexicography, now in its second year (NSF IRI-9618838, "Tools for Lexicon Building"). The project's key features are (a) a commitment to corpus evidence for semantic and syntactic generalizations, and (b) the representation of the valences of its target words (mostly nouns, adjectives, and verbs) in which the semantic portion makes use of frame semantics. The resulting database will contain (a) descriptions of the semantic frames underlying the meanings of the words described, and (b) the valence representation (semantic and syntactic) of several thousand words and phrases, each accompanied by (c) a representative collection of annotated corpus attestations, which jointly exemplify the observed linkings between "frame elements" and their syntactic realizations (e.g. grammatical function, phrase type, and other syntactic traits). This report will present the project's goals and workflow, and information about the computational tools that have been adapted or created in-house for this work.},
  booktitle = {Proceedings of the 17th {{International Conference}} on {{Computational Linguistics}} - {{Volume}} 1},
  publisher = {{Association for Computational Linguistics}},
  author = {Baker, Collin F. and Fillmore, Charles J. and Lowe, John B.},
  year = {1998},
  pages = {86--90},
  file = {C:\\Users\\MSI\\Zotero\\storage\\4ZHIGPBN\\Baker et al. - 1998 - The Berkeley FrameNet Project.pdf}
}

@inproceedings{lareau18,
  address = {Miyazaki},
  title = {{{GenDR}}: {{A Generic Deep Realizer}} with {{Complex Lexicalization}}},
  abstract = {We present a generic deep realizer called GenDR, which takes as input an abstract semantic representation of predicate-argument relations, and produces corresponding syntactic dependency structures in English, French, Lithuanian and Persian, with the possibility to fairly easily add more languages. It is generic in that it is designed to operate across a wide range of languages and applications, given the appropriate lexical resources. The focus is on the lexicalization of multiword expressions, with built-in rules to handle thousands of different cross-linguistic patterns of collocations (intensifiers, support verbs, causatives, etc.), and on rich paraphrasing, with the ability to produce many syntactically and lexically varied outputs from the same input. The system runs on a graph transducer, MATE (Bohnet et al., 2000; Bohnet and Wanner, 2010), and its grammar design is directly borrowed from MARQUIS (Lareau and Wanner, 2007; Wanner et al., 2009; Wanner et al., 2010), which we have trimmed down to its core and built upon. The grammar and demo dictionaries are distributed under a CC-BY-SA licence (http://bit.ly/2x8xGVO). This paper explains the design of the grammar, how multiword expressions (especially collocations) are dealt with, and how the syntactic structure is derived from the relative communicative salience of the meanings involved.},
  booktitle = {Proceedings of 11th Edition of the {{Language Resources}} and {{Evaluation Conference}} ({{LREC}})},
  author = {Lareau, Fran{\c c}ois and Lambrey, Florie and Dubinskaite, Ieva and Galarreta-Piquette, Daniel and Nejat, Maryam},
  year = {2018},
  file = {C:\\Users\\MSI\\Zotero\\storage\\BDRQHQ6H\\Lareau et al. - GenDR A Generic Deep Realizer with Complex Lexica.pdf}
}

@article{cawsey00,
  title = {The {{Evaluation}} of a {{Personalised Health Information System}} for {{Patients}} with {{Cancer}}},
  volume = {10},
  number = {1},
  journal = {User Modeling and User-Adapted Interaction},
  author = {Cawsey, A.J. and Jones, R.B. and Pearson, J.},
  year = {2000},
  pages = {47--72}
}

@inproceedings{callaway03,
  address = {San Francisco},
  title = {Evaluating Coverage for Large Symbolic {{NLG}} Grammars},
  booktitle = {{{IJCAI}}'03: {{Proceedings}} of the 18th International Joint Conference on {{Artificial}} Intelligence},
  publisher = {{Morgan Kaufmann Publishers Inc.}},
  author = {Callaway, Charles B.},
  year = {2003},
  pages = {811--816}
}

@article{ReiterInvestigationValidityMetrics2009,
  title = {An {{Investigation}} into the {{Validity}} of {{Some Metrics}} for {{Automatically Evaluating Natural Language Generation Systems}}},
  volume = {35},
  issn = {0891-2017},
  doi = {10.1162/coli.2009.35.4.35405},
  abstract = {There is growing interest in using automatically computed corpus-based evaluation metrics to evaluate Natural Language Generation (NLG) systems, because these are often considerably cheaper than the human-based evaluations which have traditionally been used in NLG. We review previous work on NLG evaluation and on validation of automatic metrics in NLP, and then present the results of two studies of how well some metrics which are popular in other areas of NLP (notably BLEU and ROUGE) correlate with human judgments in the domain of computer-generated weather forecasts. Our results suggest that, at least in this domain, metrics may provide a useful measure of language quality, although the evidence for this is not as strong as we would ideally like to see; however, they do not provide a useful measure of content quality. We also discuss a number of caveats which must be kept in mind when interpreting this and other validation studies.},
  number = {4},
  journal = {Computational Linguistics},
  author = {Reiter, Ehud and Belz, Anja},
  month = oct,
  year = {2009},
  pages = {529--558},
  file = {C:\\Users\\MSI\\Zotero\\storage\\762E23A4\\Reiter and Belz - 2009 - An Investigation into the Validity of Some Metrics.pdf;C:\\Users\\MSI\\Zotero\\storage\\IX64S23Z\\coli.2009.35.4.html}
}

@article{Vicentegeneracionlenguajenatural2015,
  title = {La Generaci{\'o}n de Lenguaje Natural: An{\'a}lisis Del Estado Actual},
  copyright = {\textcopyright{} Computaci{\'o}n y Sistemas},
  issn = {2007-9737},
  shorttitle = {La Generaci{\'o}n de Lenguaje Natural},
  doi = {10.13053/CyS-19-4-2196},
  abstract = {El ser humano se comunica y expresa a trav{\'e}s del lenguaje. Para conseguirlo, ha de desarrollar una serie de habilidades de alto nivel cognitivo cuya complejidad se pone de manifiesto en la tarea de automatizar el proceso, tanto cuando se trata de producir lenguaje como de interpretarlo. Cuando la acci{\'o}n comunicativa ocurre entre una persona y un ordenador y {\'e}ste {\'u}ltimo es el destinatario de la acci{\'o}n, se emplean lenguajes computacionales que, como norma general, est{\'a}n sujetos a un conjunto de reglas fuertemente tipadas, acotadas y sin ambig{\"u}edad. Sin embargo, cuando el sentido de la comunicaci{\'o}n es el contrario y la m{\'a}quina ha de transmitir informaci{\'o}n a la persona, si el mensaje se quiere transmitir en lenguaje natural, el procedimiento para generarlo debe lidiar con la flexibilidad y la ambig{\"u}edad que lo caracterizan, dando lugar a una tarea de alto nivel de complejidad. Para que las m{\'a}quinas sean capaces de manejar el lenguaje humano se hacen necesarias t{\'e}cnicas de Ling{\"u}{\'\i}stica Computacional. Dentro de esta disciplina, el campo que se encarga de crear textos en lenguaje natural se denomina Generaci{\'o}n de Lenguaje Natural (GLN). En este art{\'\i}culo se va a hacer un recorrido exhaustivo de este campo. Se describen las fases en las que se suelen descomponer los sistemas de GLN junto a las t{\'e}cnicas que se aplican y se analiza con detalle la situaci{\'o}n actual de esta {\'a}rea de investigaci{\'o}n y su problem{\'a}tica, as{\'\i} como los recursos m{\'a}s relevantes y las t{\'e}cnicas que se est{\'a}n empleando para evaluar la calidad de los sistemas.},
  author = {Vicente, Marta and Barros, Cristina and Peregrino Torregrosa, Fernando and Agull{\'o} Antol{\'\i}n, Francisco and Lloret, Elena},
  year = {2015},
  file = {C:\\Users\\MSI\\Zotero\\storage\\BJDWKIRE\\Vicente et al. - 2015 - La generación de lenguaje natural análisis del es.pdf;C:\\Users\\MSI\\Zotero\\storage\\5U762MLS\\52480.html}
}

@book{Fellbaum1998,
  address = {Cambridge, MA},
  series = {Language, Speech, and Communication},
  title = {{{WordNet}}: {{An Electronic Lexical Database}}},
  isbn = {978-0-262-06197-1},
  abstract = {WordNet, an electronic lexical database, is considered to be the most important resource available to researchers in computational linguistics, text analysis, and many related areas. Its design is inspired by current psycholinguistic and computational theories of human lexical memory. English nouns, verbs, adjectives, and adverbs are organized into synonym sets, each representing one underlying lexicalized concept. Different relations link the synonym sets. The purpose of this volume is twofold. First, it discusses the design of WordNet and the theoretical motivations behind it. Second, it provides a survey of representative applications, including word sense identification, information retrieval, selectional preferences of verbs, and lexical chains.},
  publisher = {{MIT Press}},
  editor = {Fellbaum, Christiane},
  year = {1998},
  keywords = {01821 101 mitpress book shelf ai language processing ontology lexicon},
  file = {C:\\Users\\MSI\\Zotero\\storage\\LVM4UDRS\\5papers.pdf},
  biburl = {https://www.bibsonomy.org/bibtex/28472b4f9d7f2bfc4a97ffd4a023facc6/flint63},
  interhash = {42daa1681607dd1d3f3234c605d84ec3},
  intrahash = {8472b4f9d7f2bfc4a97ffd4a023facc6},
  username = {flint63}
}

@article{ResearchGroupLexicalizedTreeAdjoining2001,
  title = {A {{Lexicalized Tree Adjoining Grammar}} for {{English}}},
  journal = {IRCS Technical Reports Series},
  author = {Research Group, The XTAG},
  month = feb,
  year = {2001},
  file = {C:\\Users\\MSI\\Zotero\\storage\\NAV729BR\\8.html}
}

@inproceedings{W04-3326,
  address = {Vancouver, Canada},
  title = {Assigning {{XTAG Trees}} to {{VerbNet}}},
  booktitle = {Proceedings of the 7th {{International Workshop}} on {{Tree Adjoining Grammar}} and {{Related Formalisms}}},
  author = {Ryant, Neville and Kipper, Karin},
  year = {2004},
  pages = {194--198},
  file = {C:\\Users\\MSI\\Zotero\\storage\\G9JYLLQZ\\W04-3326.pdf}
}

@article{DorrUseLexicalSemantics1992,
  title = {The {{Use}} of {{Lexical Semantics}} in {{Interlingual Machine Translation}}},
  volume = {7},
  issn = {0922-6567},
  abstract = {This paper describes the lexical-semantic basis for UNITRAN, an implemented scheme for translating Spanish, English, and German bidirectionally. Two claims made here are that the current representation handles many distinctions (or "divergences") across languages without recourse to language-specific rules and that the lexical-semantic framework provides the basis for a systematic mapping between the interlingua and the syntactic structure. The representation adopted is an extended version of "lexical conceptual structure" which is suitable to the task of translating between divergent structures for two reasons: (1) it provides an abstraction of language-independent properties from structural idiosyncrasies; and (2) it is compositional in nature. The lexical-semantic approach ad- dresses the divergence problem by using a linguistically grounded mapping that has access to parameter settings in the lexicon. We will examine a number of relevant issues including the problem of defining primitives, the issue of interlinguality, the cross-linguistic cover- age of the system, and the mapping between the syntactic structure and the interlingua. A detailed example of lexical-semantic composition will be presented.},
  number = {3},
  journal = {Machine Translation},
  author = {Dorr, Bonnie J.},
  year = {1992},
  pages = {135--193},
  file = {C:\\Users\\MSI\\Zotero\\storage\\GLECJMX7\\Dorr - 1992 - The Use of Lexical Semantics in Interlingual Machi.pdf}
}

@article{MacLeod1997,
  title = {{{COMLEX Syntax}} -- {{A Large Syntactic Dictionary}} for {{Natural Language Processing}}},
  volume = {31},
  issn = {1572-8412},
  doi = {10.1023/A:1001142417369},
  abstract = {This article is a detailed account of COMLEX Syntax, an on-line syntactic dictionary of English, developed by the Proteus Project at New York University under the auspices of the Linguistics Data Consortium. This lexicon was intended to be used for a variety of tasks in natural language processing by computer and as such has very detailed classes with a large number of syntactic features and complements for the major parts of speech and is, as far as possible, theory neutral. The dictionary was entered by hand with reference to hard copy dictionaries, an on-line concordance and native speakers`intuition. Thus it is without prior encumbrances and can be used for both pure research and commercial purposes.},
  number = {6},
  journal = {Computers and the Humanities},
  author = {MacLeod, Catherine and Grishman, Ralph and Meyers, Adam},
  month = nov,
  year = {1997},
  pages = {459--481},
  file = {C:\\Users\\MSI\\Zotero\\storage\\DR2LQI6B\\10.1023A1001142417369.pdf},
  day = {01}
}

@inproceedings{McFateExpandingVerbCoverage2010,
  address = {Stroudsburg, PA, USA},
  series = {ACLstudent '10},
  title = {Expanding {{Verb Coverage}} in {{Cyc}} with {{VerbNet}}},
  abstract = {A robust dictionary of semantic frames is an essential element of natural language understanding systems that use ontologies. However, creating lexical resources that accurately capture semantic representations en masse is a persistent problem. Where the sheer amount of content makes hand creation inefficient, computerized approaches often suffer from over generality and difficulty with sense disambiguation. This paper describes a semi-automatic method to create verb semantic frames in the Cyc ontology by converting the information contained in VerbNet into a Cyc usable format. This method captures the differences in meaning between types of verbs, and uses existing connections between WordNet, VerbNet, and Cyc to specify distinctions between individual verbs when available. This method provides 27,909 frames to OpenCyc which currently has none and can be used to extend ResearchCyc as well. We show that these frames lead to a 20\% increase in sample sentences parsed over the Research Cyc verb lexicon.},
  booktitle = {Proceedings of the {{ACL}} 2010 {{Student Research Workshop}}},
  publisher = {{Association for Computational Linguistics}},
  author = {McFate, Clifton J.},
  year = {2010},
  pages = {61--66},
  file = {C:\\Users\\MSI\\Zotero\\storage\\XTIWF5G7\\McFate - 2010 - Expanding Verb Coverage in Cyc with VerbNet.pdf}
}

@inproceedings{HensmanAutomaticallyBuildingConceptual2004,
  address = {Las Vegas, Nevada, USA},
  series = {ISICT '04},
  title = {Automatically {{Building Conceptual Graphs Using VerbNet}} and {{WordNet}}},
  isbn = {978-1-59593-170-2},
  abstract = {With the huge number of documents becoming available in electronic form, finding the right information in a large corpus is becoming an increasingly important and difficult task. We believe that semantic processing is required for accurate information retrieval.This paper describes a framework for the automatic creation of semantic markup and its insertion into XML documents. The availability of such semantic annotation would be of great help when the documents are queried, and, in particular, would facilitate the application of inference techniques, therefore allowing the system to deduce information not explicitly mentioned in the text.},
  booktitle = {Proceedings of the 2004 {{International Symposium}} on {{Information}} and {{Communication Technologies}}},
  publisher = {{Trinity College Dublin}},
  author = {Hensman, Svetlana and Dunnion, John},
  year = {2004},
  pages = {115--120},
  file = {C:\\Users\\MSI\\Zotero\\storage\\Y8BY3HAP\\Hensman and Dunnion - 2004 - Automatically Building Conceptual Graphs Using Ver.pdf}
}

@inproceedings{BrownVerbNetClassAssignment2011,
  address = {Stroudsburg, PA, USA},
  series = {IWCS '11},
  title = {{{VerbNet Class Assignment As}} a {{WSD Task}}},
  abstract = {The VerbNet lexical resource classifies English verbs based on semantic and syntactic regularities and has been used for numerous NLP tasks, most notably, semantic role labeling. Since, in addition to thematic roles, it also provides semantic predicates, it can serve as a foundation for further inferencing. Many verbs belong to multiple VerbNet classes, with each class membership corresponding roughly to a different sense of the verb. A VerbNet token classifier is essential for current applications using the resource and could provide the basis for a deep semantic parsing system, one that made full use of VerbNet's extensive syntactic and semantic information. We describe our VerbNet classifier, which uses rich syntactic and semantic features to label verb instances with their appropriate VerbNet class. It achieves an accuracy of 88.67\% with multiclass verbs, which is a 49\% error reduction over the most frequent class baseline.},
  booktitle = {Proceedings of the {{Ninth International Conference}} on {{Computational Semantics}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Brown, Susan Windisch and Dligach, Dmitriy and Palmer, Martha},
  year = {2011},
  pages = {85--94},
  file = {C:\\Users\\MSI\\Zotero\\storage\\749LVGDU\\Brown et al. - 2011 - VerbNet Class Assignment As a WSD Task.pdf}
}

@inproceedings{Korhonenlargesubcategorizationlexicon2006,
  title = {A Large Subcategorization Lexicon for Natural Language Processing Applications},
  abstract = {We introduce a large computational subcategorization lexicon which includes subcategorization frame (SCF) and frequency information for 6,397 English verbs. This extensive lexicon was acquired automatically from five corpora and the Web using the current version of the comprehensive subcategorization acquisition system of Briscoe and Carroll (1997). The lexicon is provided freely for research use, along with a script which can be used to filter and build sub-lexicons suited for different natural language processing (NLP) purposes. Documentation is also provided which explains each sub-lexicon option and evaluates its accuracy. 1.},
  booktitle = {In {{Proceedings}} of {{LREC}}},
  author = {Korhonen, Anna and Krymolowski, Yuval and Briscoe, Ted},
  year = {2006},
  file = {C:\\Users\\MSI\\Zotero\\storage\\QQHCTZ8G\\Korhonen et al. - 2006 - A large subcategorization lexicon for natural lang.pdf}
}

@inproceedings{MessiantSubcategorizationAcquisitionSystem2008,
  address = {Stroudsburg, PA, USA},
  series = {HLT-SRWS '08},
  title = {A {{Subcategorization Acquisition System}} for {{French Verbs}}},
  abstract = {This paper presents a system capable of automatically acquiring subcategorization frames (SCFs) for French verbs from the analysis of large corpora. We applied the system to a large newspaper corpus (consisting of 10 years of the French newspaper 'Le Monde') and acquired subcategorization information for 3267 verbs. The system learned 286 SCF types for these verbs. From the analysis of 25 representative verbs, we obtained 0.82 precision, 0.59 recall and 0.69 F-measure. These results are comparable with those reported in recent related work.},
  booktitle = {Proceedings of the 46th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} on {{Human Language Technologies}}: {{Student Research Workshop}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Messiant, C{\'e}dric},
  year = {2008},
  pages = {55--60},
  file = {C:\\Users\\MSI\\Zotero\\storage\\6TMRWYXW\\Messiant - 2008 - A Subcategorization Acquisition System for French .pdf}
}

@article{asmussen2005a,
  title = {Valency Information for Dictionaries and {{NLP}} Lexicons},
  language = {English},
  journal = {Papers in Computational Lexicography},
  author = {Asmussen, J{\o}rg and {\O}rsnes, Bjarne},
  editor = {{Kiefer, F., Kiss, G., Pajzs, J{\'u}lia}},
  year = {2005}
}

@inproceedings{DoranXTAGSystemWide1994,
  address = {Stroudsburg, PA, USA},
  series = {COLING '94},
  title = {{{XTAG System}}: {{A Wide Coverage Grammar}} for {{English}}},
  shorttitle = {{{XTAG System}}},
  doi = {10.3115/991250.991297},
  abstract = {This paper present the XTAG system, a grammar development tool based on the Tree Adjoining Grammar (TAG) formalism that includes a wide-coverage syntactic grammar for English. The various components of the system are discussed and preliminary evaluation results from the parsing of various corpora are given. Results from the comparison of XTAG against the IBM statistical parser and the Alvey Natural Language Tool parser are also given.},
  booktitle = {Proceedings of the 15th {{Conference}} on {{Computational Linguistics}} - {{Volume}} 2},
  publisher = {{Association for Computational Linguistics}},
  author = {Doran, Christy and Egedi, Dania and Hockey, Beth Ann and Srinivas, B. and Zaidel, Martin},
  year = {1994},
  pages = {922--928},
  file = {C:\\Users\\MSI\\Zotero\\storage\\MJAKTU9D\\Doran et al. - 1994 - XTAG System A Wide Coverage Grammar for English.pdf}
}

@techreport{xtag-2001,
  title = {A {{Lexicalized Tree Adjoining Grammar}} for {{English}}},
  number = {IRCS-01-03},
  institution = {{IRCS, University of Pennsylvania}},
  author = {{XTAG Research Group}},
  year = {2001},
  keywords = {grammar linguistic},
  biburl = {http://sandbox.academic-puma.de/bibtex/24e57db5127da28382c02956a2a07a334/alistair},
  interhash = {bb5698d870802b339d0d32f79e3498c1},
  intrahash = {4e57db5127da28382c02956a2a07a334},
  topics = {area.analysis}
}

@article{citeulike:6058251,
  title = {English {{Verbs}} as a {{Semantic Net}}},
  volume = {3},
  doi = {10.1093/ijl/3.4.278},
  abstract = {This paper describes the semantic network of English verbs in WordNet. The semantic relations used to build networks of nouns and adjectives cannot be applied without modification, but have to be adapted to fit the semantics of verbs, which differ substantially from those of the other lexical categories. The nature of these relations is discussed, as is their distribution throughout different semantic groups of verbs, which determines certain idiosyneratic patterns of lexicalization. In addition, four variants of lexical entailment are distinguished, which interact in systematic ways with the semantic relations. Finally, the lexical properties of the different verb groups are outlined.},
  number = {4},
  journal = {International Journal of Lexicography},
  author = {Fellbaum, Christiane},
  month = dec,
  year = {1990},
  keywords = {ijl,lexicography},
  pages = {278--301},
  biburl = {https://www.bibsonomy.org/bibtex/21b15f18548f5ad117f7564b25c04de51/baisemain},
  citeulike-article-id = {6058251},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/ijl/3.4.278},
  citeulike-linkout-1 = {http://ijl.oxfordjournals.org/content/3/4/278.abstract},
  citeulike-linkout-2 = {http://ijl.oxfordjournals.org/content/3/4/278.full.pdf},
  day = {21},
  interhash = {0cd3a505c3964ed7deae5e5293ebdde2},
  intrahash = {1b15f18548f5ad117f7564b25c04de51},
  posted-at = {2011-04-28 20:07:59},
  priority = {2}
}

@inproceedings{AyanGeneratingParsingLexicon2002a,
  title = {Generating {{A Parsing Lexicon}} from an {{LCS}}-{{Based Lexicon}}},
  abstract = {This paper describes a technique for generating parsing lexicons for a principle-based parser (Minipar). Our approach maps lexical entries in a large LCS-based repository of semantically classified verbs to their corresponding syntactic patterns. A by-product of this mapping is a lexicon that is directly usable in the Minipar system. We evaluate the accuracy and coverage of this lexicon using LDOCE syntactic codes as a gold standard. We show that this lexicon is comparable to the hand-generated Minipar lexicon (i.e., similar recall and precision values). In a later experiment, we automate the process of mapping between the LCS-based repository and syntactic patterns. The advantage of automating the process is that the same technique can be applied directly to lexicons we have for other languages, for example, Arabic, Chinese, and Spanish. 1.},
  booktitle = {In: {{Proceedings}} of the {{LREC}}-2002 {{Workshop}} on {{Linguistic Knowledge Acquisition}} and {{Representation}}, {{Las Palmas}}, {{Canary Islands}}},
  author = {Ayan, Necip Faz{\i}l and Dorr, Bonnie J.},
  year = {2002},
  pages = {4352},
  file = {C:\\Users\\MSI\\Zotero\\storage\\HSIMCWCE\\Ayan and Dorr - 2002 - Generating A Parsing Lexicon from an LCS-Based Lex.pdf}
}

@inproceedings{MESSIANT08.142,
  address = {Marrakech, Morocco},
  title = {{{LexSchem}}: A {{Large Subcategorization Lexicon}} for {{French Verbs}}},
  isbn = {2-9517408-4-0},
  booktitle = {Proceedings of the {{Sixth International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}'08)},
  publisher = {{European Language Resources Association (ELRA)}},
  author = {C{\'e}dric Messiant, Thierry Poibeau and Korhonen, Anna},
  editor = {{Nicoletta Calzolari (Conference Chair), Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, Daniel Tapias}},
  month = may,
  year = {2008},
  note = {http://www.lrec-conf.org/proceedings/lrec2008/}
}

@inproceedings{PROISL10.62,
  address = {Valletta, Malta},
  title = {Using {{High}}-{{Quality Resources}} in {{NLP}}: {{The Valency Dictionary}} of {{English}} as a {{Resource}} for {{Left}}-{{Associative Grammars}}},
  isbn = {2-9517408-6-7},
  booktitle = {Proceedings of the {{Seventh International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}'10)},
  publisher = {{European Language Resources Association (ELRA)}},
  author = {Proisl, Thomas and Kabashi, Besim},
  editor = {Chair), Nicoletta Calzolari (Conference and Choukri, Khalid and Maegaard, Bente and Mariani, Joseph and Odijk, Jan and Piperidis, Stelios and Rosner, Mike and Tapias, Daniel},
  month = may,
  year = {2010}
}

@inproceedings{BriscoeSecondReleaseRASP2006,
  address = {Stroudsburg, PA, USA},
  series = {COLING-ACL '06},
  title = {The {{Second Release}} of the {{RASP System}}},
  doi = {10.3115/1225403.1225423},
  abstract = {We describe the new release of the RASP (robust accurate statistical parsing) system, designed for syntactic annotation of free text. The new version includes a revised and more semantically-motivated output representation, an enhanced grammar and part-of-speech tagger lexicon, and a more flexible and semi-supervised training method for the structural parse ranking model. We evaluate the released version on the WSJ using a relational evaluation scheme, and describe how the new release allows users to enhance performance using (in-domain) lexical information.},
  booktitle = {Proceedings of the {{COLING}}/{{ACL}} on {{Interactive Presentation Sessions}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Briscoe, Ted and Carroll, John and Watson, Rebecca},
  year = {2006},
  pages = {77--80},
  file = {C:\\Users\\MSI\\Zotero\\storage\\JT6XELXG\\Briscoe et al. - 2006 - The Second Release of the RASP System.pdf}
}

@inproceedings{verbalex,
  title = {Verbalex \textendash{} New Comprehensive Lexicon of Verb Valencies for Czech},
  booktitle = {In {{Proceedings}} of the {{Slovko Conference}}},
  author = {Hlav{\'a}{\v c}kov{\'a}, Dana},
  year = {2005}
}

@inproceedings{AbendSupervisedAlgorithmVerb2008,
  address = {Stroudsburg, PA, USA},
  series = {COLING '08},
  title = {A {{Supervised Algorithm}} for {{Verb Disambiguation}} into {{VerbNet Classes}}},
  isbn = {978-1-905593-44-6},
  abstract = {VerbNet (VN) is a major large-scale English verb lexicon. Mapping verb instances to their VN classes has been proven useful for several NLP tasks. However, verbs are polysemous with respect to their VN classes. We introduce a novel supervised learning model for mapping verb instances to VN classes, using rich syntactic features and class membership constraints. We evaluate the algorithm in both in-domain and corpus adaptation scenarios. In both cases, we use the manually tagged Semlink WSJ corpus as training data. For indomain (testing on Semlink WSJ data), we achieve 95.9\% accuracy, 35.1\% error reduction (ER) over a strong baseline. For adaptation, we test on the GENIA corpus and achieve 72.4\% accuracy with 10.7\% ER. This is the first large-scale experimentation with automatic algorithms for this task.},
  booktitle = {Proceedings of the {{22Nd International Conference}} on {{Computational Linguistics}} - {{Volume}} 1},
  publisher = {{Association for Computational Linguistics}},
  author = {Abend, Omri and Reichart, Roi and Rappoport, Ari},
  year = {2008},
  pages = {9--16},
  file = {C:\\Users\\MSI\\Zotero\\storage\\PRCSK2Q5\\Abend et al. - 2008 - A Supervised Algorithm for Verb Disambiguation int.pdf}
}

@inproceedings{DBLP:conf/acl/KlebanovLGSF16,
  title = {Semantic Classifications for Detection of Verb Metaphors},
  booktitle = {Proceedings of the 54th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}, {{ACL}} 2016, {{August}} 7-12, 2016, {{Berlin}}, {{Germany}}, {{Volume}} 2: {{Short Papers}}},
  author = {Klebanov, Beata Beigman and Leong, Chee Wee and Guti{\'e}rrez, E. Dario and Shutova, Ekaterina and Flor, Michael},
  year = {2016},
  crossref = {DBLP:conf/acl/2016-2},
  biburl = {https://dblp.org/rec/bib/conf/acl/KlebanovLGSF16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{DBLP:conf/acl/2016-2,
  title = {Proceedings of the 54th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}, {{ACL}} 2016, {{August}} 7-12, 2016, {{Berlin}}, {{Germany}}, {{Volume}} 2: {{Short Papers}}},
  isbn = {978-1-945626-01-2},
  publisher = {{The Association for Computer Linguistics}},
  year = {2016},
  biburl = {https://dblp.org/rec/bib/conf/acl/2016-2},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DusekSequencetoSequenceGenerationSpoken2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1606.05491},
  primaryClass = {cs},
  title = {Sequence-to-{{Sequence Generation}} for {{Spoken Dialogue}} via {{Deep Syntax Trees}} and {{Strings}}},
  doi = {10.18653/v1/P16-2008},
  abstract = {We present a natural language generator based on the sequence-to-sequence approach that can be trained to produce natural language strings as well as deep syntax dependency trees from input dialogue acts, and we use it to directly compare two-step generation with separate sentence planning and surface realization stages to a joint, one-step approach. We were able to train both setups successfully using very little training data. The joint setup offers better performance, surpassing state-of-the-art with regards to n-gram-based scores while providing more relevant outputs.},
  journal = {arXiv:1606.05491 [cs]},
  author = {Du{\v s}ek, Ond{\v r}ej and Jur{\v c}{\'\i}{\v c}ek, Filip},
  year = {2016},
  keywords = {Computer Science - Computation and Language,I.2.7},
  pages = {45--51},
  file = {C:\\Users\\MSI\\Zotero\\storage\\P6GV3NIF\\Dušek and Jurčíček - 2016 - Sequence-to-Sequence Generation for Spoken Dialogu.pdf;C:\\Users\\MSI\\Zotero\\storage\\R48PCS3J\\1606.html},
  annote = {Comment: Accepted as a short paper for ACL 2016}
}

@phdthesis{PfeilAlgorithmsResourcesScalable2016,
  title = {Algorithms and {{Resources}} for {{Scalable Natural Language Generation}}},
  school = {Case Western Reserve University},
  author = {Pfeil, Jonathan W.},
  year = {2016},
  file = {C:\\Users\\MSI\\Zotero\\storage\\9FET5SSM\\Pfeil - 2016 - Algorithms and Resources for Scalable Natural Lang.pdf;C:\\Users\\MSI\\Zotero\\storage\\ZM4XXJAS\\pg_10.html}
}

@inproceedings{GalanisGeneratingMultilingualDescriptions2007,
  address = {Stroudsburg, PA, USA},
  series = {ENLG '07},
  title = {Generating {{Multilingual Descriptions}} from {{Linguistically Annotated OWL Ontologies}}: {{The NaturalOWL System}}},
  shorttitle = {Generating {{Multilingual Descriptions}} from {{Linguistically Annotated OWL Ontologies}}},
  abstract = {We introduce NaturalOWL, an open-source multilingual natural language generator that produces descriptions of instances and classes, starting from a linguistically annotated ontology. The generator is heavily based on ideas from ILEX and M-PIRO, but it is in many ways simpler and it provides full support for OWL DL ontologies with RDF linguistic annotations. NaturalOWL is written in Java, and it is supported by M-PIRO's authoring tool, as well as an alternative plug-in for the Prot{\'e}g{\'e} ontology editor.},
  booktitle = {Proceedings of the {{Eleventh European Workshop}} on {{Natural Language Generation}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Galanis, Dimitrios and Androutsopoulos, Ion},
  year = {2007},
  pages = {143--146},
  file = {C:\\Users\\MSI\\Zotero\\storage\\GHPWRVNT\\Galanis and Androutsopoulos - 2007 - Generating Multilingual Descriptions from Linguist.pdf}
}

@inproceedings{W05-1602,
  title = {Interactive {{Authoring}} of {{Logical Forms}} for {{Multilingual Generation}}},
  booktitle = {Proceedings of the {{Tenth European Workshop}} on {{Natural Language Generation}} ({{ENLG}}-05)},
  author = {Biller, Ofer and Elhadad, Michael and Netzer, Yael},
  year = {2005},
  file = {C:\\Users\\MSI\\Zotero\\storage\\5SMAS7UE\\W05-1602.pdf}
}

@incollection{fillmore:case,
  address = {New York},
  title = {The {{Case}} for {{Case}}},
  booktitle = {Universals in {{Linguistic Theory}}},
  publisher = {{Holt, Rinehart and Winston}},
  author = {Fillmore, Charles J.},
  editor = {Bach, Emmon and Harms, Robert T.},
  year = {1968},
  keywords = {nn},
  pages = {0--88},
  biburl = {https://www.bibsonomy.org/bibtex/2bec94321ea706cd7b383ca9287413139/idsia},
  citeulike-article-id = {2376632},
  interhash = {103bf01751708ebaeb99980e6fa368b8},
  intrahash = {bec94321ea706cd7b383ca9287413139},
  priority = {2}
}

@book{Jackendoff1972-JACSII-2,
  title = {Semantic {{Interpretation}} in {{Generative Grammar}}},
  publisher = {{Cambridge: Mass., Mit Press}},
  author = {Jackendoff, Ray},
  year = {1972}
}

@article{PalmerPropositionBankAnnotated2005,
  title = {The {{Proposition Bank}}: {{An Annotated Corpus}} of {{Semantic Roles}}},
  volume = {31},
  issn = {0891-2017},
  shorttitle = {The {{Proposition Bank}}},
  doi = {10.1162/0891201053630264},
  abstract = {The Proposition Bank project takes a practical approach to semantic representation, adding a layer of predicate-argument information, or semantic role labels, to the syntactic structures of the Penn Treebank. The resulting resource can be thought of as shallow, in that it does not represent coreference, quantification, and many other higher-order phenomena, but also broad, in that it covers every instance of every verb in the corpus and allows representative statistics to be calculated.We discuss the criteria used to define the sets of semantic roles used in the annotation process and to analyze the frequency of syntactic/semantic alternations in the corpus. We describe an automatic system for semantic role tagging trained on the corpus and discuss the effect on its performance of various types of information, including a comparison of full syntactic parsing with a flat representation and the contribution of the empty ''trace'' categories of the treebank.},
  number = {1},
  journal = {Comput. Linguist.},
  author = {Palmer, Martha and Gildea, Daniel and Kingsbury, Paul},
  month = mar,
  year = {2005},
  pages = {71--106},
  file = {C:\\Users\\MSI\\Zotero\\storage\\JH2QLB7Y\\Palmer et al. - 2005 - The Proposition Bank An Annotated Corpus of Seman.pdf}
}

@misc{ReiterNaturalLanguageGeneration2016,
  title = {Natural {{Language Generation}} and {{Machine Learning}}},
  abstract = {Machine Learning and statistical corpus techniques are often very useful in Natural Language Generation, but they are not the best way to solve all NLG problems.},
  journal = {Ehud Reiter's Blog},
  author = {Reiter, Ehud},
  month = dec,
  year = {2016},
  file = {C:\\Users\\MSI\\Zotero\\storage\\HKVVGTEV\\nlg-and-ml.html}
}

@article{11403/dicovalence/v1,
  title = {Dicovalence},
  author = {{D{\'e}partement de linguistique}},
  year = {2017},
  file = {C:\\Users\\MSI\\Zotero\\storage\\R6869MA6\\DicovalenceManuel_v20_100625.pdf},
  copyright = {Licence Publique Générale Amoindrie GNU pour les Ressources linguistiques},
  note = {ORTOLANG (Open Resources and TOols for LANGuage) \textendash{}www.ortolang.fr}
}

@article{faucris.1039365,
  title = {Erlangen {{Valency Patternbank}}. {{A}} Corpus-Based Research Tool for Work on Valency and Argument Structure Constructions.},
  abstract = {The patternbank is a \&nbsp;research tool for all linguists and psychologists doing research on valency paterns of English verbs, nouns and adjectives.},
  author = {Herbst, Thomas and Uhrig, Peter},
  year = {2009},
  keywords = {pattern - construction - valency},
  faupublication = {yes},
  peerreviewed = {automatic}
}

@book{HerbstValencyDictionaryEnglish2004,
  address = {Berlin, Boston},
  title = {A {{Valency Dictionary}} of {{English}}, {{A Corpus}}-{{Based Analysis}} of the {{Complementation Patterns}} of {{English Verbs}}, {{Nouns}} and {{Adjectives}}},
  isbn = {978-3-11-089258-1},
  abstract = {This dictionary provides a valency description of English verbs, nouns and adjectives. Each entry contains a comprehensive list of the complementation patterns identified on the basis of the largest corpus of English available at the present time. All examples are taken directly from the COBUILD/Birmingham corpus. The valency description comprises statements about the quantitative valency of the lexical units established, an inventory of their obligatory, contextually optional and purely optional complements as well as systematic information on the semantic and collocational properties of the complements. An outline of the model of valency theory used in this dictionary is provided in the introduction.},
  publisher = {{De Gruyter Mouton}},
  author = {Herbst, Thomas and Heath, David and Roe, Ian F. and G{\"o}tz, Dieter},
  year = {2004},
  keywords = {English/language,valency/lexicon; dictionary},
  doi = {10.1515/9783110892581}
}

@inproceedings{BelzSystemBuildingCost2009,
  address = {Stroudsburg, PA, USA},
  series = {ENLG '09},
  title = {System {{Building Cost}} vs. {{Output Quality}} in {{Data}}-to-Text {{Generation}}},
  abstract = {Data-to-text generation systems tend to be knowledge-based and manually built, which limits their reusability and makes them time and cost-intensive to create and maintain. Methods for automating (part of) the system building process exist, but do such methods risk a loss in output quality? In this paper, we investigate the cost/quality trade-off in generation system building. We compare four new data-to-text systems which were created by predominantly automatic techniques against six existing systems for the same domain which were created by predominantly manual techniques. We evaluate the ten systems using intrinsic automatic metrics and human quality ratings. We find that increasing the degree to which system building is automated does not necessarily result in a reduction in output quality. We find furthermore that standard automatic evaluation metrics underestimate the quality of handcrafted systems and over-estimate the quality of automatically created systems.},
  booktitle = {Proceedings of the 12th {{European Workshop}} on {{Natural Language Generation}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Belz, Anja and Kow, Eric},
  year = {2009},
  pages = {16--24},
  file = {C:\\Users\\MSI\\Zotero\\storage\\5MJIQX9C\\Belz and Kow - 2009 - System Building Cost vs. Output Quality in Data-to.pdf}
}

@inproceedings{MilleLargeCoverageDetailed2015,
  address = {Edinburgh, Scotland},
  title = {Towards {{Large Coverage Detailed Lexical Resources}} for {{Data}}-to-{{Text Generation}}.},
  booktitle = {Proceedings of the {{First International Workshop}} on {{D2T Generation}}},
  author = {Mille, Simon and Wanner, Leo},
  year = {2015},
  file = {C:\\Users\\MSI\\Zotero\\storage\\BCNETQ6X\\d2t_MilleWanner.pdf}
}

@article{ScartoncrosslinguisticVerbNetstylelexicon,
  title = {Towards a Cross-Linguistic {{VerbNet}}-Style Lexicon for {{Brazilian Portuguese}}},
  abstract = {This paper presents preliminary results of the Brazilian Portuguese Verbnet (VerbNet.Br). This resource is being built by using other existing Computational Lexical Resources via a semi-automatic method. We identified, automatically, 5688 verbs as candidate members of VerbNet.Br, which are distributed in 257 classes inherited from VerbNet. These preliminary results give us some directions of future work and, since the results were automatically generated, a manual revision of the complete resource is highly desirable.},
  author = {Scarton, Carolina and Alu, Sandra},
  pages = {8},
  file = {C:\\Users\\MSI\\Zotero\\storage\\C6GPDN9L\\Scarton and Alu - Towards a cross-linguistic VerbNet-style lexicon f.pdf}
}

@article{DanlosVerscreationVerb,
  title = {Vers La Cr{\'e}ation d'un {{Verb}} Net Du Fran{\c c}ais},
  abstract = {VerbNet is an English lexical resource that has proven useful for NLP due to its high coverage and coherent classification. Such a resource doesn't exist for French, despite some (mostly automatic and unsupervised) attempts. We show how to semi-automatically adapt VerbNet using existing lexical resources, namely LVF (Les Verbes Fran{\c c}ais) and LG (Lexique-Grammaire).},
  author = {Danlos, Laurence and Nakamura, Takuya and Pradet, Quentin and Paris-Est, IGM-LabInfo Universit{\'e} and Cedex, Marne-la-Vall{\'e}e},
  pages = {6},
  file = {C:\\Users\\MSI\\Zotero\\storage\\PU54M2KX\\Danlos et al. - Vers la création d’un Verb net du français.pdf}
}

@article{BussoItalianVerbNetConstructionbased,
  title = {Italian {{VerbNet}}: {{A Construction}}-Based {{Approach}} to {{Italian Verb Classification}}},
  abstract = {This paper proposes a new method for Italian verb classification -and a preliminary example of resulting classes- inspired by Levin (1993) and VerbNet (Kipper-Schuler, 2005), yet partially independent from these resources; we achieved such a result by integrating Levin and VerbNet's models of classification with other theoretic frameworks and resources. The classification is rooted in the constructionist framework (Goldberg, 1995; 2006) and is distribution-based. It is also semantically characterized by a link to FrameNet'ssemanticframesto represent the event expressed by a class. However, the new Italian classes maintain the hierarchic ``tree'' structure and monotonic nature of VerbNet's classes, and, where possible, the original names (e.g.: Verbs of Killing, Verbs of Putting, etc.). We therefore propose here a taxonomy compatible with VerbNet but at the same time adapted to Italian syntax and semantics. It also addresses a number of problems intrinsic to the original classifications, such as the role of argument alternations, here regarded simply as epiphenomena, consistently with the constructionist approach.},
  author = {Busso, Lucia and Lenci, Alessandro},
  pages = {10},
  file = {C:\\Users\\MSI\\Zotero\\storage\\8ZCXB93Q\\Busso and Lenci - Italian VerbNet A Construction-based Approach to .pdf}
}

@inproceedings{DBLP:conf/semeval/MilleCBW17,
  title = {{{FORGe}} at {{SemEval}}-2017 {{Task}} 9: {{Deep}} Sentence Generation Based on a Sequence of Graph Transducers},
  doi = {10.18653/v1/S17-2158},
  booktitle = {Proceedings of the 11th {{International Workshop}} on {{Semantic Evaluation}}, {{SemEval}}@{{ACL}} 2017, {{Vancouver}}, {{Canada}}, {{August}} 3-4, 2017},
  author = {Mille, Simon and Carlini, Roberto and Burga, Alicia and Wanner, Leo},
  year = {2017},
  pages = {920--923},
  file = {C:\\Users\\MSI\\Zotero\\storage\\ZIBXVUE4\\S17-2158.pdf},
  crossref = {DBLP:conf/semeval/2017},
  biburl = {https://dblp.org/rec/bib/conf/semeval/MilleCBW17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/nlpke/WenJH08,
  title = {A Question Answering System Based on {{VerbNet}} Frames},
  doi = {10.1109/NLPKE.2008.4906769},
  booktitle = {Proceedings of the 4th {{International Conference}} on {{Natural Language Processing}} and {{Knowledge Engineering}}, {{NLPKE}} 2008, {{Beijing}}, {{China}}, {{October}} 19-22, 2008},
  author = {Wen, Dunwei and Jiang, Shen and He, Yangjian},
  year = {2008},
  pages = {1--8},
  crossref = {DBLP:conf/nlpke/2008},
  biburl = {https://dblp.org/rec/bib/conf/nlpke/WenJH08},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DanlosPresentationmodelegeneration1983,
  title = {Pr{\'e}sentation d'un Mod{\`e}le de G{\'e}n{\'e}ration Automatique},
  volume = {13},
  issn = {0710-0167, 1705-4591},
  doi = {10.7202/602510ar},
  abstract = {An article from Revue qu{\'e}b{\'e}coise de linguistique, on {\'E}rudit.},
  number = {1},
  journal = {Revue qu{\'e}b{\'e}coise de linguistique},
  author = {Danlos, Laurence},
  year = {1983},
  pages = {203--228},
  file = {C:\\Users\\MSI\\Zotero\\storage\\DEAT2QVJ\\Danlos - 1983 - Présentation d’un modèle de génération automatique.pdf;C:\\Users\\MSI\\Zotero\\storage\\MUI9JJ5H\\602510ar.html}
}

@article{CallawayEvaluatingCoverageLarge,
  title = {Evaluating {{Coverage}} for {{Large Symbolic NLG Grammars}}},
  abstract = {After many successes, statistical approaches that have been popular in the parsing community are now making headway into Natural Language Generation (NLG). These systems are aimed mainly at surface realization, and promise the same advantages that make statistics valuable for parsing: robustness, wide coverage and domain independence. A recent experiment aimed to empirically verify the linguistic coverage for such a statistical surface realization component by generating transformed sentences from the Penn TreeBank corpus. This article presents the empirical results of a similar experiment to evaluate the coverage of a purely symbolic surface realizer. We present the problems facing a symbolic approach on the same task, describe the results of its evaluation, and contrast them with the results of the statistical method to help quantitatively determine the level of coverage currently obtained by NLG surface realizers.},
  author = {Callaway, Charles B and Istituto, ITC-irst},
  pages = {6},
  file = {C:\\Users\\MSI\\Zotero\\storage\\3RWJRA26\\Callaway and Istituto - Evaluating Coverage for Large Symbolic NLG Grammar.pdf}
}

@book{ReiterBuildingNaturalLanguage2000,
  address = {New York, NY, USA},
  title = {Building {{Natural Language Generation Systems}}},
  isbn = {978-0-521-62036-9},
  publisher = {{Cambridge University Press}},
  author = {Reiter, Ehud and Dale, Robert},
  year = {2000},
  file = {C:\\Users\\MSI\\Zotero\\storage\\9X98Y5VA\\Reiter and Dale - 2000 - Building Natural Language Generation Systems.pdf}
}

@article{gatt18,
  title = {Survey of the {{State}} of the {{Art}} in {{Natural Language Generation}}: {{Core}} Tasks, Applications and Evaluation},
  volume = {61},
  journal = {Journal of Artificial Intelligence Research},
  author = {Gatt, Albert and Krahmer, Emiel},
  year = {2018},
  keywords = {NLG},
  pages = {65--170},
  file = {C:\\Users\\MSI\\Zotero\\storage\\F2TUIDBY\\Gatt and Krahmer - 2017 - Survey of the State of the Art in Natural Language.pdf}
}

@inproceedings{BohnetDevelopmentEnvironmentMTTbased2000,
  address = {Stroudsburg, PA, USA},
  series = {INLG '00},
  title = {A {{Development Environment}} for an {{MTT}}-Based {{Sentence Generator}}},
  isbn = {978-965-90296-0-0},
  doi = {10.3115/1118253.1118292},
  abstract = {With the rising standard of the state of the art in text generation and the increase of the number of practical generation applications, it becomes more and more important to provide means for the maintenance of the generator, i.e. its extension, modification, and monitoring by grammarians who are not familiar with its internals. However, only a few sentence and text generators developed to date actually provide these means. One of these generators is KPML (Bateman, 1997). KPML comes with a Development Environment and there is no doubt about the contribution of this environment to the popularity of the systemic approach in generation.},
  booktitle = {Proceedings of the {{First International Conference}} on {{Natural Language Generation}} - {{Volume}} 14},
  publisher = {{Association for Computational Linguistics}},
  author = {Bohnet, Bernd and Langjahr, Andreas and Wanner, Leo},
  year = {2000},
  pages = {260--263},
  file = {C:\\Users\\MSI\\Zotero\\storage\\CP8NGUPM\\Bohnet et al. - 2000 - A Development Environment for an MTT-based Sentenc.pdf}
}

@inproceedings{WannerSurfaceRealizationorientedCorpus2012,
  address = {Stroudsburg, PA, USA},
  series = {INLG '12},
  title = {Towards a {{Surface Realization}}-Oriented {{Corpus Annotation}}},
  abstract = {Until recently, deep stochastic surface realization has been hindered by the lack of semantically annotated corpora. This is about to change. Such corpora are increasingly available, e.g., in the context of CoNLL shared tasks. However, recent experiments with CoNLL 2009 corpora show that these popular resources, which serve well for other applications, may not do so for generation. The attempts to adapt them for generation resulted so far in a better performance of the realizers, but not yet in a genuinely semantic generation-oriented annotation schema. Our goal is to initiate a debate on how a generation suitable annotation schema should be defined. We define some general principles of a semantic generation-oriented annotation and propose an annotation schema that is based on these principles. Experiments shows that making the semantic corpora comply with the suggested principles does not need to have a negative impact on the quality of the stochastic generators trained on them.},
  booktitle = {Proceedings of the {{Seventh International Natural Language Generation Conference}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Wanner, Leo and Mille, Simon and Bohnet, Bernd},
  year = {2012},
  pages = {22--30},
  file = {C:\\Users\\MSI\\Zotero\\storage\\MBTP8642\\Wanner et al. - 2012 - Towards a Surface Realization-oriented Corpus Anno.pdf}
}

@article{WannerGettingEnvironmentalInformation2015,
  title = {Getting the {{Environmental Information Across}}: {{From}} the {{Web}} to the {{User}}},
  volume = {32},
  issn = {0266-4720},
  shorttitle = {Getting the {{Environmental Information Across}}},
  doi = {10.1111/exsy.12100},
  abstract = {Environmental and meteorological conditions are of utmost importance for the population, as they are strongly related to the quality of life. Citizens are increasingly aware of this importance. This awareness results in an increasing demand for environmental information tailored to their specific needs and background. We present an environmental information platform that supports submission of user queries related to environmental conditions and orchestrates results from complementary services to generate personalized suggestions. The system discovers and processes reliable data in the Web in order to convert them into knowledge. At runtime, this information is transferred into an ontology-structured knowledge base, from which then information relevant to the specific user is deduced and communicated in the language of their preference. The platform is demonstrated with real world use cases in the south area of Finland, showing the impact it can have on the quality of everyday life.},
  number = {3},
  journal = {Expert Sys: J. Knowl. Eng.},
  author = {Wanner, Leo and Bosch, Harald and Bouayad-Agha, Nadjet and Casamayor, Gerard and Ertl, Thomas and Hilbring, D{\'e}sir{\'e}e and Johansson, Lasse and Karatzas, Kostas and Karppinen, Ari and Kompatsiaris, Ioannis and Koskentalo, Tarja and Mille, Simon and Mo\$$\backslash$beta\$graber, J{\"u}rgen and Moumtzidou, Anastasia and Myllynen, Maria and Pianta, Emanuele and Rospocher, Marco and Serafini, Luciano and Tarvainen, Virpi and Tonelli, Sara and Vrochidis, Stefanos},
  month = jun,
  year = {2015},
  keywords = {data extraction,data fusion,data interpretation,decision support,environmental data discovery,multimodal environmental information generation,ontology},
  pages = {405--432}
}

@inproceedings{BohnetStuMaBaDeepRepresentation2011,
  address = {Stroudsburg, PA, USA},
  series = {ENLG '11},
  title = {$\ll${{StuMaBa}}$\gg$: {{From Deep Representation}} to {{Surface}}},
  shorttitle = {$\ll${{StuMaBa}}$\gg$},
  abstract = {We realize the full generation pipeline, from the deep (= semantic) representation (SemR), over the shallow (= surface-syntactic) representation (SSyntR) to the surface. To account systematically for the non-isomorphic projection between SemR and SSyntR, we introduce an intermediate representation: the so-called deep-syntactic representation (DSyntR), which does not contain yet (all) function words (as SemR), but which already contains grammatical function relation labels (as SSyntR).},
  booktitle = {Proceedings of the 13th {{European Workshop}} on {{Natural Language Generation}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Bohnet, Bernd and Mille, Simon and Favre, Beno{\^\i}t and Wanner, Leo},
  year = {2011},
  pages = {232--235},
  file = {C:\\Users\\MSI\\Zotero\\storage\\FACVBJHZ\\Bohnet et al. - 2011 - ≪StuMaBa≫ From Deep Representation to Surface.pdf}
}

@inproceedings{LavoieFastPortableRealizer1997,
  address = {Stroudsburg, PA, USA},
  series = {ANLC '97},
  title = {A {{Fast}} and {{Portable Realizer}} for {{Text Generation Systems}}},
  doi = {10.3115/974557.974596},
  booktitle = {Proceedings of the {{Fifth Conference}} on {{Applied Natural Language Processing}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Lavoie, Benoit and Rambow, Owen},
  year = {1997},
  pages = {265--268},
  file = {C:\\Users\\MSI\\Zotero\\storage\\PZZMAVLA\\Lavoie and Rambow - 1997 - A Fast and Portable Realizer for Text Generation S.pdf}
}

@incollection{DaoustJSREALTextRealizer2015,
  address = {Cham},
  title = {{{JSREAL}}: {{A Text Realizer}} for {{Web Programming}}},
  volume = {48},
  isbn = {978-3-319-08042-0 978-3-319-08043-7},
  shorttitle = {{{JSREAL}}},
  abstract = {The web is constantly growing and its documents, getting progressively more dynamic, are well-suited to presentation automation by a text realizer. Current browser-based information display systems have mostly focused on the display and layout of textual data, restricting the generation of nonnumerical informations to canned text or formatted strings. We describe JSREAL, a French text realizer implemented in Javascript. It allows its user to build a variety of French expressions and sentences, combined with HTML tags to easily integrate them into web pages to produce dynamic output depending on the content of the page.},
  booktitle = {Language {{Production}}, {{Cognition}}, and the {{Lexicon}}},
  publisher = {{Springer International Publishing}},
  author = {Daoust, Nicolas and Lapalme, Guy},
  editor = {Gala, N{\'u}ria and Rapp, Reinhard and Bel-Enguix, Gemma},
  year = {2015},
  pages = {361--376},
  file = {C:\\Users\\MSI\\Zotero\\storage\\VZLC2J6L\\Daoust and Lapalme - 2015 - JSREAL A Text Realizer for Web Programming.pdf},
  doi = {10.1007/978-3-319-08043-7_21}
}

@inproceedings{MolinsJSrealBBilingualText2015,
  title = {{{JSrealB}}: {{A Bilingual Text Realizer}} for {{Web Programming}}},
  shorttitle = {{{JSrealB}}},
  doi = {10.18653/v1/W15-4719},
  abstract = {JSrealB is an English and French text realizer written in JavaScript to ease its integration in web applications. The realization engine is mainly rule-based. Table driven rules are defined for inflection and algorithmic propagation rules, for agreements. It allows its user to build a variety of French and English expressions and sentences from a single specification to produce dynamic output depending on the content of a web page.},
  publisher = {{Association for Computational Linguistics}},
  author = {Molins, Paul and Lapalme, Guy},
  year = {2015},
  pages = {109--111},
  file = {C:\\Users\\MSI\\Zotero\\storage\\8B9JS4P8\\Molins and Lapalme - 2015 - JSrealB A Bilingual Text Realizer for Web Program.pdf}
}

@article{BohnetBroadCoverageMultilingual,
  title = {Broad {{Coverage Multilingual Deep Sentence Generation}} with a {{Stochastic Multi}}-{{Level Realizer}}},
  abstract = {Most of the known stochastic sentence generators use syntactically annotated corpora, performing the projection to the surface in one stage. However, in full-fledged text generation, sentence realization usually starts from semantic (predicate-argument) structures. To be able to deal with semantic structures, stochastic generators require semantically annotated, or, even better, multilevel annotated corpora. Only then can they deal with such crucial generation issues as sentence planning, linearization and morphologization. Multilevel annotated corpora are increasingly available for multiple languages. We take advantage of them and propose a multilingual deep stochastic sentence realizer that mirrors the state-ofthe-art research in semantic parsing. The realizer uses an SVM learning algorithm. For each pair of adjacent levels of annotation, a separate decoder is defined. So far, we evaluated the realizer for Chinese, English, German, and Spanish.},
  author = {Bohnet, Bernd and Wanner, Leo and Mille, Simon and Burga, Alicia},
  pages = {9},
  file = {C:\\Users\\MSI\\Zotero\\storage\\SILH4TG7\\Bohnet et al. - Broad Coverage Multilingual Deep Sentence Generati.pdf}
}

@inproceedings{GattSimpleNLGRealisationEngine2009,
  address = {Stroudsburg, PA, USA},
  series = {ENLG '09},
  title = {{{SimpleNLG}}: {{A Realisation Engine}} for {{Practical Applications}}},
  shorttitle = {{{SimpleNLG}}},
  abstract = {This paper describes SimpleNLG, a realisation engine for English which aims to provide simple and robust interfaces to generate syntactic structures and linearise them. The library is also flexible in allowing the use of mixed (canned and non-canned) representations.},
  booktitle = {Proceedings of the 12th {{European Workshop}} on {{Natural Language Generation}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Gatt, Albert and Reiter, Ehud},
  year = {2009},
  pages = {90--93},
  file = {C:\\Users\\MSI\\Zotero\\storage\\L93SH5CH\\Gatt and Reiter - 2009 - SimpleNLG A Realisation Engine for Practical Appl.pdf}
}

@article{WannerMARQUISGENERATIONUSERTAILORED2010,
  title = {{{MARQUIS}}: {{GENERATION OF USER}}-{{TAILORED MULTILINGUAL AIR QUALITY BULLETINS}}},
  volume = {24},
  issn = {0883-9514},
  shorttitle = {{{MARQUIS}}},
  doi = {10.1080/08839514.2010.529258},
  abstract = {Air pollution has a major influence on health. It is thus not surprising that air quality (AQ) increasingly becomes a central issue in the environmental information policy worldwide. The most common way to deliver AQ information is in terms of graphics, tables, pictograms, or color scales that display either the concentrations of the pollutant substances or the corresponding AQ indices. However, all of these presentation modi lack the explanatory dimension; nor can they be easily tailored to the needs of the individual users. MARQUIS is an AQ information generation service that produces user-tailored multilingual bulletins on the major measured and forecasted air pollution substances and their relevance to human health in five European regions. It incorporates modules for the assessment of pollutant time series episodes with respect to their relevance to a given addressee, for planning of the discourse structure of the bulletins and the selection of the adequate presentation mode, and for generation proper. The positive evaluation of the bulletins produced by MARQUIS by users shows that the use of automatic text generation techniques in such a complex and sensitive application is feasible.},
  number = {10},
  journal = {Appl. Artif. Intell.},
  author = {Wanner, Leo and Bohnet, Bernd and Bouayad-Agha, Nadjet and Lareau, Francois and Nicklass, Daniel},
  month = nov,
  year = {2010},
  pages = {914--952},
  file = {C:\\Users\\MSI\\Zotero\\storage\\YIJUGPZH\\Wanner et al. - 2010 - MARQUIS GENERATION OF USER-TAILORED MULTILINGUAL .pdf}
}

@inproceedings{BelzFirstSurfaceRealisation2011,
  address = {Stroudsburg, PA, USA},
  series = {ENLG '11},
  title = {The {{First Surface Realisation Shared Task}}: {{Overview}} and {{Evaluation Results}}},
  shorttitle = {The {{First Surface Realisation Shared Task}}},
  abstract = {The Surface Realisation (SR) Task was a new task at Generation Challenges 2011, and had two tracks: (1) Shallow: mapping from shallow input representations to realisations; and (2) Deep: mapping from deep input representations to realisations. Five teams submitted six systems in total, and we additionally evaluated human toplines. Systems were evaluated automatically using a range of intrinsic metrics. In addition, systems were assessed by human judges in terms of Clarity, Readability and Meaning Similarity. This report presents the evaluation results, along with descriptions of the SR Task Tracks and evaluation methods. For descriptions of the participating systems, see the separate system reports in this volume, immediately following this results report.},
  booktitle = {Proceedings of the 13th {{European Workshop}} on {{Natural Language Generation}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Belz, Anja and White, Michael and Espinosa, Dominic and Kow, Eric and Hogan, Deirdre and Stent, Amanda},
  year = {2011},
  pages = {217--226},
  file = {C:\\Users\\MSI\\Zotero\\storage\\CXM8KYQX\\Belz et al. - 2011 - The First Surface Realisation Shared Task Overvie.pdf}
}

@techreport{Elhadad98surge:a,
  title = {{{SURGE}}: A {{Comprehensive Plug}}-in {{Syntactic Realization Component}} for {{Text Generation}}},
  author = {Elhadad, Michael and Robin, Jacques},
  year = {1998}
}

@article{BatemanEnablingTechnologyMultilingual1997,
  title = {Enabling {{Technology}} for {{Multilingual Natural Language Generation}}: {{The KPML Development Environment}}},
  volume = {3},
  issn = {1351-3249},
  shorttitle = {Enabling {{Technology}} for {{Multilingual Natural Language Generation}}},
  doi = {10.1017/S1351324997001514},
  abstract = {Natural language generation is now moving away from research prototypes into more practical applications. Generation functionality is also being asked to play a more significant role in established applications such as machine translation. In both cases, multilingual generation techniques have much to offer. However, the take-up of multilingual generation is being restricted by a critical lack both of large-scale linguistic resources suited to the generation task and of appropriate development environments. This paper describes KPML, a multilingual development environment that offers one possible solution to these problems. KPML aims to provide generation projects with standardized, broad-coverage, reusable resources and a basic engine for using such resources for generation. A variety of focused debugging aids ensure efficient maintenance, while supporting multilingual work such as contrastive language development and automatic merging of independently developed resources. KPML is based on a new, generic approach to multilinguality in resource description that extends significantly beyond previous approaches. The system has already been used in a number of large generation projects and is freely available to the generation community.},
  number = {1},
  journal = {Nat. Lang. Eng.},
  author = {Bateman, John A.},
  month = mar,
  year = {1997},
  pages = {15--55},
  file = {C:\\Users\\MSI\\Zotero\\storage\\7SXFHDAR\\BATEMAN - Enabling technology for multilingual natural langu.pdf}
}

@article{BelzSurfaceRealisationTask,
  title = {The {{Surface Realisation Task}}: {{Recent Developments}} and {{Future Plans}}},
  abstract = {The Surface Realisation Shared Task was first run in 2011. Two common-ground input representations were developed and for the first time several independently developed surface realisers produced realisations from the same shared inputs. However, the input representations had several shortcomings which we have been aiming to address in the time since. This paper reports on our work to date on improving the input representations and on our plans for the next edition of the SR Task. We also briefly summarise other related developments in NLG shared tasks and outline how the different ideas may be usefully brought together in the future.},
  author = {Belz, Anja and Bohnet, Bernd and Mille, Simon and Wanner, Leo and White, Michael},
  pages = {5},
  file = {C:\\Users\\MSI\\Zotero\\storage\\EN6EAH8T\\Belz et al. - The Surface Realisation Task Recent Developments .pdf}
}

@book{HryniewiczEnvironmentalinformaticssystems2007,
  address = {Aachen},
  title = {Environmental Informatics and Systems Research: {{EnviroInfo Warsaw}} 2007 ; the 21st {{International Conference}} on "{{Informatics}} for {{Environmental Protection}}", {{Warsaw}}, {{Poland}}, [{{September}} 12 - 14, 2007]},
  isbn = {978-3-8322-6397-3},
  shorttitle = {Environmental Informatics and Systems Research},
  abstract = {Multilingual environmental information is communicated via different media. These media can be newspapers, TV, internet, WAP, SMS, etc. Each of the media has a presentation mode which fits best. Thus, it turned out that for newspapers, pictograms which indicate good, normal, and bad conditions, a map with pictograms and/or a very short text are to be preferred. In contrast, the information provided in the internet, can be very detailed and personalized and contain the latest data available at the moment the user requests the information. Furthermore, in the internet, the user can interactively select more details or change the presentation mode. For all media, the most challenging information mode is text. Since a template-based method where predefined sentences with empty slots filled at the time of generation cannot ensure coherent and cohesive text for all contextual settings, full-fledged generation techniques are needed. In this paper, we present the generation techniques as used for the production of multilingual air quality information in the framework of the MARQUIS-project.},
  language = {eng},
  publisher = {{Shaker}},
  editor = {Hryniewicz, Olgierd and Studzi{\'n}ski, Jan and Szediw, Anna and {International Conference Informatics for Environmental Protection}},
  year = {2007},
  file = {C:\\Users\\MSI\\Zotero\\storage\\Q9RPGIZN\\Hryniewicz et al. - 2007 - Environmental informatics and systems research En.pdf}
}

@article{PolguerePourmodelestratifie,
  title = {Pour Un Mod{\`e}le Stratifi{\'e} de La Lexicalisation En G{\'e}n{\'e}ration de Texte},
  abstract = {Pour un mod{\`e}le stratifi{\'e} de la lexicalisation en g{\'e}n{\'e}ration de texte},
  journal = {Traitement Automatique des Langues (TAL)},
  author = {Polgu{\`e}re, Alain},
  file = {C:\\Users\\MSI\\Zotero\\storage\\6G5PZTXI\\POLGUÈRE - POUR UN MODÈLE STRATIFIÉ DE LA LEXICALISATION EN G.pdf}
}

@article{VanDeemterRealTemplateBasedNatural2005,
  title = {Real {{Versus Template}}-{{Based Natural Language Generation}}: {{A False Opposition}}?},
  volume = {31},
  issn = {0891-2017},
  shorttitle = {Real {{Versus Template}}-{{Based Natural Language Generation}}},
  doi = {10.1162/0891201053630291},
  abstract = {This article challenges the received wisdom that template-based approaches to the generation of language are necessarily inferior to other approaches as regards their maintainability, linguistic well-foundedness, and quality of output. Some recent NLG systems that call themselves ''template-based'' will illustrate our claims.},
  number = {1},
  journal = {Comput. Linguist.},
  author = {Van Deemter, Kees and Krahmer, Emiel and Theune, Mari{\"e}t},
  month = mar,
  year = {2005},
  pages = {15--24},
  file = {C:\\Users\\MSI\\Zotero\\storage\\YYSWEWL7\\Van Deemter et al. - 2005 - Real Versus Template-Based Natural Language Genera.pdf}
}

@inproceedings{BohnetOpensourcegraph2010,
  title = {Open Source Graph Transducer Interpreter and Grammar Development Environment},
  abstract = {Graph and tree transducers have been applied in many NLP areas\textemdash{}among them, machine translation, summarization, parsing, and text generation. In particular, the successful use of tree rewriting transducers for the introduction of syntactic structures in statistical machine translation contributed to their popularity. However, the potential of such transducers is limited because they do not handle graphs and because they ''consume '' the source structure in that they rewrite it instead of leaving it intact for intermediate consultations. In this paper, we describe an open source tree and graph transducer interpreter, which combines the advantages of graph transducers and two-tape Finite State Transducers and surpasses the limitations of state-of-the-art tree rewriting transducers. Along with the transducer, we present a graph grammar development environment that supports the compilation and maintenance of graph transducer grammatical and lexical resources. Such an environment is indispensable for any effort to create consistent large coverage NLP-resources by human experts. 1.},
  booktitle = {In {{Proc}}. {{LREC}}},
  author = {Bohnet, Bernd and Wanner, Leo},
  year = {2010},
  file = {C:\\Users\\MSI\\Zotero\\storage\\NCH55YVE\\Bohnet and Wanner - 2010 - Open source graph transducer interpreter and gramm.pdf;C:\\Users\\MSI\\Zotero\\storage\\3ZFT8PPY\\summary.html}
}

@inproceedings{EssersChoosingSurfaceRealiser1998,
  address = {Singapore},
  title = {Choosing a {{Surface Realiser}}},
  booktitle = {In {{Proceedings}} of {{PRICAI98}}},
  author = {Essers, Victor and Dale, Robert},
  year = {1998}
}

@inproceedings{MahapatraStatisticalNaturalLanguage2016,
  title = {Statistical {{Natural Language Generation}} from {{Tabular Non}}-Textual {{Data}}},
  doi = {10.18653/v1/W16-6624},
  abstract = {Most of the existing natural language generation (NLG) techniques employing statistical methods are typically resource and time intensive. On the other hand, handcrafted rulebased and template-based NLG systems typically require significant human/designer efforts. In this paper, we proposed a statistical NLG technique which does not require any semantic relational knowledge and takes much less time to generate output text. The system can be used in those cases where source non-textual data are in the form of tuple in some tabular dataset. We carried out our experiments on the Prodigy-METEO wind forecasting dataset. For the evaluation purpose, we used both human evaluation and automatic evaluation. From the evaluation results we found that the linguistic quality and correctness of the texts generated by the system are better than many existing NLG systems.},
  language = {en},
  publisher = {{Association for Computational Linguistics}},
  author = {Mahapatra, Joy and Naskar, Sudip Kumar and Bandyopadhyay, Sivaji},
  year = {2016},
  pages = {143--152},
  file = {C:\\Users\\MSI\\Zotero\\storage\\MHPPW53V\\Mahapatra et al. - 2016 - Statistical Natural Language Generation from Tabul.pdf}
}

@article{DANLOSGTAGLexicalizedFormalism,
  title = {G-{{TAG}}: {{A Lexicalized Formalism}} for {{Text Generation}} Inspired by {{Tree Adjoining Grammar}}},
  author = {DANLOS, LAURENCE},
  pages = {26},
  file = {C:\\Users\\MSI\\Zotero\\storage\\AMP49D54\\DANLOS - G-TAG A Lexicalized Formalism for Text Generation.pdf}
}

@article{DanlosGenerationtextesGTAG,
  title = {G{\'e}n{\'e}ration de Textes : {{G}}-{{TAG}} Revisit{\'e} Avec Les {{Grammaires Cat{\'e}gorielles Abstraites}}},
  abstract = {G-TAG is a formalism dedicated to text generation. It relies on the Tree Adjoining Grammar (TAG) formalism and extends it with several specific notions allowing for the construction of a surface form from a conceptual representation. This conceptual representation is independent from the target language. The goal of this paper is to study G-TAG and its specific notions from the perspective given by Abstract Categorial Grammars (ACG). We use the reversibility property of ACG and the encoding of TAG they offer. We show that the key G-TAG notions of g-derivation tree and lexicalization are naturally expressed in ACG. The construction of surface forms can then rely on the general ACG algorithms and some operations that G-TAG is lacking can be freely accounted for.},
  author = {Danlos, Laurence and Maskharashvili, Aleksandre and Pogodalla, Sylvain},
  pages = {12},
  file = {C:\\Users\\MSI\\Zotero\\storage\\CTN68A7U\\Danlos et al. - Génération de textes  G-TAG revisité avec les Gra.pdf}
}

@inproceedings{Lareau2007TowardsAG,
  title = {Towards a {{Generic Multilingual Dependency Grammar}} for {{Text Generation}}},
  author = {Lareau, Fran{\c c}ois and Wanner, Leo and Fabra, Pompeu and Holloway, Tracy and Bender, Emily M.},
  year = {2007},
  file = {C:\\Users\\MSI\\Zotero\\storage\\5V4WVJ4Z\\geaf07lareauwanner.pdf}
}

@inproceedings{bohnet07,
  address = {Warsaw},
  title = {Automatic {{Production}} of {{Multilingual Environmental Information}}},
  volume = {2},
  booktitle = {Proceedings of {{EnviroInfo}} 2007},
  author = {Bohnet, Bernd and Lareau, Fran{\c c}ois and Wanner, Leo},
  year = {2007},
  pages = {59--66}
}

@article{mcroy_channarukul_ali_2003,
  title = {An Augmented Template-Based Approach to Text Realization},
  volume = {9},
  doi = {10.1017/S1351324903003188},
  number = {4},
  journal = {Natural Language Engineering},
  author = {McRoy, Susan W. and Channarukul, Songsak and Ali, Syed S.},
  year = {2003},
  pages = {381--420},
  file = {C:\\Users\\MSI\\Zotero\\storage\\RB7S43JV\\DOI 10.1017S1351324903003188 Printed in the Unit.pdf},
  publisher = {{Cambridge University Press}}
}

@inproceedings{thomason:coling14,
  address = {Dublin, Ireland},
  title = {Integrating {{Language}} and {{Vision}} to {{Generate Natural Language Descriptions}} of {{Videos}} in the {{Wild}}},
  booktitle = {Proceedings of the 25th {{International Conference}} on {{Computational Linguistics}} ({{COLING}} 2014)},
  author = {Thomason, Jesse and Venugopalan, Subhashini and Guadarrama, Sergio and Saenko, Kate and Mooney, Raymond},
  month = aug,
  year = {2014},
  pages = {1218--1227}
}

@incollection{1948c0b7a8ca42679cad977bb2cdddc2,
  title = {Generating {{Affective Natural Language}} for {{Parents}} of {{Neonatal Infants}}},
  booktitle = {Proceedings of {{ENLG}}-2011},
  publisher = {{Association for Computational Linguistics}},
  author = {Mahamood, Saad and Reiter, Ehud Baruch},
  year = {2011},
  pages = {12--21}
}

@inproceedings{W17-3513,
  address = {Santiago de Compostela, Spain},
  title = {{{PASS}}: {{A Dutch}} Data-to-Text System for Soccer, Targeted towards Specific Audiences},
  booktitle = {Proceedings of the 10th {{International Conference}} on {{Natural Language Generation}}},
  publisher = {{Association for Computational Linguistics}},
  author = {{van der Lee}, Chris and Krahmer, Emiel and Wubben, Sander},
  year = {2017},
  pages = {95--104}
}

@article{DBLP:journals/corr/HendricksARDSD16,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1603.08507},
  title = {Generating {{Visual Explanations}}},
  volume = {abs/1603.08507},
  journal = {CoRR},
  author = {Hendricks, Lisa Anne and Akata, Zeynep and Rohrbach, Marcus and Donahue, Jeff and Schiele, Bernt and Darrell, Trevor},
  year = {2016},
  biburl = {https://dblp.org/rec/bib/journals/corr/HendricksARDSD16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DimitromanolakiLearningOrderFacts2003,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {cs/0306062},
  title = {Learning to {{Order Facts}} for {{Discourse Planning}} in {{Natural Language Generation}}},
  abstract = {This paper presents a machine learning approach to discourse planning in natural language generation. More specifically, we address the problem of learning the most natural ordering of facts in discourse plans for a specific domain. We discuss our methodology and how it was instantiated using two different machine learning algorithms. A quantitative evaluation performed in the domain of museum exhibit descriptions indicates that our approach performs significantly better than manually constructed ordering rules. Being retrainable, the resulting planners can be ported easily to other similar domains, without requiring language technology expertise.},
  journal = {arXiv:cs/0306062},
  author = {Dimitromanolaki, Aggeliki and Androutsopoulos, Ion},
  month = jun,
  year = {2003},
  keywords = {Computer Science - Computation and Language,H.5.2},
  file = {C:\\Users\\MSI\\Zotero\\storage\\7TAUN5S8\\Dimitromanolaki and Androutsopoulos - 2003 - Learning to Order Facts for Discourse Planning in .pdf;C:\\Users\\MSI\\Zotero\\storage\\67UQ4P9U\\0306062.html},
  annote = {Comment: 8 pages, 4 figures, 1 table}
}

@inproceedings{ChengCapturingInteractionAggregation2000,
  address = {Stroudsburg, PA, USA},
  series = {INLG '00},
  title = {Capturing the {{Interaction Between Aggregation}} and {{Text Planning}} in {{Two Generation Systems}}},
  isbn = {978-965-90296-0-0},
  doi = {10.3115/1118253.1118279},
  abstract = {In natural language generation, different generation tasks often interact with each other in a complex way. We think that how to resolve the complex interactions inside and between tasks is more important to the generation of a coherent text than how to model each individual factor. This paper focuses on the interaction between aggregation and text planning, and tries to explore what preferences exist among the features considered by the two tasks. The preferences are implemented in two generation systems, namely ILEX-TS and a text planner using a Genetic Algorithm. The evaluation emphasises the second implementation and shows that capturing these preferences properly can lead to coherent text.},
  booktitle = {Proceedings of the {{First International Conference}} on {{Natural Language Generation}} - {{Volume}} 14},
  publisher = {{Association for Computational Linguistics}},
  author = {Cheng, Hua and Mellish, Chris},
  year = {2000},
  pages = {186--193},
  file = {C:\\Users\\MSI\\Zotero\\storage\\R5ZGR8A3\\Cheng and Mellish - 2000 - Capturing the Interaction Between Aggregation and .pdf}
}

@article{ElhadadFloatingConstraintsLexical1997,
  title = {Floating {{Constraints}} in {{Lexical Choice}}},
  volume = {23},
  issn = {0891-2017},
  abstract = {Lexical choice is a computationally complex task, requiring a generation system to consider a potentially large number of mappings between concepts and words. Constraints that aid in determining which word is best come from a wide variety of sources, including syntax, semantics, pragmatics, the lexicon, and the underlying domain. Furthermore, in some situations, different constraints come into play early on, while in others, they apply much later. This makes it difficult to determine a systematic ordering in which to apply constraints. In this paper, we present a general approach to lexical choice that can handle multiple, interacting constraints. We focus on the problem of floating constraints, semantic or pragmatic constraints that float, appearing at a variety of different syntactic ranks, often merged with other semantic constraints. This means that multiple content units can be realized by a single surface element, and conversely, that a single content unit can be realized by a variety of surface elements. Our approach uses the Functional Unification Formalism (FUF) to represent a generation lexicon, allowing for declarative and compositional representation of individual constraints.},
  number = {2},
  journal = {Comput. Linguist.},
  author = {Elhadad, Michael and Robin, Jacques and McKeown, Kathleen},
  month = jun,
  year = {1997},
  pages = {195--239},
  file = {C:\\Users\\MSI\\Zotero\\storage\\C8276R24\\Elhadad et al. - 1997 - Floating Constraints in Lexical Choice.pdf}
}

@inproceedings{LangkildeForestbasedStatisticalSentence2000,
  address = {Stroudsburg, PA, USA},
  series = {NAACL 2000},
  title = {Forest-Based {{Statistical Sentence Generation}}},
  abstract = {This paper presents a new approach to statistical sentence generation in which alternative phrases are represented as packed sets of trees, or forests, and then ranked statistically to choose the best one. This representation offers advantages in compactness and in the ability to represent syntactic information. It also facilitates more efficient statistical ranking than a previous approach to statistical generation. An efficient ranking algorithm is described, together with experimental results showing significant improvements over simple enumeration or a lattice-based approach.},
  booktitle = {Proceedings of the 1st {{North American Chapter}} of the {{Association}} for {{Computational Linguistics Conference}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Langkilde, Irene},
  year = {2000},
  pages = {170--177},
  file = {C:\\Users\\MSI\\Zotero\\storage\\SJHARAJ8\\Langkilde - 2000 - Forest-based Statistical Sentence Generation.pdf}
}

@inproceedings{KayFunctionalUnificationGrammar1984,
  address = {Stroudsburg, PA, USA},
  series = {COLING '84},
  title = {Functional {{Unification Grammar}}: {{A Formalism}} for {{Machine Translation}}},
  shorttitle = {Functional {{Unification Grammar}}},
  doi = {10.3115/980431.980509},
  abstract = {Functional Unification Grammar provides an opportunity to encompass within one formalism and computational system the parts of machine translation systems that have usually been treated separately, natably analysis, transfer, and synthesis. Many of the advantages of this formalism come from the fact that it is monotonic allowing data structures to grow differently as different nondeterministic alternatives in a computation are pursued, but never to be modified in any way. A striking feature of this system is that it is fundamental reversible, allowing a to translate as b only if b could translate as a.},
  booktitle = {Proceedings of the 10th {{International Conference}} on {{Computational Linguistics}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Kay, Martin},
  year = {1984},
  pages = {75--78},
  file = {C:\\Users\\MSI\\Zotero\\storage\\WFS63C96\\Kay - 1984 - Functional Unification Grammar A Formalism for Ma.pdf}
}

@book{MatthiessenSystemicfunctionalgrammar1997,
  title = {Systemic Functional Grammar: A First Step into the Theory},
  shorttitle = {Systemic Functional Grammar},
  author = {Matthiessen, Christian M. I. M and Halliday, M. A. K},
  year = {1997},
  note = {OCLC: 222039101}
}

@inproceedings{PenmanOverview,
  title = {An Overview of the {{PENMAN}} Text Generation System},
  booktitle = {Proceedings of the {{National Conference}} on {{Artificial Intelligence}}},
  author = {Mann, William C.},
  year = {1983},
  keywords = {grammar linguistic},
  pages = {261--265},
  organization = {AAAI},
  biburl = {http://sandbox.academic-puma.de/bibtex/21a035f307a4b29ec98c762b72c974526/alistair},
  interhash = {c2d50f5545ed5ab6fd6c54becc425298},
  intrahash = {1a035f307a4b29ec98c762b72c974526},
  note = {Also appears as USC/Information Sciences Institute, RR-83-114.}
}

@article{MilledemoFORGePompeu2017,
  title = {A Demo of {{FORGe}}: The {{Pompeu Fabra Open Rule}}-Based {{Generator}}},
  shorttitle = {A Demo of {{FORGe}}},
  doi = {10.18653/v1/W17-3539},
  journal = {Proceedings of the 10th International Conference on Natural Language Generation},
  author = {Mille, Simon and Wanner, Leo},
  year = {2017},
  pages = {245--246},
  file = {C:\\Users\\MSI\\Zotero\\storage\\ZVAVPWUH\\Mille and Wanner - 2017 - A demo of FORGe the Pompeu Fabra Open Rule-based .pdf;C:\\Users\\MSI\\Zotero\\storage\\2PS3SNSB\\w17-3539.html}
}

@article{PolgueretheorieSensTexte1998,
  title = {La Th{\'e}orie {{Sens}}-{{Texte}}},
  volume = {8-9},
  journal = {Dialangue},
  author = {Polgu{\`e}re, Alain},
  year = {1998},
  pages = {pp.9--30},
  file = {C:\\Users\\MSI\\Zotero\\storage\\N5D6J6NL\\PolgIntroTST.pdf}
}

@article{MillerWordNetonlinelexical1990,
  title = {{{WordNet}}: {{An}} on-Line Lexical Database},
  volume = {3},
  shorttitle = {{{WordNet}}},
  abstract = {WordNet is an on-line lexical reference system whose design is inspired by current},
  journal = {International Journal of Lexicography},
  author = {Miller, George A. and Beckwith, Richard and Fellbaum, Christiane and Gross, Derek and Miller, Katherine},
  year = {1990},
  pages = {235--244},
  file = {C:\\Users\\MSI\\Zotero\\storage\\QSW7T5SH\\Miller et al. - 1990 - WordNet An on-line lexical database.pdf;C:\\Users\\MSI\\Zotero\\storage\\KGK7S6KK\\summary.html}
}

@article{FillmoreBackgroundFramenet2003,
  title = {Background to {{Framenet}}},
  volume = {16},
  issn = {0950-3846, 1477-4577},
  doi = {10.1093/ijl/16.3.235},
  number = {3},
  journal = {International Journal of Lexicography},
  author = {Fillmore, C. J.},
  month = sep,
  year = {2003},
  pages = {235--250}
}

@misc{MertensdictionnairevalenceDICOVALENCE2006,
  title = {Le Dictionnaire de Valence {{DICOVALENCE}}: Manuel d'utilisation},
  howpublished = {http://bach.arts.kuleuven.be/dicovalence/manuel 061117.pdf.},
  author = {Mertens, Piet and {Van den Eynde}, Karel},
  year = {2006}
}

@book{blanche1987pronom,
  series = {SELAF - Societe d'Etudes Linguistiques et Anthropologiques de France Series},
  title = {Pronom et Syntaxe: L'approche Pronominale et Son Application Au Fran{\c c}ais},
  isbn = {978-2-85297-202-5},
  publisher = {{Peeters Publishers \& Booksellers}},
  author = {Blanche-Benveniste, C.},
  year = {1987},
  lccn = {96153641}
}

@inproceedings{danlos:hal-01179175,
  address = {Rimouski, Canada},
  title = {Traduction de {{VerbNet}} Vers Le Fran{\c c}ais},
  booktitle = {Congr{\`e}s {{ACFAS}}},
  author = {Danlos, Laurence and Nakamura, Takuya and Pradet, Quentin},
  month = may,
  year = {2015},
  pages = {1},
  organization = {ACFAS},
  hal_id = {hal-01179175},
  hal_version = {v1}
}

@article{FellbaumLargescaleLexicographyDigital2014,
  title = {Large-Scale {{Lexicography}} in the {{Digital Age}}},
  volume = {27},
  issn = {0950-3846},
  doi = {10.1093/ijl/ecu018},
  abstract = {The Digital Revolution has significantly impacted lexicography on several levels. First, freedom from the traditional paper format has removed constraints on size and format, paving the way for the construction of ever larger lexical databases with multi-faceted, flexible and rich representations of word meaning and use that have been unfeasible for print dictionaries. Second, access to electronic text corpora provide a solid empirical base and allow the lexicographer to craft entries that reflect actual speaker usage, variations across genres and the dynamics of continuous language change. Corpora have moreover opened the possibility to explore and statistically measure on the distributional properties of word and encode their syntagmatic properties. Third, different resources (lexicons, annotated corpora, language-independent, formal ontologies, syntactic and frame-based resources, Wikipedia) can be interlinked and harmonized. Fourth, electronic dictionaries can be continuously updated by a large community of both experts and volunteers, independently of official releases of new editions. All these make it possible to test, on a large-scale and crosslingually, the viability of different theories of lexical meaning and the structure of the lexicon. We discuss these aspects of digital lexicography with a particular emphasis on WordNet.},
  number = {4},
  journal = {International Journal of Lexicography},
  author = {Fellbaum, Christiane},
  month = dec,
  year = {2014},
  pages = {378--395},
  file = {C:\\Users\\MSI\\Zotero\\storage\\IVRKUV93\\Fellbaum - 2014 - Large-scale Lexicography in the Digital Age.pdf;C:\\Users\\MSI\\Zotero\\storage\\9MP2WQFB\\933914.html}
}

@article{FillmoreBackgroundFramenet2003a,
  title = {Background to {{Framenet}}},
  volume = {16},
  issn = {0950-3846},
  doi = {10.1093/ijl/16.3.235},
  abstract = {This article presents general background information about theFrameNet project, including an introduction to its basic assumptions and goals, a description of its precursors, and information about its evolution during the six years of the project. The companion articles in this special issue of IJL describe various aspects of the project in greater detail.},
  number = {3},
  journal = {International Journal of Lexicography},
  author = {Fillmore, Charles J. and Johnson, Christopher R. and Petruck, Miriam R. L.},
  month = sep,
  year = {2003},
  pages = {235--250},
  file = {C:\\Users\\MSI\\Zotero\\storage\\3TFRFW9P\\Fillmore et al. - 2003 - Background to Framenet.pdf;C:\\Users\\MSI\\Zotero\\storage\\KRIE8FLE\\936943.html}
}

@inproceedings{WhiteMinimalDependencyLength2012,
  address = {Stroudsburg, PA, USA},
  series = {EMNLP-CoNLL '12},
  title = {Minimal {{Dependency Length}} in {{Realization Ranking}}},
  abstract = {Comprehension and corpus studies have found that the tendency to minimize dependency length has a strong influence on constituent ordering choices. In this paper, we investigate dependency length minimization in the context of discriminative realization ranking, focusing on its potential to eliminate egregious ordering errors as well as better match the distributional characteristics of sentence orderings in news text. We find that with a state-of-the-art, comprehensive realization ranking model, dependency length minimization yields statistically significant improvements in BLEU scores and significantly reduces the number of heavy/light ordering errors. Through distributional analyses, we also show that with simpler ranking models, dependency length minimization can go overboard, too often sacrificing canonical word order to shorten dependencies, while richer models manage to better counterbalance the dependency length minimization preference against (sometimes) competing canonical word order preferences.},
  booktitle = {Proceedings of the 2012 {{Joint Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} and {{Computational Natural Language Learning}}},
  publisher = {{Association for Computational Linguistics}},
  author = {White, Michael and Rajkumar, Rajakrishnan},
  year = {2012},
  pages = {244--255},
  file = {C:\\Users\\MSI\\Zotero\\storage\\6AN2JQLR\\White and Rajkumar - 2012 - Minimal Dependency Length in Realization Ranking.pdf}
}

@book{TesniereElementssyntaxestructurale1965,
  address = {Paris},
  title = {{El{\'e}ments de syntaxe structurale}},
  isbn = {978-2-252-01861-3 978-2-252-02620-5},
  language = {French},
  publisher = {{Klincksieck}},
  author = {Tesni{\`e}re, Lucien and Fourquet, Jean},
  year = {1965},
  note = {OCLC: 489764849}
}

@article{MilicevicSchemaregimepont2009,
  title = {Sch{\'e}ma de R{\'e}gime~: Le Pont Entre Le Lexique et La Grammaire},
  volume = {176},
  issn = {9782200925680},
  shorttitle = {Sch{\'e}ma de R{\'e}gime~: Le Pont Entre Le Lexique et La Grammaire},
  doi = {10.3917/lang.176.0094},
  number = {4},
  journal = {Langages},
  author = {Milicevic, Jasmina},
  year = {2009},
  pages = {94--116},
  file = {C:\\Users\\MSI\\Zotero\\storage\\GTXSL335\\Milicevic - 2009 - Schéma de régime  le pont entre le lexique et la .pdf}
}

@phdthesis{LambreyImplementationcollocationspour2017,
  title = {Impl{\'e}mentation Des Collocations Pour La R{\'e}alisation de Texte Multilingue},
  school = {Universit{\'e} de Montr{\'e}al},
  author = {Lambrey, Florie},
  month = mar,
  year = {2017},
  file = {C:\\Users\\MSI\\Zotero\\storage\\2AKM9PFR\\Lambrey - 2017 - Implémentation des collocations pour la réalisatio.pdf}
}

@phdthesis{dubinskaite17,
  address = {Grenoble},
  title = {D{\'e}veloppement de Ressources Lituaniennes Pour Un G{\'e}n{\'e}rateur Automatique de Texte Multilingue},
  school = {Universit{\'e} Grenoble Alpes},
  author = {Dubinskaite, Ieva},
  year = {2017}
}

@book{melcuk1988,
  title = {Dependency {{Syntax}}: {{Theory}} and {{Practice}}},
  publisher = {{State University of New York Press}},
  author = {Mel'\v{}cuk, Igor},
  year = {1988},
  keywords = {book dependency grammar head melcuk noun},
  biburl = {https://www.bibsonomy.org/bibtex/23f648a9a81197eb7ecea995c6a2700b0/jil}
}

@phdthesis{PolguereStructurationmisejeu1990,
  title = {Structuration et Mise En Jeu Proc{\'e}durale d'un Mod{\`e}le Linguistique D{\'e}claratif Dans Un Cadre de G{\'e}n{\'e}ration de Texte},
  school = {Universit{\'e} de Montr{\'e}al},
  author = {Polgu{\`e}re, Alain},
  year = {1990},
  file = {C:\\Users\\MSI\\Zotero\\storage\\5Y8VKIBY\\PolguerePhD1990.pdf}
}

@inproceedings{lambrey15,
  address = {Caen},
  title = {Le Traitement Des Collocations En G{\'e}n{\'e}ration de Texte Multilingue},
  booktitle = {Actes de {{TALN}} 2015},
  author = {Lambrey, Florie and Lareau, Fran{\c c}ois},
  year = {2015},
  pages = {579--585},
  crossref = {TALN15}
}

@book{mel2012semantics,
  series = {Semantics: From Meaning to Text},
  title = {Semantics: {{From Meaning}} to {{Text}}},
  isbn = {978-90-272-0596-4},
  number = {v. 1},
  publisher = {{John Benjamins Publishing Company}},
  author = {Mel'\v{}cuk, I.A. and Beck, D. and Polgu{\`e}re, A.},
  year = {2012},
  lccn = {2012017459}
}


