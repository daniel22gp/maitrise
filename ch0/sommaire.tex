\chapter*{Sommaire} 	% La commande "\chapter*" crée un chapitre sans numéro, contrairement \`a la commande "\chapter" réguli\`ere.
% N.B. : La commande "\noindent" force LaTeX \`a ne pas indenter le nouveau paragraphe.
La \ac{GAT} a comme objectif de produire du texte compréhensible en langue naturelle à partir de données non-linguistiques. Les générateurs font essentiellement deux tâches, d'abord ils déterminent le contenu d'un message à énoncer puis ils sélectionnent les mots qui serviront à transmettre le message, aussi appellée la réalisation linguistique. Pour réaliser du texte le plus naturel possible, un système de \ac{GAT} doit se doter de ressources lexicales riches. Si on veut couvrir un maximum de de formes d'énoncés, il nous faut avoir accès aux différents comportements des unités lexicales d'une langue donnée. Puisque les verbes sont au c\oe{}r de chaque énoncé et qu'ils contrôlent généralement la structure d'une phrase, il faudrait encoder leurs propriétés afin de produire du texte représentant la richesse réelle des langues. De plus, les verbes sont imprévisibles en termes de comportements syntaxiques, c'est pourquoi il faut les encoder dans un dictionnaire. Par exemple, on ne peut pas prévoir que le verbe \lex{parler} demandera la préposition \lex{de} pour la phrase \form{Paul parle d'un évènement à Martine}, tandis que \lex{relater} n'en a pas besoin \form{Paul relate un évènement à Martine}. Cet exemple illustre que deux verbes synonymiques engendrent des constructions très différentes, arbitrairement. Il faut donc encoder ce savoir dans un dictionnaire pour que les applications \ac{TAL} comme la \ac{GAT} reproduisent ces comportements correctement.

Ce mémoire porte sur l'intégration de VerbNet, une ressource lexicale riche sur les verbes et leurs comportements syntaxiques, à un réalisateur profond GenDR, dans le cadre de la \ac{GAT}. Pour procéder à cette implémentation, nous avons utilisé le langage de programmation Python et le module \emph{xml.etree.cElementTree} pour extraire les données de VerbNet et les manipuler pour les adapter à GenDR un réalisateur profond opérant dans le cadre de la théorie Sens-Texte. Nous avons ainsi intégré 274 cadres syntaxiques à GenDR ainsi que 6\,394 verbes.

\textbf{Mots-clés}: génération automatique de texte; réalisation linguistique; patrons de régime; cadres syntaxiques; verbes; Théorie Sens-Texte; traitement automatique des langues; linguistique

\chapter*{Summary}

Natural language generation's (NLG) goal is to produce understandable text from non-linguistics data. Generators are essentially separated into two tasks: determine the content of a message to transmit and then carefully select the words that will transmit the wanted message, this second task is called linguistic realization. An NLG system requires acces to a rich lexical resoure in order to generate text in natural way. If such a system wants to cover a maximum of different utterances, it must have access to the different behaviours of a lexical unit of a given language. Because verbs are at the core of each utterance and they usually control the structure of a sentence, we should encode their properties in order to generate text representing the true richness of any language. In addition to that, verbs are highly unpredictible in terms of syntactic behaviours, that is why we need to store them into a dictionary. For example, we can't predict that such a verb like ... That example illustrates that two synonymic verbs do not entail identical constructions. Hence, we must encode this linguistic knowledge in a dictionary so that natural language processing (NLP) applications like NLG recreat correctly these behaviors.

This work is about the integration of VerbNet, a rich lexical resource on verbs and their syntactic behaviors, into a deep realizer called GenDR, in the course of NLG. To make this implementation possible, we have used the Python environment and its module \emph{xml.etree.cElementTree} that allowed us to extract VerbNet's data and to manipulate those in accordance to the Meaning-Text theory encoding of dictionaries, which is the theoretical framework GenDR is based on. We have imported 274 syntactic frames and 6\,394 verbs.

\textbf{Keywords}: natural language generation; linguistic realisation; government patterns; syntactic frames; verbs; Meaning-Text theory; linguistics; natural language processing; linguistics