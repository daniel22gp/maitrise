\chapter*{Sommaire} 	% La commande "\chapter*" crée un chapitre sans numéro, contrairement \`a la commande "\chapter" réguli\`ere.
% N.B. : La commande "\noindent" force LaTeX \`a ne pas indenter le nouveau paragraphe.
La \ac{GAT} a comme objectif de produire du texte compréhensible en langue naturelle à partir de données non-linguistiques. Les générateurs font essentiellement deux tâches: d'abord ils déterminent le contenu d'un message à communiquer, puis ils sélectionnent les mots et les constructions syntaxiques qui serviront à transmettre le message, aussi appellée la réalisation linguistique. Pour générer des textes aussi naturels que possible, un système de \ac{GAT} doit être doté de ressources lexicales riches. Si on veut avoir un maximum de flexibilité dans les réalisations, il nous faut avoir accès aux différentes propriétés de combinatoire des unités lexicales d'une langue donnée. Puisque les verbes sont au c\oe{}ur de chaque énoncé et qu'ils contrôlent généralement la structure de la phrase, il faudrait encoder leurs propriétés afin de produire du texte exploitant toute la richesse des langues. De plus, les verbes ont des propriétés de combinatoires imprévisibles, c'est pourquoi il faut les encoder dans un dictionnaire.

Ce mémoire porte sur l'intégration de VerbNet, un dictionnaire riche de verbes de l'anglais et de leurs comportements syntaxiques, à un réalisateur profond, GenDR. Pour procéder à cette implémentation, nous avons utilisé le langage de programmation Python pour extraire les données de VerbNet et les manipuler pour les adapter à GenDR, un réalisateur profond basé sur la théorie Sens-Texte. Nous avons ainsi intégré 274 cadres syntaxiques à GenDR ainsi que 6\,394 verbes de l'anglais.

\textbf{Mots-clés}: génération automatique de texte; réalisation linguistique; patrons de régime; cadres syntaxiques; verbes; Théorie Sens-Texte

\chapter*{Summary}

\draft{change to match modifications in French}
Natural language generation's (NLG) goal is to produce understandable text from non-linguistics data. Generators are essentially separated into two tasks: they first determine the content of a message to transmit and then they carefully select the words that will transmit the wanted message, this second task is also called linguistic realization. An NLG system requires acces to a rich lexical resoure in order to generate text in natural way. If we want a maximum of flexibility in the realizations, we need access to the combinatorial properties of a lexical unit of a given language . Because verbs are at the core of each utterance and they usually control the structure of a sentence, we should encode their properties in order to generate text representing the true richness of any language. In addition to that, verbs are highly unpredictible in terms of syntactic behaviours, that is why we need to store them into a dictionary.

This work is about the integration of VerbNet, a rich lexical resource on verbs and their syntactic behaviors, into a deep realizer called GenDR, in the course of NLG. To make this implementation possible, we have used the Python programming language that allowed us to extract VerbNet's data and to manipulate those to adapt them to GenDR. We have imported 274 syntactic frames and 6\,394 verbs.

\textbf{Keywords}: natural language generation; linguistic realisation; government patterns; syntactic frames; verbs; Meaning-Text theory