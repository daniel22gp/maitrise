%!TEX root = ../memoire.tex

\chapter*{Introduction}

% \noindent c'est mieux de changer la définition de \chapter et autres titres pour que ça soit uniforme

Depuis les dernières années, les percées en intelligence artificielle ne cessent de fasciner la population. Plus particulièrement les applications liées au \ac{TAL} comme les systèmes de dialogue ordinateur-humain. Ainsi, de nombreuses recherches se sont orientées vers le développement de système informatique pouvant communiquer avec les humains. Or, la communication implique deux processus: la compréhension du langage et la production de celle-ci. Le deuxième processus a donné naissance à la \ac{GAT} qui est une branche du \ac{TAL} dont le but est de produire du texte compréhensible en langue naturelles à partir de données non-linguistiques. Pour générer automatiquement des documents, ces systèmes se servent de connaissances linguistiques. Les premiers systèmes de \ac{GAT} ayant vu le jour ont été créés pour produire des rapports automatiquement dans le but d'alléger la charge de travail des humains \citep{ReiterBuildingNaturalLanguage2000}. Autrement, l'écriture de ces documents est effectuée par un humain, ce qui entraîne des coûts inutiles. Ainsi, la \ac{GAT} est un domaine de recherche dont les applications sont concrètes et facilitent le travail des humains.

Par exemple, en termes d'applications concrètes la \ac{GAT} peut être utilisée pour produire des documents résumant des informations complexes pour des gens n'ayant pas les connaissances de bases requises pour les comprendre. Dans cette veine, MARQUIS \citep{WannerMARQUISGENERATIONUSERTAILORED2010} génère du texte à partir de données numériques brutes sur la qualité de l'air et les textes généres sont adaptés au lecteur. La \ac{GAT} a aussi fait une incursion dans le journalisme, ce qu'on appelle le \scare{robo-journalisme} \citep{W17-3513}. En effet, des articles journalistiques ont été rédigés à partir de données brutes comme les statistiques d'un match.

Traditionnellement, un système de \ac{GAT} se divise en deux parties. La première étant ce que \cite{DanlosPresentationmodelegeneration1983} appelle le \emph{quoi-dire} et que \cite{gatt18} appellent le \emph{early process} qui équivaut à déterminer et structurer le contenu à générer. Autrement dit, il s'agit d'évaluer, parmi les données s'offrant à nous, lesquelles voulons-nous transmettre au lecteur et dans quel ordre. Ensuite il y a ce que Danlos appelle le \emph{comment-le-dire} puis que Gatt et Kramer appellent le \emph{late process} qui revient à choisir les unités lexicales qui serviront à transmettre le \emph{quoi-dire}, on appelle cela la réalisation linguistique. Cette étape du processus a fait l'\oe{}uvre de plusieurs travaux, entre autre parce qu'il y existe diverses approches pour l'effectuer. Nous nous concentrerons sur l'une d'entre elles: la réalisation linguistique à base de règles. Il s'agit de modéliser les connaissances linguistiques d'une langue donnée à partir d'une grammaire et d'un dictionnaire. 

Comme le lexique d'une langue est immense, la plupart des réalisateurs profonds n'ont pas accès à tous les mots d'une langue ainsi que leurs propriétés lexicales (comment ils se combinent avec d'autres). Toutefois, la majorité des classes de mots présentent des régularités quant à leurs comportements syntaxiques, à l'exception des verbes qui forment la partie du discours la plus imprévisible. Ainsi, si on souhaite qu'un réalisateur génère du texte le plus naturellement possible, on devrait récupérer les propritésé lexicales des verbes qui sont, en plus, la partie du discours qui contrôlent la plupart des énoncés. Cette problématique ne s'applique pas uniquement qu'à la \ac{GAT}, toutes les branches du \ac{TAL} bénéficierait d'un traitement approfondi des verbes que ce soit pour toutes les tâches confondues en \ac{TAL}. \cite{SchulerVerbnetBroadcoverageComprehensive2005,Korhonenlargesubcategorizationlexicon2006} pensent qu'un meilleur traitement des langues naturelles passe par la connaissance des comportements syntaxiques des verbes. Pour clarifier l'expression \scare{comportements syntaxiques}, il s'agit des cooccurences syntaxique d'une unité lexicale donnée avec les arguments que cette lexie sélectionne. Par exemple, la relation entre un verbe et son sujet, ou bien la relation entre un nom et le complément qu'il sélectionne. On encode généralement ces comportements dans des dictionnaires car on ne peut pas prédire les comportements des verbes à partir de règles grammaticales. \cite{MilicevicSchemaregimepont2009} illustre ce problème en montrant que deux verbes synonymiques ont des comportements différents bien qu'il s'agit du même message qui est transmis: \form{on se souvient de $X$}, mais \form{on se rappelle $X$}.

Ainsi, en détenant les propriétés syntaxiques des verbes d'une langue donnée, on arrive à couvrir une grande partie des constructions possibles pour cette langue. ce qui nous amène à notre objectif principal. Nous voulons intégrer au réalisateur profond GenDR un dictionnaire de comportements syntaxiques renfermant une quantité exhaustive des constructions possibles de l'anglais. GenDR, est un réalisateur profond multilingue qui reprend les bases du système MARQUIS et qui opère dans le cadre théorique de la \ac{TST}. GenDR a déjà fait l'objet d'un mémoire focusant sur sa capacité à rendre compte de phénomènes langagiers complexes comme les collocations \cite{LambreyImplementationcollocationspour2017, lareau18}.

La ressource lexicale que nous avons choisi pour améliorer la couverture de GenDR est le système de  VerbNet. Une base de données verbale créée dans un contexte où il y avait un réel besoin de faire un dictionnaire décrivant la richesse et la complexité des verbes \citep{KipperClassBasedConstructionVerb2000}. \cite{SchulerVerbnetBroadcoverageComprehensive2005} trouvait qu'il y avait un manque de lignes directrices par rapport à l'organisation des verbes dans les dictionnaires destinés à des applications \ac{TAL}. Son dictionnaire est organisé en une hiérarchie de classes verbales héritées de \cite{verb-classes.levin.1993} qui proposait une méthode de classification des verbes basé sur le partage de comportements syntaxiques. Levin a tenté de délimiter tous les patrons de régime possibles pour les verbes de la langue anglaise. Lorsque plusieurs présentaient des caractéristiques communes sur le plan syntaxique, elle rassemblait ces verbes dans une classe.

Pour implémenter VerbNet à GenDR, nous avons utilisé le langage de programmation Python qui nous a permi de manipuler et d'extraire les données de VerbNet. En effet, nous avons du les manipuler pour que les informations marchent avec la TST. Pour compléter l'implémentation de cette ressource, nous avons du revoir certaines règles de grammaire et l'architecture de nos dictionnaires pour tenir compte des nouvelles informations lexicales auxquelles nous avons accès. Finalement, nous avons testé le tout pour vérifier si l'intégration de VerbNet fonctionnait.

Nous avons séparé ce mémoire en 6 chapitres dont les trois premiers correspondent à la préparation du projet et les trois derniers à l'exécution du projet. Ainsi, le premier chapitre décrit ce qu'est la \ac{GAT} en décrivant brièvement les six étapes du processus classique de génération de texte. Nous retiendrons la dernière étape du processus: la réalisation, et nous la décrirons en détails. Par après, nous présentons quelques réalisateurs pour montrer les différences théoriques et concrètes qui existent entre ceux-ci. Le deuxième chapitre porte entièrement sur un réalisateur profond nommé GenDR, un réalisateur multilingue opérant dans le cadre de la \ac{TST}. Nous décrivons comment ce réalisateur fait pour modéliser les phénomènes langagiers en expliquant en détails les modules qui le composent. Le troisième chapitre est dédié à la description de diverses ressources lexicales, mais nous focuseront la discussion sur les comportements syntaxiques des verbes. Finalement, nous décrivons en détails la ressource VerbNet, puisque c'est celle que nous avons retenu pour faire notre projet.

Dans le quatrième chapitre, nous expliquons comment nous avons procédé à l'extraction, avec Python, des verbes et des cadres syntaxiques pour enrichir notre dictionnaire. Nous décrivons ensuite les étapes qui ont mené à la construction du dictionnaire de patron de régime qui servira au réalisateur profond GenDR. Puis, le cinquième chapitre décrit comment nous avons adatpé le réalisateur profond GenDR pour qu'il incorpore les données que nous avons extraite de VerbNet. Nous décrivons comment les règles de grammaire ont été adpatées ainsi que les dictionnaires. Finalement, le sixième chapitre renferme l'évaluation du système, ce qui consiste à expliquer le choix des méthodes d'évaluation ainsi que nos critères. Puis, pour conclure le tout, nous faisons une synthèse du travail en montrant la contribution de ce mémoire à l'état de l'art, puis nous évoquons quelques pistes à explorer.

\pagenumbering{arabic}