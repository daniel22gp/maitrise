%!TEX root = ../memoire.tex

\chapter*{Introduction}

% \noindent c'est mieux de changer la définition de \chapter et autres titres pour que ça soit uniforme

Dans les dernières années, les percées en intelligence artificielle ne cessent de fasciner la population. Plus particulièrement les applications liées au \ac{TAL} comme les systèmes de dialogue ordinateur-humain. Ainsi, énormément de recherche s'est orientée vers le développement de système informatique pouvant communiquer avec les humains. Or, généralement la communication implique deux processus: la compréhension du langage et la production de celle-ci. La deuxième composante de ce processus a donné naissance à la \ac{GAT} qui est une branche du \ac{TAL} dont le but est de produire du texte compréhensible en langue naturelles à partir de données non-linguistiques. Pour générer automatiquement des documents, ces systèmes se servent des connaissances linguistiques et des connaissances de domaine d'application. Les premiers systèmes de \ac{GAT} ayant vu le jour ont été créés pour produire des rapports automatiquement dans le but d'alléger la charge de travail des humains \citep{ReiterBuildingNaturalLanguage2000}. Autrement, l'écriture de ces documents est effectuée par un humain, ce qui entraîne des coûts continus. Ainsi, la \ac{GAT} est un domaine de recherche menant vers des applications concrètes et pouvant faciliter la tâche des humains. Que ce soit pour générer du texte ou de la parole, les capacités d'usage de tels systèmes sont infinies.

Par exemple, en termes d'applications concrètes la \ac{GAT} peut être utilisée pour produire des documents résumant des informations complexes pour des gens n'ayant pas les connaissances de bases requises pour les comprendre. Dans cette veine, MARQUIS \citep{WannerMARQUISGENERATIONUSERTAILORED2010} génère du texte à partir de données numériques brutes sur la qualité de l'air et les textes généres sont adaptés au lecteur. La \ac{GAT} a aussi fait une incursion dans le journalisme, ce qu'on appelle le robo-journalisme \citep{W17-3513}. Ainsi, des articles journalistiques peuvent être publiés à partir de données brutes dans le but d'informer les gens, sans qu'un humain soit derrière le texte, ce qui donne lieu à la rédaction d'articles sportif écrit par des machines.

Traditionnellement, un système de \ac{GAT} se divise en deux parties. La première étant ce que \cite{DanlosPresentationmodelegeneration1983} appelle le \emph{quoi-dire} et que \cite{gatt18} appellent le \emph{early process} qui équivaut à déterminer et structurer le contenu à générer. Autrement dit, il s'agit d'évaluer parmi les données s'offrant à nous, lesquelles voulons-nous transmettre et dans quel ordre. Ensuite il y a ce que Danlos appelle le \emph{comment-le-dire} puis que Gatt et Kramer appellent le \emph{late process} qui revient à choisir les unités lexicales qui serviront à transmettre le \emph{quoi-dire}, on appelle cela la réalisation linguistique. Cette étape du processus a fait l'oeuvre de nombre de recherche, entre autre parce qu'il y existe diverses approches pour l'effectuer. Nous nous concentrerons sur l'une d'entre elles: la réalisation linguistique à base de règles. Il s'agit de modéliser les connaissances linguistiques d'une langue donnée dans des règles de grammaire et des dictionnaires. Comme il existe une quantité faramineuse de mots, la plupart des réalisateurs profonds n'ont pas accès à tous les mots d'une langue ainsi que leurs propriétés lexico-syntaxiques. Toutefois, la majorité des catégories syntaxiques de mots présentent des régularités. À l'exception des verbes qui sont la partie du discours la plus imprévisible. Ainsi, si on veut qu'un réalisateur génère du texte le plus fidèle à la langue, on peut aller chercher les verbes qui sont la partie du discours qui contrôlent la plupart des énoncés et dont les comportemetns sont les moins prévisibles. Si on a ça, alors on obtient un système extrêmement flexible d'un point de vue linguistique.Pour clarifier l'expression \scare{comportements syntaxiques}, il s'agit des cooccurences syntaxique d'une unité lexicale donnée avec les arguments que cette lexie sélectionne. Par exemple, la relation entre un verbe et son sujet, ou bien la relation entre un nom et le complément qu'il sélectionne. La raison pour laquelle nous encodons généralement ces comportements dans des dictionnaires est du à l'aspect imprévisible de ces comportemetns. En effet, on ne peut pas prédire le nombre d'actants qu'un prédicat gouverne, ou bien les prépositions qu'il régit. ce qui est illustré par \cite{MilicevicSchemaregimepont2009}: \form{on se souvient de $X$}, mais \form{on se rappelle $X$}.

Donc, en détenant les propriétés syntaxiques des verbes d'une langue donnée, on peut couvrir une grande partie des constructions de phrases possibles pour celle-ci. \cite{SchulerVerbnetBroadcoverageComprehensive2005,Korhonenlargesubcategorizationlexicon2006} pensent qu'un meilleur traitement des langues naturelles passe par la connaissance des comportements des verbes. De là vient notre objectif, qui est d'intégrer au réalisateur profond GenDR un dictionnaire de comportements syntaxiques renfermant une quantité exhaustive des constructions possibles de l'anglais. GenDR, un réalisateur profond multilingue qui reprend les rouages de la réalisation du générateur MARQUIS, fonctionne avec la TST. GenDR a déjà fait l'objet d'un mémoire focusant sur sa capacité à rendre compte de phénomènes langagiers complexes: les collocations, GeCo. 

\draft{VerbNet a été créé dans un contexte où il y avait un réel besoin pour un dictionnaire décrivant la richesse et la complexité des verbes \citep{KipperClassBasedConstructionVerb2000}. \cite{SchulerVerbnetBroadcoverageComprehensive2005} trouvait qu'il y avait un manque de lignes directrices par rapport à l'organisation des verbes dans les dictionnaires destinés à des applications \ac{TAL}. Son dictionnaire est organisé en une hiérarchie de classes verbales héritées de \cite{verb-classes.levin.1993}. \cite{verb-classes.levin.1993} proposait une méthode de classification des verbes. Dans sa classification, les verbes de la langue anglaise sont placés dans un nombre fini de classes verbales. L'appartenance d'un verbe à l'une d'entre elles est motivée par le partage de comportements syntaxiques communs. Levin a tenté de délimiter tous les patrons de régime possibles pour les verbes de la langue anglaise. Lorsque plusieurs présentaient des caractéristiques communes sur le plan syntaxique, elle rassemblait ces verbes dans une classe.}

Pour implémenter VerbNet à GenDR, nous avons utilisé le langage de programmation Python qui nous a permi de manipuler et d'extraire les données de VerbNet. Manipuler pour que les informations marchent avec la TST. Pour compléter l'implémentation de cette ressource, nous avons du revoir certaines règles de grammaire et l'architecture de nos dictionnaires pour tenir compte des nouvelles informations lexicales auxquelles nous avons accès. Finalement, nous avons testé le tout pour vérifier si l'intégration de VerbNet fonctionnait.

Nous avons séparé ce mémoire en 6 chapitres dont les trois premiers chapitre correspondent à la préparation du projet et les trois derniers correspondent à l'expérience comme telle. Ainsi, le premier chapitre décrit ce qu'est la \ac{GAT} en expliquant les six étapes du processus classique de génération de texte, puis dans ce même chapitre, nous approfondissons une de ces étapes: la réalisation. Nous décrivons en détails ce qu'est la réalisation puis nous présentons quelques réalisateurs pour montrer les différences qui existent entre ceux-ci. Ensuite, le deuxième chapitre porte entièrement sur un réalisateur profond nommé GenDR: un réalisateur multilingue fonctionnant dans le cadre de la \ac{TST}. Nous décrivons comment ce réalisateur fait pour modéliser les phénomènes langagiers en expliquant en détails les modules qui le composent. Le troisième chapitre est dédié à la description de ressources lexicales focusant sur les comportements syntaxiques des verbes. Comme GenDR ne possède pas de telles ressources, nous avons fait des recherches pour trouver quel sera le meilleur et nous sommes tombés sur VerbNet. Nous décrirons plus en détails cette ressource lexicale.

Dans le quatrième chapitre, nous expliquons comment nous avons procédé à l'extraction des verbes et des cadres syntaxiques pour enrichir notre dictionnaire. Nous expliquons aussi comment nous avons créer le dictionnaire de patron de régime qui servira à notre réalisateur.Le tout a été effectué en Python. Puis, le cinquième chapitre décrit comment nous avons adatpé le réalisateur profond GenDR pour qu'il incorpore les données que nous avons extraite de VerbNet. Nous décrivons comment les règles de grammaire ont été adpatées ainsi que les dictionnaires. Finalement, le sixième chapitre renferme l'évaluation du système, ce qui consiste à expliquer comment nous procédons à l'évaluation puis nos critères et finalement ce que les données disent. Puis, pour conclure le tout, nous faisons une synthèse du travail en montrant la contribution de ce mémoire à l'état de l'art, puis nous évoquons quelques pistes à explorer.

\pagenumbering{arabic}