%!TEX root = ../memoire.tex

\chapter*{Introduction}

% \noindent c'est mieux de changer la définition de \chapter et autres titres pour que ça soit uniforme

Depuis les dernières années, les percées en intelligence artificielle ne cessent de fasciner la population. Plus particulièrement les applications liées au \acf{TAL} comme les systèmes de dialogue ordinateur-humain. Ainsi, de nombreuses recherches se sont orientées vers le développement de système informatique pouvant communiquer avec les humains. Or, la communication implique deux processus: la compréhension du langage et la production de celle-ci. Le deuxième processus a donné naissance à la \acf{GAT} qui est une branche du \ac{TAL} dont le but est de produire du texte compréhensible en langue naturelles à partir de données non-linguistiques. Pour générer automatiquement des documents, ces systèmes se servent de connaissances linguistiques. Les premiers systèmes de \ac{GAT} ayant vu le jour ont été créés pour produire des rapports automatiquement dans le but d'alléger la charge de travail des humains \citep{ReiterBuildingNaturalLanguage2000}. Autrement, l'écriture de ces documents est effectuée par un humain, ce qui entraîne des coûts inutiles. Ainsi, la \ac{GAT} est un domaine de recherche dont les applications sont concrètes et facilitent le travail des humains.

Par exemple, en termes d'applications concrètes, la \ac{GAT} peut être utilisée pour produire des documents résumant des informations complexes pour des gens n'ayant pas les connaissances de bases requises pour les comprendre. Dans cette veine, le générateur MARQUIS \citep{WannerMARQUISGENERATIONUSERTAILORED2010} génère du texte à partir de données numériques brutes sur la qualité de l'air, et les textes généres sont adaptés au lecteur. La \ac{GAT} a aussi fait une incursion dans le journalisme, ce qu'on appelle le \scare{robo-journalisme} \citep{W17-3513}. En effet, des articles ont été rédigés automatiquement à partir de données brutes (comme les statistiques d'un match, ou des données météorologiques).

Traditionnellement, un système de \ac{GAT} se divise en deux parties. La première étant ce que \cite{DanlosPresentationmodelegeneration1983} appelle le \emph{quoi-dire} et que \cite{gatt18} appellent le \emph{early process} qui équivaut à déterminer et structurer le contenu à transmettre. Autrement dit, il s'agit d'évaluer, parmi les données s'offrant à nous, lesquelles voulons-nous transmettre au lecteur et dans quel ordre. Ensuite il y a ce que Danlos appelle le \emph{comment-le-dire} puis que Gatt et Kramer appellent le \emph{late process} qui revient à choisir les unités lexicales qui serviront à véhiculer le \emph{quoi-dire}, on appelle cela la réalisation linguistique. Cette étape du processus de génération a fait l'\oe{}uvre de plusieurs travaux, entre autre parce qu'il y existe diverses approches pour l'effectuer. Nous nous concentrerons sur l'une d'entre elles: la réalisation linguistique à base de règles, qui correspond à modéliser les connaissances linguistiques d'une langue donnée à partir d'une grammaire et d'un dictionnaire.

Comme le lexique d'une langue est incommensurable, la plupart des réalisateurs profonds n'ont pas accès à tous les mots d'une langue ainsi que leurs propriétés lexicales (comment ils se combinent avec d'autres). Toutefois, la majorité des parties du discours présentent des régularités quant à leurs comportements syntaxiques, à l'exception des verbes qui forment la partie du discours la plus imprévisible. Ainsi, si on souhaite qu'un réalisateur génère du texte le plus naturellement possible, on devrait récupérer les propritésé lexicales des verbes qui sont, non seulement les moins prévisibles mais qui sont essentiellement au c\oe{}r des énoncés parce qu'ils contrôlent la structure des phrases. Cette problématique ne s'applique pas uniquement qu'à la \ac{GAT}, toutes les branches du \ac{TAL} bénéficierait d'un traitement approfondi des verbes pour toutes les tâches confondues en \ac{TAL}. \cite{SchulerVerbnetBroadcoverageComprehensive2005,Korhonenlargesubcategorizationlexicon2006} postulent qu'un meilleur traitement des langues naturelles passe par la connaissance des comportements syntaxiques des verbes. L'expression \scare{comportements syntaxiques} réfère aux arguments qu'une unité lexicale sélectionne, par exemple lorsqu'on dit qu'un verbe peut être à la fois transitif direct et intransitif, il s'agit là de deux comportements syntaxiques (intransitivité du verbe \lex{manger}: \form{Paul mange}, et transitivité: \form{Paul mange un dessert}). On encode généralement ces comportements dans des dictionnaires car on ne peut pas prédire les comportements des verbes à partir de règles grammaticales. \cite{MilicevicSchemaregimepont2009} illustre ce problème en montrant que deux verbes synonymiques exposent des comportements différents: \form{on se souvient de $X$}, mais \form{on se rappelle $X$}. L'obligation de la préposition dans la première construction est entièrement arbitraire, c'est pourquoi ce type d'information doit être encodé dans un dictionnaire pour qu'un système de \ac{GAT} sache comment réaliser ces constructions syntaxiques.

Ainsi, en détenant les propriétés syntaxiques des verbes d'une langue donnée, on arrive à couvrir une grande partie des constructions possibles pour cette langue. C'est pour cette raison que nous voulons intégrer au réalisateur profond GenDR un dictionnaire de comportements syntaxiques renfermant une quantité exhaustive des constructions possibles de l'anglais. GenDR, est un réalisateur profond multilingue qui reprend les bases du système MARQUIS et qui opère dans le cadre théorique de la \ac{TST}. De plus, GenDR a déjà fait l'objet d'un mémoire focusant sur sa capacité à rendre compte de phénomènes langagiers complexes comme les collocations \cite{LambreyImplementationcollocationspour2017, lareau18}.

La ressource lexicale que nous avons choisi pour améliorer la couverture de GenDR est VerbNet. Une base de données verbale créée dans un contexte où il y avait un réel besoin de faire un dictionnaire décrivant la richesse et la complexité des verbes \citep{KipperClassBasedConstructionVerb2000}. \cite{SchulerVerbnetBroadcoverageComprehensive2005} trouvait qu'il y avait un manque de lignes directrices par rapport à l'organisation des verbes dans les dictionnaires destinés à des applications \ac{TAL}. Son dictionnaire est organisé en une hiérarchie de classes verbales héritées de \cite{verb-classes.levin.1993}, qui proposait une méthode de classification des verbes basée sur le partage des comportements syntaxiques entre ceux-ci. Levin a tenté de délimiter tous les patrons de régime possibles pour les verbes de la langue anglaise. Lorsque plusieurs présentaient des caractéristiques communes sur le plan syntaxique, elle rassemblait ces verbes dans une classe.

Pour implémenter VerbNet à GenDR, nous avons utilisé l'environnement Python qui nous a permi de manipuler et d'extraire les données de la ressource lexicale choisie. En effet, nous avons du les manipuler pour que les informations marchent avec la Théorie Sens-Texte. Pour compléter l'implémentation de cette ressource, nous avons du revoir certaines règles de grammaire et l'architecture de nos dictionnaires pour tenir compte des nouvelles informations lexicales auxquelles nous aurons accès. Finalement, nous testerons le tout pour vérifier si l'intégration de VerbNet sera un succès.

Nous avons séparé ce mémoire en 6 chapitres dont les trois premiers correspondent à la préparation du projet et les trois derniers à l'exécution du projet. Ainsi, le premier chapitre décrit ce qu'est la \ac{GAT} en faisant un survol des six étapes du processus classique de génération de texte. Nous retiendrons la dernière étape du processus: la réalisation, et nous la décrirons en détails. Par après, nous présentons quelques réalisateurs pour montrer les différences théoriques et concrètes qui existent entre ceux-ci. Le deuxième chapitre porte entièrement sur le réalisateur profond GenDR. Nous décrivons comment ce réalisateur fait pour modéliser les phénomènes langagiers en expliquant en détails les modules qui le composent. Le troisième chapitre est dédié à la description de diverses ressources lexicales potentielles, mais nous focuseront leurs descriptions par rapport aux traitements des verbes que ces ressources font. Finalement, nous décrivons en détails la ressource VerbNet, puisque c'est celle qui correspond le plus à nos critères.

Dans le quatrième chapitre, nous expliquons comment nous avons utilisé Python pour faire des scripts nous permettant d'extraire les données de VerbNet que nous désirions importé. Puis, le cinquième chapitre décrit comment nous avons adatpé le réalisateur profond GenDR pour qu'il incorpore les données que nous avons extraite de VerbNet. Plus précisément, nous décrivons comment les règles de grammaire ont été adpatées ainsi que les dictionnaires. Finalement, le sixième chapitre renferme l'évaluation du système, ce qui consiste à expliquer le choix des méthodes d'évaluation ainsi que nos critères. Puis, pour conclure le tout, nous faisons une synthèse du travail en montrant la contribution de ce mémoire à l'état de l'art, puis nous évoquons quelques pistes à explorer.

\pagenumbering{arabic}