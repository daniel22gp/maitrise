%!TEX root = ../memoire.tex

\chapter*{Introduction}

% \noindent c'est mieux de changer la définition de \chapter et autres titres pour que ça soit uniforme

Depuis le siècle dernier, la communication en intelligence artificielle continue de nous fasciner. Ainsi, énormément de recherche s'est orientée vers le développement de système informatique pouvant communiquer avec les humains. Or, la communication implique deux processus: la compréhension du langage et la production de celle-ci. Ce sont deux concepts qui ont été approfondi par les scientifiques au cours des dernières décennies dans le domaine du \ac{TAL}. La \ac{GAT} est une branche du \ac{TAL} dont le but est de produire du texte compréhensible en langue naturelles à partir de données non-linguistiques. Les systèmes de \ac{GAT} se servent des connaissances linguistiques et des connaissances de domaine d'application pour générer automatiquement des documents.  Les premiers systèmes de \ac{GAT} ayant vu le jour ont été créés pour produire des rapports automatiquement dans le but d'alléger la charge de travail des humains \citep{ReiterBuildingNaturalLanguage2000}. Sinon, l'écriture de ces documents est effectuée par un humain, ce qui entraîne des coûts importants. Ainsi, la \ac{GAT} est un domaine de recherche menant vers des applications concrètes et utiles dans le monde réel.

La \ac{GAT} est aussi utilisée pour produire des documents résumant des informations complexes pour des gens n'ayant pas les connaissances de bases requises pour les comprendre ou le temps requis. Par exemple, MARQUIS \citep{WannerMARQUISGENERATIONUSERTAILORED2010} est un système générant de tels rapports à partir de données numériques brutes sur la qualité de l'air. La \ac{GAT} a aussi fait une incursion dans le journalisme, ce qu'on appelle le robo-journalisme \citep{W17-3513}. Ainsi, des articles journalistiques peuvent être produits à partir de données brutes dans le but d'informer les gens, sans qu'un humain soit derrière le texte.

Traditionnellement un système de \ac{GAT} se divise en deux parties. D'abord, ce que \cite{DanlosPresentationmodelegeneration1983} appelle le \emph{quoi-dire} et que \cite{gatt18} appellent le \emph{early process} qui équivaut à déterminer le contenu qu'on génèrera et le structurer. Autrement dit, il s'agit d'évaluer parmi les données s'offrant à nous, lesquelles voulons-nous transmettre et dans quel ordre, c'est la génération profonde. Ensuite il y a ce que Danlos appelle le \emph{comment-le-dire} puis que Gatt et Kramer appellent le \emph{late process} qui revient à choisir les unités lexicales qui serviront à transmettre le message prévu lors de la génération profonde, on appelle cela la réalisation linguistique.

En soi, la réalisation linguistique a fait l'objet d'énormément de recherche, ainsi il existe sur le marché un nombre impressionnant de réalisateurs. On les divise en deux catégories, les réalisateurs de surface et les réalisateurs profonds. Les premiers 

Nous avons développé GenDR, un réalisateur profond multilingue qui reprend les rouages de la réalisation du générateur MARQUIS. GenDR a déjà fait l'objet d'un mémoire focusant sur sa capacité à rendre compte de phénomènes langagiers complexes: les collocations. Notre mémoire s'inscrit aussi dans un contexte où on continue à chercher la meilleure manière de modéliser les connaissances linguistiques pour qu'un système de \ac{GAT} génère du texte le plus fluidement possible. 

L'objet de ce mémoire est de pourvoir GenDR d'une couverture linguistique beaucoup plus grande que celle qu'il a présentement en y intégrant VerbNet qui est une base de données lexicales décrivant les comportements syntaxiques de 6\,394 verbes. On devrait pouvoir modéliser toutes les constructions possibles par une langue en ayant des descriptions très précises des verbes puisque les verbes contrôlent la plupart des énoncés. 

\draft{Nous pensons que de telles ressources sont nécessaires puisque les verbes contrôlent la structure de la plupart des énoncés et ils démontrent une grande variété quant à leur comportement syntaxique (qui est très imprévisible). Ainsi, en détenant les propriétés lexicales des verbes d'une langue donnée, on peut couvrir une grande partie des constructions syntaxiques possibles pour cette langue.}

\draft{Notre objectif est d'intégrer au réalisateur profond GenDR un dictionnaire de cadre syntaxique des verbes de la langue anglaise. De plus, comme GenDR se veut multilingue, si l'expérience fonctionne bien, l'objectif serait d'acquérir d'autres ressources lexicales similaires dans d'autres langues afin d'exploiter GenDR au maximum de sa capacité.}

\draft{Ce que plusieurs appellent des \scare{comportements syntaxiques} sont encodés dans des patrons de régime en TST. D'abord, il faut préciser que ce qu'on appelle \ac{GP} se nomme de différentes manières selon le cadre théorique utilisé: cadre valenciel, valence, cadre de sous-catégorisation, cadre syntaxique ou schéma de régime. Selon \cite{MilicevicSchemaregimepont2009}, les \acp{GP} décrivent les cooccurrences syntaxiques d'un lexème avec les actants qu'il régit. Par exemple, la relation entre un verbe et son sujet, ou bien la relation entre un nom et le complément qu'il sélectionne. Autrement dit, les \acp{GP} d'une lexie correspondent à l'ensemble des constructions syntaxiques que la lexie régit. On encode ces constructions syntaxiques dans un dictionnaire, car les \acp{GP} des lexèmes sont généralement imprévisibles. En effet, on ne peut pas prédire le nombre d'actants qu'un prédicat gouverne, ou bien les prépositions qu'il régit. De plus, même des verbes sémantiquement proches ne possèderont pas nécessairement les mêmes constructions syntaxiques, ce qui est illustré par \cite{MilicevicSchemaregimepont2009}: \form{on se souvient de $X$}, mais \form{on se rappelle $X$}.}

\draft{L'une des raisons qui nous a poussé à nous tourner vers une ressource lexicale verbale provient des limites du logicel MATE quant à l'encodage de multiples patrons de régime pour une même entrée. Pour un verbe donné, on ne peut pas avoir deux parties du discours différentes qui compétitionnent pour la même position syntaxique. Autrement dit, si nous voulions exhaustivement représenter les comportements du verbe \lex{want}, il nous faudrait un \ac{GP} qui puisse tenir compte du fait que le second actant syntaxique de ce verbe peut avoir une \ac{DPOS} de type verbale ou nominale: \form{I want to eat} vs \form{I want a dog}. Cela nous était impossible à encoder dans MATE avec les paramètres que nous avions car le système ne nous laissait pas donner deux versions de l'actant syntaxique II de \lex{want}. Ce qui s'offrait à nous comme solution était de créer deux verbes \lex{want} qui encoderaient séparés ces comportements syntaxiques, ce qui n'était pas viable. Nous nous sommes alors tourné vers l'idée d'ajouter un dictionnaire supplémentaire à notre ressource, qui encoderait tous les régimes existants de l'anglais. Puis, nous n'aurions qu'à encoder l'identification des \ac{GP} dans les unités lexicales appropriées ce qui nous permettait de contourner le problème des \acp{GP} multiples.}

Notre ancienne méthode restreignait conséquemment le nombre de réalisations possibles pour un verbe donné ou peuplait inutilement le dictionnaire d'entrées verbales quasi-identiques mais qui se distinguaient en fonction des régimes différents. 

Nous pensons que GenDR sera amélioré grâce à cette implémentation. Plusieurs chercheurs dont \cite{SchulerVerbnetBroadcoverageComprehensive2005,Korhonenlargesubcategorizationlexicon2006} pensent qu'un meilleur traitement des langues naturelles passe par la connaissance des comportements des verbes. C'est pourquoi beaucoup de recherche s'est fait dans le but de développer des ressources lexicale computationnelle pour qu'elle soient utilisées dans tous les champs possibles du \ac{TAL}. Notamment les auteurs de VerbNet en s'inspirant de WordNet et FrameNet ont cru bon développer une ressource lexicala très riche ne focusant que sur les verbes. Nous pensons que la \ac{GAT} a beaucoup à gagner de ce type de ressource et nous tenterons d'implémenter VerbNet à notre système pour qu'il puisse réaliser le plus de phrases possibles. Cela agrandirait la couverture de GenDR et sa capacité de générer des phrases. Parler des comportements syntaxiques, Levin avait vu X, VerbNet a repris l'idée, et traite plus de 4000 vocables dont 6000 acceptions. Parler des patrons de régime, des verbes non prédictbles et pourquoi c'est important de les encoder.

Pour l'implémenter VerbNet à GenDR, nous avons utilisé le langage de programmation Python pour manipuler et extraire les données de VerbNet qui sont encodées en \emph{XML}. Ensuite, nous avons manipulé les données pour qu'elles s'insèrent dans notre système, de 1 parce que notre logiciel demande un code x et parce que la théorie dans laquelle nous nous insérons demandait de faire quelques ajustement aux données que nous avions extrait. Puis nous avons implémenté le tout à notre système en l'adpatant.

Ce mémoire est divisé en six chapitres. Dans le premier, nous décrirons les six étapes du processus classique en \ac{GAT}, puis nous approfondirons l'une de ces étapes: la réalisation. Nous décrirons en conséquence des réalisateurs de texte pour faire un état de l'art sur la réalisation linguistique. Ensuite, le deuxième chapitre porte entièrement sur un réalisateur profond nommé GenDR (TST, multilingue, héritier de MARQUIS), capable de modéliser bcp de phénomènes langagiers.. On décrira en détails les modules qui le composent et ces forces et faiblesses. Ne fonctionne pas avec des dictionnaires verbaux.Donc on veut l'upgrader avec un dict de verbes pour qu'il soit encore plus puissant. Le troisième chapitre fait un survol des dictionnaires pour augmenter notre couverture. Et nous terminons par décrire VerbNet, la ressource que nous avons choisi. Par après, nous entrons dans le quatrième chapitre qui traite de l'extraction de VerbNet à l'aide de scripts Python. Nous avons extrait les verbes, l'architecture de VerbNet et les comportements syntaxiques des diverses classes verbales. Puis, le cinquième chapitre décrit comment nous avons adatpé GenDR pour qu'il incorpore les données que nous avons extraite de VerbNet. Nous avons du revoir certaines règles de grammaire et la composition de nos dictionnaires. Finalement, le sixième chapitre renferme l'évaluation du système. D'abord nous avons expliqué comment nous procédons à l'évaluation puis nos critères et finalement ce que les données disent. Puis pour conclure le tout, nous faisons une synthèse du travail en montrant la contribution de ce mémoire à l'état de l'art, puis nous évoquons quelques pistes à explorer.

\pagenumbering{arabic}