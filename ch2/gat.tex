%!TEX root = ../memoire.tex

\chapter{Génération automatique de texte}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% --------- I N T R O   ---------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

La \acf{GAT} découle de la branche qu'est le \acf{TAL}. Reiter et Dale  définissent cette branche comme étant un domaine à la croisée des chemins entre l'intelligence artificielle et la linguistique computationnelle \citep{ReiterBuildingNaturalLanguage2000}. L'objectif de la \ac{GAT} est de développer des sytèmes pouvant produire du texte compréhensible en langue naturelle à partir de données (non-linguistiques). Bien que cet objectif soit commun à tous les générateurs de texte, il existe diverses méthodes pour y arriver. La diversité des méthodes est une conséquence directe de la combinaison des divers types d'input possibles et des multiples approches de réalisation. Effectivement, les systèmes de \ac{GAT} peuvent prendre en entrée du texte, des données et même des images \citep{thomason:coling14}. De plus, \cite{gatt18} notent qu'il y a un affaissement des frontières (systèmes hybrides) entre les méthodes traditionnelles de réalisation (à base de patrons, à base de règles, stochastiques).

Toutefois, avant d'entrer dans les détails de la \ac{GAT}, il serait pertinent de présenter l'origine de ces systèmes. À la base, ils ont été conçus pour générer des rapports automatiquement afin de faciliter le travail des êtres humains \citep{ReiterBuildingNaturalLanguage2000}. Effectivement, \cite{DaoustJSREALTextRealizer2015} expliquent que la \ac{GAT} nous permet de générer un résumé d'information compréhensible pour un humain, tandis que la lecture des données brutes lui seraient indéchiffrables. Ces tâches automatisées permettent d'éviter des coûts en termes de ressources et de temps. Autrement la production de tels rapport est faite par un humain (ressource) et celui-ci doit être payé (coûts) pour faire cette tâche.  

Les textes générés automatiquement n'ont pas besoin d'être lus par une quantité phénomènale de gens pour être considérés utiles. Dès qu'ils remplissent leur fonction auprès d'une poignée de gens, leur raison d'être est justifiée. Ces textes produits automatiquement peuvent aussi être extrêmement adaptés à leur public. Des systèmes de \ac{GAT} peuvent générer du texte en fonction du lecteur. Effectivement, quelques systèmes de \ac{GAT} ont intégré l'aspect utilisateur à leur génération de texte. Il est donc possible de générer un rapport quelconque en fonction du niveau de compréhension des données d'un utilisateur donné. Par exemple, un professionnel, un technicien ou un client \citep{1948c0b7a8ca42679cad977bb2cdddc2} se verraient offrir des rapport différents. 

D'autres chercheurs ont aussi poussé la \ac{GAT} vers le domaine journalistique. Il y avait une forme de demande pour cette branche qu'est le robo-journalisme. Un contexte propice à ce genre de système est le manque de couverture médiatique d'un match sportif. Graĉe au robo-journalisme, on peut générer un résumé d'un match à partir des données brutes de celui-ci. Par exemple, on peut savoir: qui a compté, à quelle minute, les fautes, etc. \citep{W17-3513}.

Il est aussi important de préciser que la \ac{GAT} présente une valeur linguistique théorique. En effet, de nombreux linguistes ont testé leurs théories en développant des générateurs automatique de texte pour vérifier si leur modélisation de la langue fonctionnait dans un système computationnel \citep{DanlosPresentationmodelegeneration1983}. 

\draft{ce paragraphe est un peu tout seul, je dois mieux l'intégrer}Dans le cadre de ce mémoire, nous élaborerons plus précisément sur une partie du processus de la \ac{GAT}: la réalisation. Cependant, avant de décrire cette étape, nous allons jeter les bases de la \ac{GAT} en décrivant le pipeline classique.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% --------- P I P E L I N E   ---------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Pipeline classique GAT} \label{ppc}

Traditionnellement, la \ac{GAT} est un processus ordonné qu'on sépare en diverses étapes. Selon \cite{ReiterBuildingNaturalLanguage2000}, les six étapes suivantes sont celles qui forment normalement un système de génération. Nous les illustrons à la figure~\ref{fig:Pipeline}.
\begin{figure}[htb] % utilise toujours [htb]
	\centering
	\includegraphics[width=1\textwidth, trim = {0cm 0cm 0cm 0cm},clip]{ch2/figs/pipeline.pdf}
	\caption{Pipeline classique}
	\label{fig:Pipeline}
\end{figure}

Beaucoup s'entendent pour dire qu'on peut séparer la \ac{GAT} en deux parties majeures. Le \emph{quoi-dire} et le \emph{comment-le-dire} selon \citep{DanlosPresentationmodelegeneration1983} qui correspondent aux \emph{early process} et \emph{late process} selon \cite{gatt18}. Le \emph{quoi-dire} fait référence à la sélection du contenu,la structuration du document et l'agrégation. Puis le \emph{comment-le-dire} fait référence à toutes les étapes subséquentes : la lexicalisation, la génération d'expressions référentielles et la réalisation linguistique. Pour mieux comprendre ce processus séquentiel , nous décrirons en quelques lignes chacune des étapes qui le compose.

\subsection{Sélection du contenu}
Un système de \ac{GAT} doit départir les informations qui seront dans le texte de celles qui n'y seront pas. La sélection du contenu dépend essentiellement du public à qui le texte est adressé et de l'objectif du texte. Par exemple, si un texte s'adresse à un novice dans un domaine quelconque, alors le niveau de détails à produire devra correspondre aux compétences de l'utilisateur. Il faut donc faire des choix quand au contenu qui sera généré. Dans le domaine du sport, si on souhaite généré un compte rendu du match, il faudra choisir quelles données on garde de celles qu'on ne gardera pas. On ne voudrait probablement pas réaliser en langue naturelle toutes les passes et les fautes commises durant ce match même si ces informations figurent dans les données de base.

\subsection{Structuration du document}
Après avoir sélectionné le contenu, un système de \ac{GAT} doit décider l'ordre dans lequel les informations sélectionnées apparaîtront. Cette étape est une représentation ordonnée et structurée de messages à transmettre.  Reprenons l'exemple du soccer. En fonctions des données choisies, le texte devrait débuter par les informations générales liées au match (où et quand le match s'est déroulé), suivi du noms des équipes qui s'opposaient, puis des points importants du match et en terminant par l'issue de celui-ci. Bref, il s'agit de créer le plan du texte. 

\subsection{Agrégation}
L'agrégation est l'étape où on combine des messages en une seule phrase afin de rendre le texte plus fluide et agréable à lire. Les messages sélectionnés dans le plan (structuration du document) n'ont pas à être exprimé dans des phrases individuelles si on est capable de les combiner \citep{ChengCapturingInteractionAggregation2000}. Bref, cette étape sert à éviter la redondance.

\subsection{Lexicalisation}
À cette étape, on peut commencer à traduire les données non-linguistiques en langue naturelle. Cette partie est très importante car on y sélectionne les mots qui seront utilisés pour transmettre le message. Comme il existe naturellement plusieurs manières pour traduire une même idée en mots, cette tâche peut devenir assez complexe si on veut que le système puisse tenir compte de la réalité du langage. La sélection des mots peut ainsi se faire à divers niveaux d'abstractions. Un niveau plus abstrait requière plus de travail et est plus complexe à mettre en place, mais génère plus de possiblités au moment de la réalisation. \cite{ElhadadFloatingConstraintsLexical1997} postulait dès le début une approche en faveur de la lexicalisation profonde.

\subsection{Génération d'expressions réferentielles}
Cette opération est très similaire à la lexicalisation car on choisit comment se réaliseront certaines entités. On l'appelle "l'étape discriminatoire". Le but est de s'assurer que le lecteur puisse distinguer correctement chaque entité. Pour cela, il faut trouver la meilleure façon de référer à une entité.

\subsection{Réalisation linguistique}\label{real}
La dernière étape est la réalisation linguistique. Lorsque tous les mots et les expressions référentielles ont été choisis, on peut réaliser le texte final. Cette tâche implique l'application de traits morpho-syntaxiques aux lexèmes et la linéarisation des structures. Elle inclut aussi l'insertion des mots fonctionnels (auxiliaires, déterminants,etc.) et la ponctuation. \draft{question pour françois: est-ce que le passage de concept à la syntaxe se fait en même temps que la lexicalisation dans ces systèmes ?}

À ce sujet, il existe plusieurs approches effectuant la réalisation linguistique. Nous les présenterons brièvement.

\subsubsection{À base de patrons}
Cette approche est utilisée pour générer du texte dans des domaines précis comme la météo ou les sports. Dans ces contextes, les variations linguistiques sont réduites au minimum puisque chaque réalisation de texte se fait à partir d'un moule fixe \citep{mcroy_channarukul_ali_2003}. Les phrases en \ref{template} provenant de l'article de \cite{gatt18} démontrent comment les patrons s'utilisent.

\ex. \label{template} \emph{À base de patrons}
	\a.\$player scored for \$team in the \$minute minute. 
	\b. Ivan Rakitic scored for Barcelona in the 4th minute.

En \ref{template}, le patron contient trois variables marquées par les \$. Celles-ci peuvent être respectivement comblées par un nom de joueur, suivi d'un nom d'équipe et d'une indication temporelle. Cet exemple démontre bien l'avantage d'utiliser des réalisateurs à base de patrons. Ces systèmes permettent de prévoir ce qui sera généré en output et cela diminue les risques d'erreurs. Toutefois, puisqu'ils sont codés à la main, ces sytèmes ont l'inconvénient d'être coûteux en termes de temps. Cependant, les réalisateurs à base de patrons peuvent être complémentés par des règles de grammaire, ce qui les rend plus flexibles. Ils peuvent aussi être combinés à de l'apprentissage machine. Cela automatise l'écriture des patrons et rend la tâche moins coûteuse en termes de temps \citep{gatt18}.

\subsubsection{À base de règles grammaticales}
Les modèles à base de règles grammaticales s'emploient autant dans les domaines spécifiques (météo et sport) que les domaines généraux (le parler quotidien). Effectivement, ils se prêtent bien à la réalisation du parler quotidien \draft{y-a-t-il une meilleure manière de dire 'parler quotidien' ?}car ils sont créer pour réaliser du texte de la manière la plus humaine et naturelle possible. Dans ces systèmes, la combinaison de règles de grammaire et de dictionnaires mèneront à la bonne formation de phrases. Cependant, les grammaires et dictionnaires sont codés manuellement, ce qui demande du temps et des ressources.

\subsubsection{Statistiques}
Il existe divers emplois des méthodes statistiques. On peut les utiliser pour filtrer les sorties d'un système. Dans ce contexte, les statistiques détermineront quel output est le meilleur candidat \citep{LangkildeForestbasedStatisticalSentence2000}. On appelle cela l'approche \emph{generate-and-filter}. Avec cette méthode, on utilise encore un noyau de règles manuellement encodées. Toutefois, il existe aussi des approches statistiques de réalisation n'utilisant pas de noyau de règles manuellement encodés. Dans ce contexte, les règles sont apprises automatiquement par apprentissage machine via de large corpus \citep{WhiteMinimalDependencyLength2012}. Cela diminue considérablement la charge de travail manuelle.

\subsubsection{Approches à base de règles versus approches statistiques}

Traditionnellement, les systèmes de \ac{GAT} tendaient vers des systèmes encodés manuellement. Mais, de tels systèmes nécessitaient du temps et des ressources. Cela a poussé plusieurs chercheurs à automatiser la réalisation linguistique \citep{LangkildeForestbasedStatisticalSentence2000}. L'avantage immédiat de tels systèmes est leur demande plus faible en termes de temps et de ressources. 

\cite{BelzSystemBuildingCost2009}, dans un article, s'est demandé si le temps qu'on gagnait en automatisant la réalisation se faisait au détriment de la qualité. Et si c'était le cas, à quel point la qualité de l'output en est affectée. L'évaluation s'est faite en utilisant un système à base de règles, puis un système statistique pour effectuer la même tâche de réalisation. L'évaluation se faisait en deux temps. D'abord une évaluation humaine pour traiter la qualité des outputs des deux systèmes, puis une évaluation métrique faite automatiquement. Suite à l'analyse de l'évaluation, Belz nous démontre que les évaluations humaines pointaient en faveur des systèmes à base de règles. De plus, elle suggère que certaines évaluations métriques surévaluaient parfois les systèmes statistiques et sous-évaluaient les systèmes manuels\citep{BelzSystemBuildingCost2009}.  

D'ailleurs, de son côté, Reiter s'est aussi penché sur la question et a fait un survol du sujet dans son blog \citep{ReiterNaturalLanguageGeneration2016} \draft{vérifier comment citer un blog}. Selon lui, même si les systèmes d'apprentissage machine génèrent du bon texte la plupart du temps, ils peuvent occasionnellement générer du texte bizarre et inapproprié. Il souligne aussi que les évaluations des systèmes statistiques sont souvent basés sur la moyenne du texte généré correctement. Cela ne rend pas compte de l'ampleur de certaines erreurs générées automatiquement. Ce comportement n'est pas approprié dans des domaines professionnels ou personnels où des utilisateurs comptent sur la qualité des textes générés automatiquement, entre autre, car ils prendront potentiellement des décisions en fonction de leur lecture. De plus, Reiter ajoute que lorsque des incongruités sont générées, les systèmes basés sur des méthodes statistiques ont plus de difficulté à les corriger. En revanche, les systèmes à base de règles permettent de cerner les problème avec plus de facilité et de les corriger en rectifiant la règle problématique directement. Cependant, Reiter termine son blog en soulignant que la \ac{GAT} a beaucoup à gagner grâce aux méthodes statistiques. Il suggère de se servir de celles-ci pour automatiser des parties du processus de réalisation à base de règles.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% --------- R É A L I S A T I O N   ---------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Réalisation}

Puisque nous avons maintenant traité du processus global de \ac{GAT} et des différentes méthodes de réalisation, nous pouvons entrer dans les détails de la tâche qu'est la réalisation linguistique. À ce sujet, notre projet concerne strictement la réalisation. C'est pourquoi, pour une meilleure compréhension de cette étape du processus de \ac{GAT}, nous décrirons en détails quelques réalisateurs brièvement.

Tel qu'explicité à la figure~\ref{fig:Pipeline}, la réalisation est la dernière étape dans le processus de \ac{GAT}. Toutefois, pour beaucoup de chercheurs, elle ne représente pas uniquement les tâches décrites précédemment. Il règne une ambiguité quant aux concepts qu'incarne la réalisation. Pour certains, la réalisation correspond exactement à ce qu'on a présenté dans la section \ref{real}. On appellera cela la réalisation de surface, puisque la réalisation se fait à partir d'un input beaucoup plus près du texte (des structures syntaxiques lexicalisées). Pour d'autres, la réalisation se fait à partir de données plus abstraites, en amont de la lexicalisation. Ce type de réalisation plus profonde prend généralement en input des structures pré-syntaxiques. On les appellera des réalisateurs profonds. Dans ces systèmes, les informations lexicales et grammaticales seront encodées dans des dictionnaires et des grammaires plus complexes permettant de traiter l'interace sémantique-syntaxe. Finalement, ces systèmes profonds sont généralement liés à une théorie linguistique leur permettant de modéliser le langage et de l'encoder dans un système informatique.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% --------- R É A L I S A T E U R   S U R F A C E ---
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Réalisateurs de surface}

Dans cette section, nous vous présenterons quelques réalisateurs de surface en commençant par SimpleNLG, puis JSreal et finalement RealPro.

\subsubsection{SimpleNLG}
SimpleNLG est \citep{GattSimpleNLGRealisationEngine2009} est un réalisateur de surface écrit en java. Le texte est réalisé à partir d'une structure syntaxique déjà lexicalisée encodée en XML. Par la suite, le réalisateur opère les opérations morphologiques nécessaires (flexion, dérivation des mots, linéarisation, ajout d'auxiliaires, gestion de l'accord) tout en linéarisant le texte.

Puisqu'il s'agit d'un réalisateur à base de règles, SimpleNLG est évidemment doté d'une grammaire et d'un dictionnaire. Ce dernier encode les propriétés syntaxiques et morphologiques des unités lexicales. Puis, le module grammatical contient des règles permettant le passage de la syntaxe à la morphologie.

SimpleNLG sépare son processus de réalisation en quatre étapes. Premièrement, les lexèmes compris dans la structure d'input sont mis en correspondance avec leurs entrées de dictionnaire. Deuxièmement, déterminer les traits spécifiques des lexèmes. Troisièmement, on combine les lexèmes en créant des syntagmes de plus en plus large, jusqu'à ce que l'entièreté de la phrase forme un syntagme phrastique. Finalement, celui-ci est linéarisé puis les lexèmes sont accordés en fonction des règles morphologiques pour obtenir les formes fléchies.

\draft{mettre les citations dans references.bib}Noter que SimpleNLG a été traduit dans plusieurs langues : espagnol, italien, et français, portugais (Mazzei et al., 2016, Ramos-Soto 2017, Vaudry et Lapalme 2013 ; Oliveira et Sripada).

\draft{utiliser les formats de descriptions de phrase TST}La figure \ref{simplenlg} permet de réaliser la phrase 'Refactoring is needed.'Elle provient du GitHub de simplenlg \draft{mettre le lien dans la biblio: https://github.com/simplenlg/simplenlg/blob/master/docs/XMLRepresentationOfTextSpecifications.pdf}

\begin{lstlisting}[language=Xml, caption=Structure d'input dans SimpleNLG, label=simplenlg]
<Document>
  <child xsi:type="SPhraseSpec">
    <subj xsi:type="VPPhraseSpec" FORM="PRESENT_PARTICIPLE">
      <head cat="VERB">
        <base>refactor</base>
      </head>
    </subj>
    <vp xsi:type="VPPhraseSpec" TENSE="PRESENT" >
      <head cat="VERB">
        <base>be</base>
      </head>
      <compl xsi:type="VPPhraseSpec" FORM="PAST_PARTICIPLE">
        <head cat="VERB">
          <base>need</base>
        </head>
      </compl>
    </vp>
  </child>
</Document>
\end{lstlisting}

\subsubsection{JSreal}
JSreal \citep{DaoustJSREALTextRealizer2015} qui signifie JavaScript Realiser est un réaliseur de texte conçu pour les programmeurs web. Ce réalisateur génère des expressions et phrases bien formées qui peuvent être formattées en HTML pour ensuite être utilisées dans un fureteur. JSreal peut aussi s'employer seul à des fins purement linguistiques. Généralement, les spécificités de JSreal sont assez similaires à celles de SimpleNLG \citep{GattSimpleNLGRealisationEngine2009}.

Pour générer du texte JSreal prend en input des structures syntaxiques lexicalisées. La construction de la phrase découle de l'application de règles syntaxiques et morphologiques déclenchées par les lexèmes. JSreal fonctionne aussi avec un dictionnaire et une grammaire. Son dictionnaire défini la catégorie des lexèmes qui le peuple et leurs traits lexicaux (genre, nombre, irrégularités, etc.). La grammaire de JSreal contient des règles morpho-syntaxiques qui lui permettent de faire l'accord entre les constituants. Finalement, il existe aussi une version bilingue de JSreal \citep{MolinsJSrealBBilingualText2015} qui incorpore le français et l'anglais.\draft{Présenter la phrase correctement en TST}La figure \ref{jsreal} produit la phrase :'The cat sat on the coach.' Cet exemple est tiré du GitHub de JSreal B\draft{https://github.com/rali-udem/JSrealB}

\begin{lstlisting}[language=Xml, caption=JSreal, label=jsreal]
JSrealLoader({
        language: "en",
        lexiconUrl: URL.lexicon.en,
        ruleUrl: URL.rule.en,
        featureUrl: URL.feature
    }, function() {
    QUnit.test( "Sentence EN", function( assert ) {
        assert.equal(
            S(
                NP(D("the"), N("cat")),
                VP(V("sit"), PP(P("on"), NP(D("the"), N("coach")))).t("ps")
            )
        
\end{lstlisting}
		
\subsubsection{RealPro}
RealPro est implémenté en C++ \citep{LavoieFastPortableRealizer1997}. Il est le plus profond des réalisateurs de surface préséntés jusqu'ici. Il prend en input des arbres de dépendances, ce qui le distingue des inputs présentés (arbres de constituant) jusqu'ici \citep{DaoustJSREALTextRealizer2015},\citep{GattSimpleNLGRealisationEngine2009}. L'architecture de RealPro est basé sur la TST \citep{melcuk1988}. Brièvement, il s'agit d'une théorie qui divise le langage en divers niveaux de représentations. Le niveau le plus abstrait étant la sémantique, puis la syntaxe,  suivie de la morphologie , et de la parole (ou du texte dans ce contexte). Pour plus de détails concernant les arbres de dépendances et la TST, nous vous référons au chapitre suivant.

Le passage de la syntaxe profonde à celle de surface est la première étape pour réaliser du texte dans ce système. Pour ce faire, le logiciel effectue la transition en utilisant le module de dictionnaire et de grammaire. Les modules dictionnairiques et grammaticaux sont donc réquisitionnés par les diverses composantes du réalisateur au cours de la génération. Le graphique \ref{fig:RealPro} démontre leurs intéractions. \draft{élaborer sur le fonctionnement de RealPro}
\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth, trim = {0cm 0cm 0cm 0cm},clip]{ch2/figs/realpro.pdf}
	\caption{RealPro}
	\label{fig:RealPro}
\end{figure}

La figure \ref{realpro} est un arbre de dépendance (input) représentant la phrase \draft{changer le format de l'exemple} 'March had some rain days.'
\begin{lstlisting}[language=Xml, caption=Input, label=realpro]
HAVE1 [tense:past]
(I March [class:proper-noun]
II day [class:common-noun numberpl]
(ATTR rainy [class:adjective]))
\end{lstlisting}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% --------- R É A L I S A T E U R    P R O F O N D  ---
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Réalisateurs profonds}

Maintenant que nous avons exposé quelques générateurs de surface, nous présenterons quelques réalisateurs profonds. Ceux-ci prennent généralement en input des structures plus abstraites. Cela entraîne une plus grande flexibilité linguistique dans le contenu généré. La raison est la suivante, les réalisateurs profonds incorporent généralement la lexicalisation, ce qui fait en sorte que les concepts à réaliser ne sont pas encore fixés \citep{PolguerePourmodelestratifie}. Cela permet de faire usage des paraphrases puisqu'on peut désormais exprimer une même idée en de diverses manières. Dans le pipeline classique, comme nous l'avons vu à la section \ref{ppc}, la lexicalisation est opérée avant la réalisation. Cela fait en sorte que les inputs contiennent déjà des lexèmes et cela restreint grandement les réalisations possibles puisque les lexèmes incorporent des propriétés de combinaitoires bien précises et la phrase à générer doit s'articuler autour de ces contraintes. 

Dans cette section, nous présenterons les réalisateurs profonds suivants: KPML, Surge, FORGe et MARQUIS.

\subsubsection{KPML}
KMPL\citep{BatemanEnablingTechnologyMultilingual1997} est un réalisateur multilingue et héritier du système PENMAN \citep{PenmanOverview}. La théorie linguistique sous-jacente à ce système est la \acf{SFG} \citep{MatthiessenSystemicfunctionalgrammar1997}. Cette théorie postule que les choix linguistiques sont déclenchés par l'exécution d'une fonction. D'un point de vue multilingue, les différentes langues issues de KPML partagent un grand nombre de fonctions. Ces fonctions sont au coeur du système, puis il existe quelques fonctions propres à chaque langue pour réaliser les phénomènes linguistiques spécifiques à chacune d'entre elle. Autrement dit, dans ce formalisme, la forme de surface est la conséquence directe de la sélection d'un ensemble de traits fonctionnels abstraits à partir des réseaux systémiques. Dans ce formalisme, la réalisation linguistique se fait en traversant ces réseaux. La grammaire de ce système est implémentée à la manière d'un réseau de système orienté qu'on lit de gauche à droite. Les intersections dans le réseau correspondent à un choix grammatical à faire entre différents traits fonctionnels. Ces choix grammaticaux deviennent de plus en plus précis à force d'avancer dans le réseau. \draft{pas 100\% compris KPML}

Les informations comprises dans les inputs de ce système sont d'ordre sémantiques et syntaxiques. Plus précisément, KPML prend des \acf{SPL} en entrée. Un \ac{SPL} est une matrice dont les objets sont des paires d'attributs et de valeurs. Afin d'illustrer à quoi ressemble l'input, nous vous présentons la figure \ref{kpml} qui provient de \cite{ReiterBuildingNaturalLanguage2000} \draft{mettre la phrase dans le bon format: 'March had some rainy days'.}
\begin{lstlisting}[language=Xml, caption=SPL: input de KPML, label=kpml]
(S1 \ generalized-possession
  :tense past 
	:domain (N1 \ time-interval
	            :lex march
							:determiner zero)
	:range (N2 \ time-interval
	           :number plural
						 :lex day
						 :determiner some
						 :property ascription
						 (A1 \ quality :lex rainy)))
\end{lstlisting}

\subsubsection{Surge}
Surge, qui signifie \emph{Systemic Unification Realisation Grammar of English}, est une grammaire de l'anglais\citep{Elhadad98surge:a}. Elle est écrite en \acf{FUF} qui est basé sur \acf{FUG} \citep{KayFunctionalUnificationGrammar1984}. \ac{FUF} est un langage de programmation créé pour construire des grammaires computationnelles pour faire de la réalisation dans un cadre de grammaire d'unification.

\ac{FUF} prend en entrée des \acf{FD} qui décrivent à la fois le sens d'une phrase et la grammaire \draft{le sens de la phrase OK, mais la grammaire comment ?}.Les descriptions fonctionnelles sont aussi des matrices de paire d'attributs et de valeurs. Leur union fournit une spécification de l'énoncé à réaliser. Contrairement aux autres réalisateurs présentés ici, le modèle \ac{FUF} n'utilise pas de module de dictionnaire car l'information lexicale est encodée directement dans la structure d'input (voir la figure \ref{surge}).

Dans Surge, la réalisation se fait en deux temps. D'abord, on procède à l'unification des \ac{FD} du sens de la phrase à réaliser. Autrement dit, on enrichie la structure d’entrée avec les spécifications syntaxiques et morphologiques de la grammaire. Puis, \ac{FUF} effectue la linéarisation de la structure afin de réaliser la phrase et les contraintes morpho-syntaxiques sont opérées (l'accord, les constructions syntaxiques, etc.)

Nous reprendrons encore un exemple tiré de Dale et Reiter \cite{ReiterBuildingNaturalLanguage2000} \draft{mettre la phrase dans le bon format: 'March had some rainy days'.}
\begin{lstlisting}[language=Xml, caption=FD: input de Surge, label=surge]
((cat clause)
 (proc ((type possessive)))
 (tense past)
 (partic ((possessor ((cat proper) head ((lex "March"))))
					(possessed ((cat common) head ((lex day)))
											(describer ((lex rainy)))
											(selective yes) (number plural)))))
\end{lstlisting}

\subsubsection{FORGe}
FORGe est un transducteur de graphes qui génère du texte à l'aide de ressources lexicales dictionnairiques et grammaticales \citep{MilledemoFORGePompeu2017},\citep{DBLP:conf/semeval/MilleCBW17}. C'est un réalisateur profond qui a hérité de l'architecture de Marquis \citep{WannerMARQUISGENERATIONUSERTAILORED2010}. FORGe a été conçu pour l'anglais à la base, mais il se veut multilingue (espagnol, allemand, français et polonais sont en développement). C'est un réalisateur qui peut aisément générer du texte en différentes langues grâce à ses règles grammaticales qui seront majoritairement partagées par toutes les langues. Les règles fonctionnant pour l'anglais ont ainsi été conçues pour pouvoir fonctionner avec d'autres langues.

La théorie linguistique sous-jacente à ce système est la Théorie Sens-Texte \draft{quel livre sur la TST devrais-je citer ?}. D'ailleurs nous verrons plus en détails dans la section \ref{chapgendr} au chapitre suivant comment cette théorie linguistique se prête à des transducteur de graphes.

FORGe, prend en input des représentations sémantiques en graphes acycliques. Ces structures sont formées de relations prédicats-arguments et les unités qui les composent sont de types sémantiques (pas encore lexialisées). Pour visualiser de quoi on parle ici, nous vous référons à la structure \#2 dans la figure \ref{fig:marquis} de la section MARQUIS \ref{sectionmarquis}. La réalisation de texte dans FORGe se découpe en trois étapes : le transfert de la RSem à la RSyntP, suivi du transfert de la RSyntP à la RSyntS, et finalement de la RSyntS au texte linéarisé et morphologisé. \draft{mettre RSem et cie. au début dans la section Acronyme}

Le passage de la sémantique à la syntaxe profonde est effectué via un algorithme récursif de type \emph{top-down}. Tel que nous le verrons cet algorithme est aussi appelé l'arborisation. Nous en parlerons en détails dans le chapitre suivant à la section \ref{} \draft{mettre la section.}. Brièvement, le \emph{top} est la racine de l'arbre de dépendance en développement. Ce top est un noeud vide mais contraints par une partie du discours. On veut que le lexème qui consommera le noeud corresponde à la partie du discours requise par celui-ci. Une fois que le \emph{top} est lexicalisé, on crée de nouvelles branches partant de la racine. Ces branches correspondent aux dépendants du \emph{top}. Ensuite, on crée l'arbre de dépendance en correspondance avec le graphe sémantique d'input. Cette construction se fait sur les bases du dictionnaires et de la grammaire pour que l'arbre final soit la correspondance de l'input et qu'il soit grammatical. Bref, on répète les tâches d'arborisation jusqu'à ce qu'on ait analysé la représentation sémantique au complet.

Ensuite, il faut faire le passage de la syntaxe profonde à la syntaxe de sufrace. Cela correspond à l'étape où on introduit les mots fonctionnels(prépositions, auxiliaires, déterminants) et les relations de surface (sujet, objet direct, etc.). C'est là que FORGe se démarque de MARQUIS. Ils utilisent un dictionnaire de verbes qui explicitent les comportements des verbes en syntaxe. Cela permet de rendre compte de la richesse linguistique qu'apportent les verbes. Puisque les verbes sont généralement ceux qui gouvernent la structure de la phrase, les dictionnaires de verbes permettent donc de tenir compte d'un nombre impressionnant de constructions. Nous reviendrons à cette problématique dans la section problématique \ref{problema} au chapitre suivant \ref{chapgendr}.

Finalement, la dernière étape de ce réalisateur consiste à à linéariser la structure syntaxique de surface pour en générer un texte final et à appliquer les règles morpho-syntaxiques aux lexèmes.

\subsubsection{MARQUIS}\label{sectionmarquis}
Contrairement aux autres systèmes présentés ici, MARQUIS n'est pas qu'un réalisateur profond. Il s'agit d'un système de \ac{GAT} complet qui effectue toutes les étapes du processus de génération automatique de texte (voir \ref{ppc}). Cependant, nous ne nous intéresserons ici qu'à son aspect de réalisation profonde. Pour plus d'informations concernant le processus complet de MARQUIS, nous vous réferons à cet article \citep{WannerMARQUISGENERATIONUSERTAILORED2010}. 

Le but du projet MARQUIS est de générer, à partir de données brutes, des bulletins météorologiques multilingues sur la qualité de l'air. Ces bulletins sont générés en fonction de l'utilisateur. Autrement dit, ceux-ci se créent des profils avec leurs informations personelles et cela permettait à MARQUIS de réaliser du texte en fonction de leur niveau de compréhension des données (et de leurs besoins de santé). Le tout est fait à partir d'un input conceptuel. Celui-ci est partagée par toutes les langues traitées par MARQUIS (l'anglais, l'allemand, l'espagnol, le catalan, le portugais, le français, le finnois et le polonais). Comme FORGe \citep{MilledemoFORGePompeu2017} et RealPro \citep{LavoieFastPortableRealizer1997}, le fonctionnement de MARQUIS est basé sur la théorie Sens-Texte \citep{melcuk1988}.

Afin de mieux démontrer le processus de réalisation de MARQUIS et de FORGe (bien que l'input de FORGe commence à la structure \#2). La figure \ref{marquis} suivante représente les diverses étapes entreprises par MARQUIS pour rélaiser du texte.

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth, trim = {0cm 0cm 0cm 0cm},clip]{ch2/figs/marquis.pdf}
	\caption{Pipeline de MARQUIS}
	\label{fig:marquis}
\end{figure}

À la lecture de la figure \ref{marquis}, on voit que MARQUIS prend effectivement en input des graphes conceptuels et rend en sortie du texte. Entre ces deux étapes, il y a une série de changements successifs de représentations. Ces changements de représentations sont assurés par: l'information lexicale encodée dans les dictionnaires et les modules de règles qui modélisent chaque interface. 

Nous expliquerons brièvement les mécanismes qui permettent la transition d'une représentation à une autre puisque le tout sera mieux expliquée à la section \draft{mettre la section de GenDR}. Alors, il faut d'abord que le système analyse la structure conceptuelle. Ensuite les règles de transductions permettront de passer de la représentation conceptuelle à la représentation sémantique. Le passage des unités conceptuelles aux unités sémantique se fait via l'entremise des dictionnaires respectifs. Par après, on a maintenant une structure sémantique. MARQUIS prendra ce graphe acyclique pour le traduire en arbre de dépendance syntaxique profond grâce aux règles de transductions de cette interface. Les changements d'unités sémantiques à lexicales sont opérés grâce au semanticon et au lexicon ainsi qu'au dictionnaire de fonctions lexicales. Finalement, les autres transitions de représentations sont assurées par des règles de transductions successives et les informations contenues dans le lexicon. La figure \ref{fig:reglesdict} démontre ces rouages.
\begin{figure}[htb]
	\centering
	\includegraphics[width=1\textwidth, trim = {0cm 0cm 0cm 0cm},clip]{ch2/figs/module.pdf}
	\caption{Combinaison des règles et dictionnaires}
	\label{fig:reglesdict}
\end{figure}

Pour mieux comprendre à quoi servent les dictionnaires mentionnés dans le paragraphe précédent, nous les décrirons rapidement. Le dictionnaire conceptuel comprend tous les concepts utiles à la génération des rapports sur la qualité de l'air et des termes du domaine général. Ce dictionnaire mappe les concepts aux unités sémantiques pour chaque langue traitée par le système. Le dictionnaire sémantique mappe les unités sémantiques aux lexies. Finalement, il nous faut un dictionnaire lexémique qui contient toutes les unités lexicales et leurs propriétés syntaxiques et morphologiques.

En conclusion, MARQUIS et FORGe partent de niveaux d'abstraction plus profond que les autres systèmes présentés. Cela leur permet d'être beaucoup plus flexible dans leur réalisation linguistique. C'est pourquoi nous utilisons aussi un réalisateur profond doté de paramètres très similaires à ces deux réalisateurs. Comme FORGe, nous utiliserons aussi un système basé sur MARQUIS. Il s'agit de GenDR \citep{lareau18}: un projet en cours de développement dirigé par François Lareau à l’Observatoire de linguistique Sens-Texte. Le chapitre suivant décrira en détails ce réalisateur.