%!TEX root = ../memoire.tex

\chapter{Importation de VerbNet dans GenDR}\label{ch:python}

Nous avons écrit un script en Python pour automatiser en grande partie l'importation des données de VerbNet dans GenDR. Nous avons utilisé le module \emph{xml.etree.cElementTree}\footnote{\url{https://docs.python.org/3/library/xml.etree.elementtree.html}, 01-06-17} pour manipuler et extraire les fichiers \emph{XML} qui contiennent l'information de VerbNet. Ensuite, les scripts génèrent en sortie des informations dans des fichiers \emph{.dict} que nous avons formattés pour MATE. Ceux-ci ne seront pas utilisés tels quels dans GenDR, car ce que nous générons avec chaque script correspond parfois à une section d'un dictionnaire. Par exemple, nous extrayons l'architecture de VerbNet à l'aide d'un script, toutefois, le fichier en soi contenant ces informations ne correspondra pas directement à un fichier que nous intégrerons à GenDR. Il fera partie du \emph{lexicon}. Nous avons ainsi créé trois dictionnaires temporaires à l'aide des scripts Python: un dictionnaire qui décrit les classes verbales, un dictionnaire qui mappe les unités lexicales sur leur classe VerbNet, et un dictionnaire de patrons de régime. L'information contenue dans les deux premiers dictionnaires sera intégrée au \emph{lexicon} de GenDR, ce qui impliquera quelques changements au niveau de l'architecture de ce dictionnaire. Puis, le dictionnaire de patrons de régime est placé dans un fichier à part, ce sera le \emph{gpcon} et en ce qui concerne le semanticon, il gardera la même architecture qu'il avait dans la version initiale de GenDR.

Pour mieux distinguer les dictionnaires en jeu, nous avons répertorié ceux que nous utiliserons dans la version prochaine de GenDR et ceux qui seront temporaires. En ce qui concerne GenDR, nous planifions utiliser les: \emph{semanticon} , \emph{lexicon} et \emph{gpcon}.

En ce qui concerne les dictionnaires créés avec Python, nous créerons un lexicon.dict(contient la hiérarchiee de VerbNet et les classes verbales), members.dict(contient les membres, donc les unités lexicales avec leur classe verbale correspondante) et le gpcon.dict. Parmi ceux-ci, lexicon.dict et members.dict de Python seront fusionnés pour former deux sections du prochain \emph{lexicon} de GenDR. Il sera complémenté par le lexique (plus de 1000 lexèmes non-verbaux de la langue anglaise) qu'il possédait déjà à sa version initiale et les classes abstraites non-verbales de celle-ci. La nature et l'interaction des dictionnaires de la nouvelle version de GenDR sera expliquée au chapitre suivant~\ref{ch:implementation}.
 
\section{Préparation du nouveau \emph{lexicon} de GenDR}

Le dictionnaire lexical original de GenDR contient des classes abstraites et des entrées lexicales (voir la section~\ref{sec:dictio}). À ces deux sections, nous proposons d'ajouter les classes verbales de VerbNet et les membres verbaux de ces classes, deux nouvelles sections que nous identifions comme \texttt{VERBNET CLASSES} et \texttt{VERBNET MEMBERS}. Nous décrirons dans les pages suivantes comment les scripts Python que nous avons créés nous ont permis de bâtir ces nouvelles sections du \emph{lexicon}.

D'abord, pour mieux comprendre la manière dont nous avons créé la section \texttt{VERBNET CLASSES}, il faut rappeler quelques notions de base du fonctionnement de GenDR. Au chapitre \ref{chapgendr}, nous avons décrit le mécanisme d'héritage qui façonne l'architecture du lexique (p.~\pageref{sec:dictio}). 

Ce mécanisme permet à une entrée d'hériter des traits (patrons de régime, diathèses, partie du discours, etc.) d'une classe abstraite. Cette transmission s'effectue en faisant pointer une entrée vers une classe abstraite (ex.: \texttt{like : verb\_dt}). Ainsi, nous n'avons pas à réécrire pour chaque verbe transitif qu'il prend un sujet et objet direct, par exemple. Nous avons donc planifié l'importation des classes verbales de VerbNet en fonction de ce mécanisme.  

Nous reprendrons ce mécanisme pour deux objectifs. D'abord, pour imiter l'architecture de VerbNet qui consiste à établir une hiérarchie entre les classes mères et leurs classes filles. Comme nous l'avons vu à la section \ref{sec:vnarchitecture}, les classes verbales sont hiérarchisées et les traits des classes dominantes sont transmis aux classes qu'elles gouvernent. Nous voulions donc transposer cette architecture à la section \texttt{VERBNET CLASSES}. Le but était de transmettre les \acp{GP} des classes mères aux classes filles grâce au mécanisme d'héritage. Puis, nous reprenons ce mécanisme pour transmettre les traits de partie du discours de la classe abstraite \texttt{VERB} afin d'éviter de répéter cette information pour chacune des classes verbales. Pour ce faire, on reprend le même concept qui lie les classes filles à leurs classes mères, mais cette fois-ci, on lie chaque classe mère à la classe abstraite \texttt{VERB} (illustré à la figure~\ref{fig:classeverb}). Ainsi, comme elle contient les traits de partie du discours \texttt{dpos} et \texttt{spos}, ils seront transmis à tous les lexèmes verbaux du dictionnaire.

\begin{figure}[htb]
  \caption{Traits de la classe abstraite \texttt{VERB}}
	\label{fig:classeverb}
\begin{lstlisting}[language=mate]
verb {
  dpos = V
  spos = verb
}
\end{lstlisting}
\end{figure}

Ensuite, nous avons extrait les verbes compris dans toutes les classes verbales de VerbNet et nous les avons aussi soumis à ce mécanisme (figure~\ref{fig:membreclasse}). Ainsi, chaque membre pointe vers une classe verbale dont il héritera les traits. Par exemple, les lexèmes \lex{absorb}, \lex{ingest} et \lex{take in} héritent tous les trois des traits spécifiés dans la classe verbale \texttt{absorb-39.8}. Cela nous permet de traiter 6\,393 acceptions sans avoir à décrire leur comportement syntaxique complet, simplement en pointant vers la bonne classe, telle qu'indiquée dans VerbNet. L'ajout de nouveaux verbes consisterait essentiellement à trouver à quelle classe ils appartiennent.

\begin{figure}[htb]
  \caption{Membres verbaux pointant vers leur classe}
	\label{fig:membreclasse}
\begin{lstlisting}[language=mate]
absorb: "absorb-39.8"
take_in: "absorb-39.8"
ingest_1: "absorb-39.8"
\end{lstlisting}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% --------- L E X I C O N    ---------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Extraction de l'architecture de VerbNet}

\begin{figure}[htb]
 \caption{Input du script: cadres syntaxiques imbriqués dans les fichiers VerbNet}
 \label{fig:input-absorb}
\begin{lstlisting}[language=XML]
<FRAMES>
        <FRAME>
            <DESCRIPTION descriptionNumber="0.2" primary="NP V NP" secondary="Basic Transitive"/>
            <EXAMPLES>
                <EXAMPLE>Cotton absorbs water.</EXAMPLE>
            </EXAMPLES>
            <SYNTAX>
                <NP value="Goal">
                    <SYNRESTRS/>
                </NP>
                <VERB/>
                <NP value="Theme">
                    <SYNRESTRS/>
                </NP>
            </SYNTAX>
		<FRAME>
         ...
\end{lstlisting}
\end{figure}

\begin{figure}[htb]
  \caption{Output du script: propriétés de la classe verbale \texttt{absorb-39.8}}
	\label{fig:output-absorb}
\begin{lstlisting}[language=mate]
lexicon {
"absorb-39.8": verb {
  gp = { id=NP_V_NP                        dia=x } // Cotton absorbs water.
  gp = { id=NP_V_NP_PP_from_source         dia=x } // Cattle take in nutrients from their feed.
}
\end{lstlisting}
\end{figure}

Nous avons divisé la description du premier script en trois blocs pour en faciliter la compréhension et nous illustrons à l'aide des figures~\ref{fig:input-absorb} et \ref{fig:output-absorb} le type de données que le script prend en entrée et ce qu'il produit en sortie.

\subsubsection{Bloc 1: Hiérarchie des classes verbales}

\begin{figure}[htb]
  \caption{Importation de l'architecture des classes verbales}
	\label{fig:archivn-bloc1}
\begin{lstlisting}[language=Python]
# BLOCK 1 : VERBNET HIERARCHY
def supers(t, i):
    ID = t.get('ID') # get the shared syntactic information.
    sc = {ID:i} # simulates the inheritance mechanism.
    subclasses = t.findall('SUBCLASSES/VNSUBCLASS') # gets all the information on the subclasses.
    if len(subclasses) > 0:
        for sub in subclasses:             # If there's a subclass for a given VNCLASS, 
            sc = {**sc, **supers(sub, ID)} # it'll point towards the class it's being dominated by.
    return sc
\end{lstlisting}
\end{figure}

L'objectif de la fonction \emph{supers} (présentée à la figure~\ref{fig:archivn-bloc1}) est de recréer l'architecture de VerbNet pour pouvoir l'intégrer à GenDR. Cette fonction récursive récupère l'identifiant d'une classe, puis de toutes les sous-classes imbriquées sous elle. Ensuite, \textbf{la fonction} crée un dictionnaire\footnote{Un \scare{dictionnaire} en Python est un type de structure de données, des paires de clé et de valeur non-ordonnées. Il ne faut pas les confondre avec les dictionnaires de langue.} Python dont la clé correspond à l'identifiant d'une classe fille et la valeur est l'identifiant de sa classe mère. Cette configuration correspond à celle qui est nécessaire à GenDR pour l'application du mécanisme qui nous permettra de transmettre les attributs d'une classe mère à une classe fille. Par exemple, cette fonction produit \lstinline|"begin-55.1-1": "begin-55.1"|, ce qui indique que \texttt{begin-55.1-1} hérite des traits de la classe \texttt{begin-55.1}.

\subsubsection{Bloc 2: Création du dictionnaire de classes verbales}

\begin{figure}[htb]
  \caption{Création du dictionnaire de classes verbales}
	\label{fig:archivn-bloc2}
\begin{lstlisting}[language=Python]
# BLOCK 2 : EXTRACTION of GPS identification and EXAMPLES
def treeframes(t):
    ID = t.get('ID')  # gets the name of the verbnet class
    z = []            
    for frame in t.findall('FRAMES/FRAME'):
        description = re.sub(r"\s*[\s\.\-\ +\\\/\(\)]\s*", '_',  
        frame.find('DESCRIPTION').get('primary')) # primary description = identification of a GP
        if description in exclude:
            continue
        description = re.sub('PP', 'PP_{}', description) 
        preps = [p.get('value') or 
                p.find('SELRESTRS/SELRESTR').get('type').upper()                  
                for p in frame.findall('SYNTAX/PREP')+frame.findall('SYNTAX/LEX')] 
        preps = [sorted(p.split()) for p in preps] # manipulates data to insert the prep. in desc.                                
        examples = [e.text for e in frame.findall('EXAMPLES/EXAMPLE')] # get ex. for each desc.
        if len(preps)==1:
            description = description.format('_'.join(preps[0]))
        elif len(preps)==2:
            description = description.format('_'.join(preps[0]),
                                             '_'.join(preps[1]))
        elif len(preps)==3:
            description = description.format('_'.join(preps[0]), 
                                             '_'.join(preps[1]), 
                                             '_'.join(preps[2])) # inserting preps in descriptions
        z.append((description, examples))
        
    subclasses = t.findall('SUBCLASSES/VNSUBCLASS')  # gets the root of each subclasses
    subframes = [treeframes(subclass) for subclass in subclasses] # applies function to subclasses
    subframes = sum(subframes, []) # flatten list of lists
    return [(ID, z)] + subframes # returns list of (sub)class, GP-identification and example
\end{lstlisting}
\end{figure}

L'objectif de la fonction \emph{treeframes} (figure~\ref{fig:archivn-bloc2}) est de récupérer, pour chaque classe VerbNet, l'identifiant de la classe verbale, les identifiants des patrons de régime compris sous celle-ci et une phrase exemple. Ainsi, cette fonction retourne un couple dont le deuxième élément est un couple: \texttt{(ID classe verbale, (ID \ac{GP}, exemple))}, ce qui se traduit concrètement par cela:\lstinline|('spray-9.7', ('NP_V_NP_destination', 'Jessica sprayed the wall'))|. Dans cet exemple, l'étiquette \lstinline|NP_V_NP_destination| correspond à la fois à la description d'un patron de régime et à son identifiant.

Pour ce faire, la fonction \emph{treeframes} récupère d'abord l'identifiant de la classe \texttt{spray-9.7}, puis les identifiants des patrons de régime qui sont encodés dans la section \texttt{<FRAME>} de cette classe verbale. Ensuite, grâce aux expressions régulières, on manipule les identifiants de \ac{GP} pour qu'ils correspondent au type de code demandé par GenDR. De plus, nous intégrons les prépositions régies de chaque patron de régime à l'intérieur de l'identifiant de celui-ci afin de les distinguer. En effet, certains identifiants de régime portaient le même nom, mais ne comprenaient pas les mêmes types de prépositions. Ainsi, en mettant les prépositions sélectionnées dans les identifiants des \ac{GP}, nous pouvons les distinguer et faire en sorte que les classes verbales utilisent les bonnes prépositions. Par exemple, le patron de régime \lstinline|NP_V_PP_patient| peut se distinguer par la préposition qui accompagne le groupe prépositionnel, donc pour nous assurer que les classes verbales sélectionnent les bonnes prépositions, nous les avons distinguées ainsi: \lstinline|NP_V_PP_on_patient| et \lstinline|NP_V_PP_from_patient|. Finalement, on récupère les exemples accompagnant chaque patron de régime pour compléter le triplet.

\subsubsection{Bloc 3: Écriture des données dans le fichier \emph{lexicon.dict}}

\begin{figure}[htb]
  \caption{Écriture des données dans le fichier \emph{lexicon.dict}}
	\label{fig:archivn-bloc3}
\begin{lstlisting}[language=Python]		
# BLOCK 3 : WRITING of the EXTRACTED INFORMATION in a FILE
with open('lexicon.dict','w') as f: # write the output into lexicon.dict
    f.write('lexicon {\n')
    for file in [f for f in os.listdir('verbnet') if f[-4:] == '.xml']: # open VerbNet XMl files
        root = ET.parse('verbnet/'+file).getroot() # Applies the Python Element Tree module
        d = dict(treeframes(root)) # create dictionary from results of treeframes
        sc = supers(root, 'verb') # applies supers function to each file
        for c in d.keys():
            f.write('"'+c+'"')
            if sc[c] == 'verb': # all non-dominated classes point to the default verb class
                f.write(': ' +sc[c] + ' {') 
            else:
                f.write(': ' +'"'+sc[c]+'"' + ' {') #dominated classes point towards their governor
            [f.write('\n  gp = { id=' + gp[0] + (max(len(gp[0]), 30)-len(gp[0]))
                     *' ' + ' dia=x } // ' + ' '.join(gp[1])) for gp in d[c]]
            f.write('\n}\n') # GPs will have attributes: id and dia
    f.write('\n}')
\end{lstlisting}
\end{figure}

L'objectif de ce dernier bloc de code (voir la figure~\ref{fig:archivn-bloc3}) est de créer un fichier qui contiendra le résultat des deux fonctions sur l'ensemble des données de VerbNet. Pour procéder, nous ouvrons un fichier appellé \emph{lexicon.dict} dans lequel nous écrirons les informations de VerbNet concernant les cadres syntaxiques et les classes verbales de VerbNet manipulés grâces aux fonctions \emph{treeframes} et \emph{supers}. Le produit de ce bloc correspondra à la section \texttt{VERBNET CLASSES} du nouveau \emph{lexicon} de GenDR.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% --------- M E M B R E S   ---------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Création du dictionnaire des verbes} \label{extracmembre}

Maintenant que nous avons complété la section \texttt{VERBNET CLASSES} de notre dictionnaire, il ne nous reste qu'à peupler le dictionnaire avec les verbes que VerbNet a décrits. De cette manière notre \emph{lexicon} pourra effectivement couvrir une partie importante du lexique anglais grâce au travail de \cite{SchulerVerbnetBroadcoverageComprehensive2005}, qui a associé plus de 6\,000 verbes à leur classe verbale. Lors de l'importation de ces verbes, nous procèderons aussi à leur désambiguïsation. Bien que Schuler ait distingué les différentes acceptions d'un même vocable en leur assignant des classes verbales différentes, la forme des verbes n'est pas désambiguïsée. Pour que GenDR reconnaisse chaque entrée verbale, elles doivent porter des étiquettes différentes.

\begin{figure}[htb]
  \caption{Input du script: verbes correspondant aux membres d'une classe verbale}
	\label{fig:member-absorb}
\begin{lstlisting}[language=XML]
<VNCLASS ID="absorb-39.8" >
    <MEMBERS>
        <MEMBER name="absorb">
        <MEMBER name="ingest" >
        <MEMBER name="take_in">
    </MEMBERS>
\end{lstlisting}
\end{figure}

\begin{figure}[htb]
  \caption{Output du script: lexèmes pointant vers une classe verbale}
	\label{fig:member-output-absorb}
\begin{lstlisting}[language=mate]
abound : "swarm-47.5.1-2-1"
abrade : "other_cos-45.4"
abridge : "other_cos-45.4"
absolve : "free-80-1"
absorb : "absorb-39.8"
\end{lstlisting}
\end{figure}

\subsubsection{Récupérer les verbes}
L'objectif de la fonction \emph{treemember} (illustré à la figure~\ref{fig:scriptmember-bloc1}) est de récupérer les membres assignés à chaque classe et sous-classe verbale de VerbNet. Cette fonction récupère d'abord l'identifiant de la classe verbale, puis les membres qui lui sont associés. Finalement, la fonction retourne des paires de classes verbales et de membres. Par exemple, le script récupèrera deux fois le vocable \lex{order}, une fois comme \lstinline|{order : "get-13.5.1"}|, puis comme \lstinline|{order : "order-60-1"}|. À cette étape, nous venons de récupérer la désambiguïsation de VerbNet, mais elle ne s'insère pas dans notre dictionnaire puisque nous devons donner des noms différents à ces entrées. Les entrées et sorties de ce script sont présentés aux figures \ref{fig:member-absorb} et \ref{fig:member-output-absorb}.

\begin{figure}[htb]
  \caption{Récupération des verbes de VerbNet}
	\label{fig:scriptmember-bloc1}
\begin{lstlisting}[language=Python]
#GET MEMBERS FROM VERBNET CLASSES
def treemember(t):
    ID = t.get('ID') # get ID of the VNCLASS
    members = [m.get('name') for m in t.findall('MEMBERS/MEMBER')] # get members 
    subclasses = t.findall('SUBCLASSES/VNSUBCLASS')
    submembers = []
    if len(subclasses) > 0: # if there's a subclass
        for sub in subclasses:
            submembers = submembers + treemember(sub) # get ID of the subclass and members
    return [(ID, members )] + submembers
\end{lstlisting}
\end{figure}

\subsubsection{Désambiguïser les noms des entrées}

L'objectif de ce bloc (figure~\ref{fig:scriptmember-bloc2}) est de désambiguïser les noms des entrées des différentes acceptions d'un même vocable. Pour cela, nous avons extrait toutes les entrées homonymiques, puis nous les avons distinguées en leur assignant un numéro (ex.: \texttt{grill\_1}, \texttt{grill\_2}, \texttt{grill\_3}). Finalement, nous avons identifié les vocables monosémiques et nous les avons mis à part dans une liste. Nous avons ensuite fusionné les acceptions désambiguïsées et celles qui ne le nécessitaient pas dans une même liste.

\begin{figure}[htb]
  \caption{Désambiguïsation des noms des entrées}
	\label{fig:scriptmember-bloc2}
\begin{lstlisting}[language=Python]
# DISAMBIGUATE MEMBERS
files = [f for f in os.listdir('verbnet') if f[-4:] == '.xml']
members = dict(sum([treemember(ET.parse('verbnet/'+file).getroot())
 for file in files], [])) # VNCLASS : [member1, member2, etc. ]

values = sum(list(members.values()), []) # just the members of all classes

dups = {m:[ID for ID in members.keys() if m in members[ID]]
 for m in values if values.count(m)>1}  # get all the duplicates

lexemes = {d[0]+'_'+str(n+1):d[1][n]
 for d in dups.items() for n in range(len(d[1]))} # enumerate all duplicates: eat_1, eat_2

unique_member = {m:ID for ID in members.keys() 
 for m in values if m in members[ID] and values.count(m)==1} #  get all unique lexemes

unified_dict = {**unique_member, **lexemes} # fuse both dict. to get all members disambiguated
\end{lstlisting}
\end{figure}

\subsubsection{Écriture des verbes dans un fichier \emph{.dict}}

L'objectif de ce bloc (figure~\ref{fig:scriptmember-bloc3}) est de créer le dictionnaire \emph{members.dict}, qui sera ensuite intégré au \emph{lexicon.dict} en tant que section \texttt{VERBNET MEMBERS}. Pour ce faire, nous classons alphabétiquement les verbes, puis nous assignons à chaque acception sa classe verbale (ex.: \lstinline|order_1 : "get-13.5.1"|) grâce à la fonction \emph{treemember}. Finalement, nous insérons le tout dans le fichier \emph{members.dict}

\begin{figure}[htb]
  \caption{Écriture des verbes dans le fichier \emph{members.dict}}
	\label{fig:scriptmember-bloc3}
\begin{lstlisting}[language=Python]
# WRITE MEMBERS IN A FILE
with open('members.dict','w') as f: # open a file
    f.write('members {\n')
    for key in sorted(unified_dict.keys()): # sort the members
        f.write(key) # write the members
        f.write(': '),
        f.write('"'+str(unified_dict[key])+'"') # point members towards ID of VNCLASS
        f.write('\n')
    f.write('\n}\n')
\end{lstlisting}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% --------- G P C O N    ---------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Création du dictionnaire de patrons de régime}\label{sec:creategpcon}

Lors de la création de la section \texttt{VERBNET CLASSES}, nous avons extrait les classes verbales de VerbNet ainsi que les identifiants des patrons de régime qui y sont encodés. Nous avons ensuite analysé le contenu des patrons de régime prélevés afin de trouver la meilleure manière d'encoder les propriétés lexicales et syntaxiques de chaque patron de régime dans un dictionnaire.

D'abord, nous avons dû nous débarrasser de certaines constructions syntaxiques. Nous avons ainsi filtré les \acp{GP} que nous voulions importer dans un dictionnaire afin de nous départir de ceux qui pourraient poser problème et ceux que nous jugions inutiles.

Nous avons exclu les constructions purement stylistiques comme \lstinline|NP_location_V_NP| qui réalisent les phrases du type \form{All through the mountains raged a fire}. Puis, nous avons aussi exclu les \acp{GP} qui sélectionnent des constructions de type \emph{déplacement Qu--}, comme la phrase \form{Heather cabled when to send the package}, car GenDR ne traite pas ces comportements pour l'instant. Il a aussi fallu enlever les constructions contenant des modificateurs adverbiaux ou adjectivaux, par exemple \lstinline|NP_V_ADVP_Middle_PP_into_to_with|, qu'on retrouve dans la phrase \form{The computer connected \textbf{well} to the network}. L'emploi d'un groupe adverbial dans un patron de régime n'a pas sa place, car il ne s'agit pas d'un actant syntaxique et il n'est certainement pas sélectionné par le verbe. Environ une centaine de constructions syntaxiques ont ainsi été retirées. Après avoir filtré le tout, nous avons procédé à la création du dictionnaire de patrons de régime.

Nous ne pouvions pas automatiquement extraire des \acp{GP} de VerbNet toutes les propriétés lexicales nécessaires pour GenDR. Comme nous l'avons vu plus tôt, un patron de régime dans GenDR indique la diathèse et la combinatoire lexicale et syntaxique d'une lexie (la partie du discours de ses actants, les relations de surface et les prépositions régies), mais les cadres syntaxiques de VerbNet ne nous donnent pas toutes ces informations. La nature des actants syntaxique est évidemment absente des cadres syntaxiques de VerbNet, puisque cette ressource utilise les rôles thématiques pour distinguer les actants liés au verbe. Toutefois, nous pouvons accéder à la partie du discours qui est encodée ainsi: \texttt{NP} correspond à \texttt{dpos=N} et \texttt{S\_INF/S\_ING} pour les verbes qui sélectionnent d'autres verbes correspond à \texttt{dpos=V}. VerbNet nous donne aussi accès aux prépositions régies qui sont encodées dans les cadres syntaxiques. Toutefois, les relations de surface ne sont pas explicitées dans les cadres syntaxiques, mais nous pouvons les déduire grâce aux phrases exemples accompagnant les identifiants de patrons de régime que nous avons prélevées plus tôt.

Bref, nous avons extrait le plus d'information possible des identifiants des \acp{GP}. Ainsi, un identifiant comme \texttt{NP\_V\_NP\_destination\_PP\_with\_theme} nous donne les informations suivantes: la partie du discours de chaque actant syntaxique, l'ordre des actants syntaxiques en \ac{RSyntP} et les prépositions régies par le verbe pour un actant donné. Ensuite, la phrase exemple \form{Jessica loaded the wagon with boxes} nous permet de déduire, de façon manuelle, les relations de surface (sujet, objet direct, etc.) de chaque actant syntaxique. C'est grâce à ces informations que nous avons construit le \emph{gpcon}.

À l'aide d'un petit script Python, nous avons établi qu'il y avait 274 \ac{GP} uniques. Chacun sera une entrée dans le dictionnaire de patrons de régime, que nous avons écrite manuellement. Cependant, pour accélérer ce processus, nous avons défini dans Python des objets qui représentent des actants syntaxiques non-étiquetés incorporant des traits lexicaux et syntaxiques. Ensuite, nous avons défini une fonction permettant d'assigner une étiquette au contenu d'un actant syntaxique, puis la combinaison du contenu et de l'étiquette nous a permis de créer des patrons de régime assez rapidement. Le tout sera expliqué en détail dans la section qui suit.

Pour cette partie, nous avons construit le dictionnaire de patrons de régime à partir de données que nous avons entrées manuellement. Ainsi, il n'y a pas d'input XML provenant de VerbNet. Toutefois, afin de mieux comprendre la section présente, voici à quoi ressemble l'output prévu pour le script (voir figure~\ref{fig:outputgpcon}).

\begin{figure}[htb]
  \caption{Output prévu par le script gpcon}
	\label{fig:outputgpcon}
\begin{lstlisting}[language=Python]
gpcon {
NP_agent_V {
   I={rel=subjective dpos=N}
}
NP_agent_V_NP {
   I={rel=subjective dpos=N}
   II={rel=dir_objective dpos=N}
}
NP_asset_V_NP_PP_from_out_of {
   I={rel=subjective dpos=N}
   II={rel=dir_objective dpos=N}
   III={rel=oblique dpos=N prep=from}
   III={rel=oblique dpos=N prep="out of"}
}
\end{lstlisting}
\end{figure}
\subsection{Contenu lexical et syntaxique d'un actant non-étiqueté}

Dans le premier bloc, nous définissons des objets comme \texttt{subj} ou \texttt{dir\_N} qui correspondent à des propriétés syntaxiques qui seraient normalement associées à un actant syntaxique. Par exemple, l'objet \texttt{subj} renvoie aux traits \lstinline|'rel=subjective dpos=N'|. Nous avons ainsi défini toutes les propriétés lexico-syntaxiques possibles des actants que nous avons relevés parmi les identifiants des \acp{GP}. Autrement dit, ces objets correspondent aux éléments constitutifs des \acp{GP}. Ensuite, nous avons créé une fonction pour prendre ces éléments et leur assigner une étiquette selon leur position dans le \ac{GP}. Cela nous évite de décrire les propriétés syntaxiques des actants à chaque patron de régime. Finalement, nous avons décrit tous les patrons de régime en combinant ces éléments: \lstinline|{'NP_agent_V_NP': [subj, dir_N],}|. Le tout est illustré à la figure~\ref{fig:contenulexical}.

\begin{figure}[htb]
  \caption{Contenu lexical et syntaxique d'un actant non-étiqueté}
	\label{fig:contenulexical}
\begin{lstlisting}[language=Python]
# BLOCK 1 SYNTACTIC ACTANTS PROPERTIES
#subjective
subj = 'rel=subjective dpos=N'

#direct obj
dir_N = 'rel=dir_objective dpos=N'
dir_V_ING = 'rel=dir_objective dpos=V finiteness=GER'
dir_V_INF = 'rel=dir_objective dpos=V finiteness=INF'

#indirect obj
to_N = 'rel=indir_objective dpos=N prep=to'
indir_N = 'rel = indir_objective dpos = N'

#oblic
on_V = 'rel=oblique dpos=V prep=on'
to_obl_N = 'rel=oblique dpos=N prep=to' 
for_obl_N = 'rel=oblique dpos=N prep=for'
against_N = 'rel=oblique dpos=N prep=against'
...
\end{lstlisting}
\end{figure}

\subsection{Assignation des relations syntaxiques profondes aux actants}

L'objectif de la combinaison des fonctions \emph{roman} et \emph{gp} est d'assigner les relations syntaxiques profondes aux actants selon leur position dans un \ac{GP} (voir la figure~\ref{fig:assignationrel}). Par exemple, dans \lstinline|NP_agent_V_NP: [subj, dir_N]|, puisque \texttt{dir\_N} est à la deuxième position, les propriétés qu'il renferme seront celles de l'actant syntaxique \texttt{II}. Cela permet de générer le patron de régime \lstinline|NP_agent_V_NP { I={rel=subjective dpos=N}| \lstinline|II={rel=dir_objective dpos=N} }|, qui est le format attendu dans GenDR. De plus, on dédouble le même actant syntaxique pour un \ac{GP} dont l'un des actants syntaxiques se réalise à l'aide de deux prépositions différentes. Cela est illustré par le \ac{GP} \lstinline|NP_asset_V_NP_PP_from_out_of| qu'on a décrit à l'aide des objets \lstinline|[subj, dir_N, [from_N, out_of_N]]|. Cela nous donne \lstinline| III={rel=oblique dpos=N| \lstinline|prep=from}| et \lstinline|III={rel=oblique dpos=N prep="out of"}| pour le troisième actant syntaxique.

\begin{figure}[htb]
  \caption{Assignation des relations syntaxiques profondes aux actants et construction des patrons de régime}
	\label{fig:assignationrel}
\begin{lstlisting}[language=Python]
# BLOCK 2.1 ASSIGN SYNTACTIC LABEL to ACTANT
def roman(n):
    return ['I', 'II', 'III', 'IV', 'V', 'VI'][n-1] # transforms arabic numbers in roman numbers
def gp(name, real_actant):
    s = name + ' {\n'
    i=0
    for actant in real_actant:
        i = i+1                   # starts to enumerate at 1
        if type(actant) == list:  # if not actant but list, apply function to actants in list
            for y in actant:
                s = s + "   " + roman(i) + "={" + y + "}\n"
        else:
            s = s + "   " + roman(i) + "={" + actant + "}\n" # apply function to actant
    s = s + '}\n'
    return s 

# BLOCK 2.2 CONSTRUCTION OF A GP ENTRY
descriptions = {
'NP_agent_V': [subj],
'NP_agent_V_NP': [subj, dir_N],
'NP_asset_V_NP_PP_from_out_of': [subj, dir_N, [from_N, out_of_N]],
...
\end{lstlisting}
\end{figure}

\subsection{Création du \emph{gpcon}}

Finalement, il ne nous reste qu'à créer le fichier \emph{gpcon.dict} (figure~\ref{fig:creationgpcon}) qui renfermera tous les \ac{GP}. Donc, nous appliquons la fonction \emph{gp} à chaque description (\lstinline|ex: 'NP_agent_V_NP'|) pour que le contenu des objets (\lstinline|[subj, dir_N]|) se fassent assigner une étiquette syntaxique (\lstinline|I ='rel=subjective dpos=N'|, \lstinline|II = dir_N = 'rel=dir_objective dpos=N'|). Un exemple du contenu final de ce dictionnaire est illustré à la figure~\ref{fig:4entries-gpcon}.

\begin{figure}[htb]
  \caption{Création du dictionnaire de patrons de régime}
	\label{fig:creationgpcon}
\begin{lstlisting}[language=Python]
# BLOCK 3 GPCON CREATION
with open('gpcon.dict','w') as f: 
    f.write('gpcon {\n')
    for d in descriptions.keys():       # for each gps descriptions,
        f.write(gp(d, descriptions[d])) # write them with the correct syntactic label
    f.write('}')
\end{lstlisting}
\end{figure}


