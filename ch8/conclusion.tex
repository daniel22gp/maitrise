%!TEX root = ../memoire.tex

\chapter*{Conclusion}
Un des enjeux en GAT c'est, de générer du texte le plus naturel possible. Pour ça y'existe différentes manières. Parmi ces manièrs y'a la méthode à base de règles. Cette méthode nécessite l'emploi de dictionnaire pour encoder les propriétés du lexique. Mais, si on veut couvrir large, il nous faut avoir accès aux différentes comportements des mots du langage. Certains comportements sont prévisibles, donc on peut les traiter facilement, mais les comportements syntaxiques des verbes sont très différents et imprévisibles. Il faut donc encoder ces données pour pouvoir les réaliser et réaliser du langage représentant la richesse des langues naturelles. Un verbe peut s'exprimer de différentes manières, sélectionner des arguments divers à l'aide de prépositions diverses, etc. 

une chance que des gens se sont penchés sur cette problématique et ont développé des ressources encodant ce type d'information. Pas juste en GAT, mais dans le TAL en général, ce type de ressource est extrêmement utile. Nous nous sommes dit que ce serait bon d'intégrer une telle ressource à GenDR, spécialiement pour traiter les verbes, puisque ce sont eux qui contrôlent la plupart des énoncés et c'est la prtie du discours qui démontre le plus de variation quant aux constructions syntaxiques permises par chaque lexème. L'objet de ce mémoire est de pourvoir GenDR d'une couverture linguistique beaucoup plus grande que celle qu'il a présentement en y intégrant VerbNet qui est une base de données lexicales décrivant les comportements syntaxiques de 6\,394 verbes.Nous voulions voir si l'implémentation d'une telle ressource était viable dans un réalisateur profond et comment le faire, et est-ce que ça fonctionne ?.

6 lignes par chapitre
Dans le premier chapitre, nous introduisons la \ac{GAT} et le pipeline classique qui la compose. Nous nous sommes arrêtés sur la réalisation linguistique qui est la dernière étape du pipeline. Ensuite nous avons souligné qu'il existait différents types d'approches pour effectuer la réalisation linguistique: à base de patrons, à base de règles et à base de statistiques. Ensuite, nous avons exploré les différents réalisateurs de surface et profonds. Notamment, nous avons parlé de SimpleNLG, JSrealB et RealPro qui sont des réalisateurs de surface. Puis, nous avons décrit des réalisateurs profonds: KMPL, SURGE, MARQUIS, FORGe.

Dans le deuxième chapitre, nous avons décrit en détails le réalisateur profond: GenDR, un héritier de MARQUIS. Nous avons décrit l'architecture qui le composait et le logiciel MATE (conçu pour la TST) qui offre un éditeur de graphes, de dictionnaire et de règles pour développer et tester une grammaire computationnelle. Ensuite nous avons expliqué quelques notions de base de la TST dont l'interface sémantique-syntaxe. Puisque GenDR opère au niveau de cette interface en mettant toutes ces forces à modéliser l'arborisation et la lexicalisation. Finalement, nous avons démontré le fonctionnement du réalisateur GenDR à l'aide d'un exemple décrivant l'intéraction des règles et dictionnaires pour réaliser du texte à partir d'un input sémantique. Nous avons aussi mentionné que GenDR contenait très peu d'information sur toutes les constructions possibles des verbes, mais imagine si on l'enrichie qu'est-ce que ça pourrait donner.

Dans le troisième chapitre, nous faisons un survol des ressources lexicales potentielles que nous envisageons pour intégrer à GenDR dans le but d'augmenter sa couverture et de lui permettre de réaliser des constructions syntaxiques variées en fonction des verbes. Nous décrivons notamment WordNet, FrameNet, XTAG, LCS, Comlex, Valex,et le VDE et finalement VerbNet, le grand gagnant. Cette ressource lexicale est basée sur les travaux de \cite{verb-classes.levin.1993}. Ce qui nous a le plus attiré de cette ressource est l'organisation des classes verbales ainsi que la large couverture de VerbNet plus de 6000 verbes, désambiguisés.

Dans le quatrième chapitre, nous avons procédé à l'extraction des données lexicales de VerbNet. Nous avons d'abord extrait les informations syntaxiques des classes verbales en conservant la hiérarchie pensée par VerbNet. Puis nous avons extrait les verbes associés à chaque classe verbale et nous les avons désambiguïsés avant de les rajouter à notre dictionnaire. Ensuite, nous avons procédé à la création du dictionnaire de patron de régime à partir des données extraites. Le tout a été fait par l'entremise de Python qui nous a permis de manipuler les fichiers de VerbNet qui sont encodés en XML.

Dans le cinquième chapitre, nous avons démontré comment nous avons adapté GenDR à l'utilisation d'un dictionnaire de patron de régime. Le nombre de verbe décrit par le réalisateur passait de passe de 500 à 6394, puis nous avons complètement changé l'utilisation des patrons de régime avec la venue du dictionnaire de \ac{GP}. Cela a permi à GenDR d'avoir une couverture beaucoup plus large avec les lexèmes et de couvrir une énorme quantité de constructions syntaxiques possibles en anglais. Par le fait même on règle le problème des gps multilpes et on agrandi la couverture de GenDR. 
	
Dans le sixième chapitre, on a d'abord créé les scripts nous permettant de générer les structures de bases pour évaluer GenDR. Le résultat nous donne 978 structures sémantiques dont nous avons manuellement encodé le contenu. 50 ont été choisies aléatoirement pour faire l'évaluation. On a évalué le rappel avec une technique similaire à BLEU. Ensuite on a évalué la précision avec une évaluation humaine classique pour voir si les phrases générées étaient grammaticales et quel était le pourcentage de celle-ci sur le nombre de générées. GenDR performe à 100 pourcent partout rappel et précision. VerbNet nous fait faire des erreurs de précisions (manque de gp, manque d'entrée et GenDR guess fait n'importe quoi, prépositions pour le mm actant, ça donne des phrases incohérentes) VerbNet excellent pour le rappel, mais y'a des incompatibilités sémantiques entre la TST et VerbNet.  

Le travail que nous avons fait apporte plusieurs contributions importantes à la recherche en \ac{GAT}. Nous avons démontré comment s'implémenterait une ressource lexicale comme VerbNet dans un réalisateur profond à base de règles. Nous avons par le fait même démontré qu'avec une ressource comme Python nous pouvons extraire et manipuler les données d'un dictionnaire pour les implémenter dans un réalisateur. Nous avons montré qu'il est possible de prendre une ressource fait dans un cadre X et la transcoder pour l'adapter à un autre cadre théorique sans que ce ne soit trop encombrant. C'est ainsi que nous avons créé un dictionnaire de patron de régime codé en \emph{Sens-Texte}. Cela pourrait être utile à d'autres réalisateurs qui voudraient s'inspirer de cette théorie. Ou bien pour des systèmes n'utilisant pas les rôles thématiques. Nous avons montré qu'il est possible de doter un réalisateur profond d'une immense couverture grâce à de telles ressources et que leur implémentation donne déjà de bons résultats sans même avoir été modifié. 80\% sans retouches, mais on pourrait l'adapter à nos besoins et aller chercher une meilleure précision. Une autre contribution de cette recherche est que nous avons par le fait même évaluer la capacité d'utiliser VerbNet précisément comme dictionnaire verbal pour un réalisateur profond en GAT. Les avantages et les inconvénients de cette ressource. Notamment, dans 20\% des phrases générées contenait des incongruités.

Finalement, ce projet de recherche ouvre la porte à GenDR à se doter d'autres ressources lexicales similaires pour améliorer se couverture. Notamment, nous pourrions implémenter les régimes des noms, grâce aux autres ressources (comme FrameNet). Nous pourrions aussi aller chercher les gps manquant dans d'autres ressources que nous avons répertoriés. De plus, comme il existe des VerbNet dans d'autres langues (francais, portugais et italien), on aurait avantage à aller les chercher, ce sera facile vu qu'on a déjà le frame d'importation. Et comme GenDr est multilingue ça vient rejoindre le but.


