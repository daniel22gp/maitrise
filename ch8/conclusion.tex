% !TEX root = ../memoire.tex

\chapter*{Conclusion}
L'un des enjeux fondamentaux en \ac{GAT} est de générer du texte qui paraisse aussi naturel que possible. Généralement, il faut pour cela que le système ait accès à des connaissances linguistiques fines. Par exemple, les réalisateurs à base de règles nécessiteront une grammaire qui modélise des phénomènes complexes et des dictionnaires riches encodant les propriétés de combinatoires des lexies. Si on veut couvrir le plus de constructions permises par une langue, il nous faut avoir accès aux différents comportements des lexèmes de cette langue. Certaines parties du discours présentent des comportements plus prévisibles, mais les comportements syntaxiques des verbes sont extrêmement variés et très imprévisibles. Il faut donc stocker ces données dans un dictionnaire pour pouvoir produire du texte représentant toute la richesse des langues naturelles.

C'est pour cette raison que plusieurs chercheurs ont cherché à créer des ressources lexicales décrivant les comportements syntaxiques des unités lexicales de l'anglais. Ces ressources ont pour but de servir toutes les branches du \ac{TAL}, dont la \ac{GAT}. L'objet de ce mémoire était de pourvoir GenDR d'une couverture linguistique beaucoup plus grande que celle qu'il a présentement en y intégrant VerbNet, qui est une base de données lexicales décrivant les comportements syntaxiques de 6\,393 verbes. Ainsi, ce mémoire répond à ces deux questions:

\begin{enumerate}
  \item \form{Comment implémenter une telle ressource dans un réalisateur profond à base de règles ?}
  \item \form{Est-ce que cette implémentation donne de bons résultats ?}
\end{enumerate}

Dans le premier chapitre, nous introduisons la \ac{GAT} et le pipeline classique qui la compose. Nous nous sommes arrêté sur la réalisation linguistique, qui est la dernière étape du pipeline. Ensuite nous avons souligné qu'il existait différents types d'approches pour effectuer la réalisation linguistique: à base de patrons, à base de règles et à base de modèles statistiques. Ensuite, nous avons exploré les différents réalisateurs de surface et profonds. Notamment, nous avons parlé de SimpleNLG \citep{GattSimpleNLGRealisationEngine2009}, JSrealB \citep{MolinsJSrealBBilingualText2015} et RealPro \citep{LavoieFastPortableRealizer1997} qui sont des réalisateurs de surface. Puis, nous avons décrit des réalisateurs profonds: KMPL \cite{BatemanEnablingTechnologyMultilingual1997}, SURGE \citep{Elhadad98surge:a}, MARQUIS \citep{WannerMARQUISGENERATIONUSERTAILORED2010}, FORGe\citep{MilledemoFORGePompeu2017}.

Dans le deuxième chapitre, nous avons décrit en détail le réalisateur profond GenDR \citep{lareau18}, un héritier de MARQUIS. Nous avons dépeint l'environnement dans lequel GenDR s'insère: le logiciel MATE (conçu pour la TST), qui offre un éditeur de graphes, de dictionnaire et de règles pour développer et tester une grammaire computationnelle. Ensuite nous avons expliqué quelques notions de base de la \ac{TST} dont l'interface sémantique-syntaxe. Puisque GenDR opère au niveau de cette interface en modélisant l'arborisation et la lexicalisation. Finalement, nous avons démontré le fonctionnement du réalisateur GenDR à l'aide d'un exemple décrivant l'interaction des règles et dictionnaires pour générer des arbres syntaxiques de surface à partir d'un input sémantique.

Dans le troisième chapitre, nous avons fait un survol des ressources lexicales potentielles que nous envisagions pour augmenter la couverture de GenDR et sa capacité à traiter le plus grand nombre de constructions possibles. Nous avons exploré notamment WordNet, FrameNet, XTAG, LCS, Comlex, Valex,et le VDE et finalement VerbNet, le grand gagnant, qui est basé sur les travaux de \cite{verb-classes.levin.1993}. Ce qui nous a plu dans cette ressource est l'organisation des classes verbales ainsi que sa large couverture (plus de 6\,000 verbes désambiguïsés).

Dans le quatrième chapitre, nous avons procédé à l'extraction des données lexicales de VerbNet. Nous avons d'abord extrait les informations syntaxiques des classes verbales en conservant la hiérarchie pensée pour VerbNet. Puis nous avons extrait les verbes associés à chaque classe verbale et nous les avons désambiguïsés avant de les ajouter à notre dictionnaire. Ensuite, nous avons procédé à la création du dictionnaire de patrons de régime à partir des données extraites. Le tout a été fait par l'entremise de Python, qui nous a permis de manipuler les fichiers de VerbNet encodés en \emph{XML}.

Dans le cinquième chapitre, nous avons démontré comment nous avons adapté GenDR à l'utilisation d'un dictionnaire de patrons de régime. Le nombre de verbes décrit par le réalisateur est ainsi passé de 500 à 6\,393. Puis, nous avons complètement changé l'utilisation des patrons de régime avec la venue du dictionnaire de \acp{GP}. Cela a permi à GenDR d'avoir une couverture beaucoup plus large en termes de lexèmes verbaux et de couvrir un grand nombre de constructions syntaxiques possibles en anglais. Par le fait même, on règle le problème des \acp{GP} multiples.
	
Dans le sixième chapitre, nous montrons comment nous avons créé les scripts permettant de générer les structures de base pour évaluer GenDR. Puis nous expliquons que nous avons sélectionné 50 structures sémantiques aléatoirement parmi les 978 encodées pour faire l'évaluation. Nous avons d'abord testé notre système en calculant le rappel et la précision. D'abord, le rappel a été calculé en vérifiant qu'on arrivait à générer les structures syntaxiques des 50 phrases attendues. Ensuite, la précision a été calculée en vérifiant combien des structures générées étaient grammaticales. Bref, les résulats nous montrent que les règles de GenDR fonctionnent généralement bien et que la plupart des erreurs nous sont transmises via VerbNet, notamment les erreurs affectant la précision.

Le travail que nous avons fait apporte plusieurs contributions importantes au développement de GenDR. Nous avons démontré comment s'implémente une ressource lexicale comme VerbNet dans un réalisateur profond à base de règles, de façon surtout automatique. Nous avons montré qu'il est possible de prendre une ressource relativement neutre d'un point de vue théorique et d'adapter les données pour une utilisation dans un autre cadre théorique sans que ce ne soit trop encombrant. C'est ainsi que nous avons créé un dictionnaire de patrons de régime selon le formalisme de la \ac{TST}. Cela pourrait être utile à d'autres réalisateurs qui voudraient s'inspirer de cette théorie. De plus, nous avons montré que l'implémentation de VerbNet sans trop de retouches donnait un score naturel de 80\% de précision, ce qui veut dire que l'intégration de cette ressources dans le cadre de la \ac{GAT} nécessite quelques modifications pour éviter des phrases agrammaticales. Il reste que la couverture de GenDR s'est vue grandir d'un coup grâce à l'implémentation massive de VerbNet, ainsi il est possible de rapidement augmenter la couverture d'un réalisateur, sans trop modifier la source. 

Cette recherche contribue également à évaluer la pertinence de VerbNet comme dictionnaire verbal pour un réalisateur profond en \ac{GAT}. Nous en concluons que c'est une ressource que se prête très bien à cette branche du \ac{TAL}, mais qu'il faudrait faire quelques modifications à la ressource post-intégration pour tenir compte des erreurs que nous avons soulignées.

De plus, ce projet de recherche démontre que GenDR pourrait aussi bénéficier d'autres ressources lexicales pour complémenter sa couverture. Notamment, nous pourrions implémenter les régimes des noms, grâce aux autres ressources (comme FrameNet \cite{FillmoreBackgroundFramenet2003a}). Nous pourrions aussi aller chercher les \acp{GP} manquants dans d'autres ressources que nous avons répertoriés. De plus, comme il existe des VerbNet dans d'autres langues (francais \citep{danlos:hal-01179175}, portugais \citep{ScartoncrosslinguisticVerbNetstylelexicon}, italien \citep{busso2016italian}, espagnol \citep{TauleAnCoraNetMappingSpanish2010}, tchèque \citep{pala2008can}, mandarin \citep{liu2008construction}), on aurait avantage à les acquérir. La tâche serait relativement rapide puisqu'on sait déjà comment implémenter les données de ce format. De plus, comme GenDR est un réalisateur multilingue, son architecture interne est déjà établie pour accueillir d'autres lanuges. Finalement, une recherche récente \citep{Majewska2017} démontre que l'exportation des classes et des membres de VerbNet \citep{SchulerVerbnetBroadcoverageComprehensive2005} à d'autres langues est valide et donne généralement de bons résultats. Ils soulignent qu'il faudrait évidemment faire des ajustements spécifiques pour chaque langue, mais que l'architecture pensée pour l'anglais se traduit bien à d'autres langues. 

Finalement, pour que GenDR soit utilisé à pleine capacité, il faudrait lui intégrer le module de fonctions lexicales de sa version originale \citep{LambreyImplementationcollocationspour2017, lareau18}, ce qui enrichirait nettement sa nouvelle version grâce à la modélisation des règles permettant le traitement des collocations.