%!TEX root = ../memoire.tex

\chapter*{Conclusion}
L'un des enjeux fondamentaux en \ac{GAT} est de générer du texte le plus naturellement possible. Généralement, pour arriver à réaliser du texte le plus près de la langue, il faut que le système ait accès à des connaissances langagières très poussées. Par exemple, les réalisateurs à base de règles nécessiteront un grammaire capable de modéliser des phénomènes complexes et des dictionnaires riches encodant le plus de propriétés lexicales pour chaque unité. Ainsi, si on veut couvrir le plus de constructions permises par une langue, il nous faut avoir accès aux différents comportements des lexèmes d'une langue donnée. Certaines parties du discours présentent des comportements plus prévisibles, mais les comportements syntaxiques des verbes sont extrêmement variés et très imprévisibles. Il faut donc encoder ces données pour pouvoir les réaliser et produire du texte représentant la richesse des langues naturelles.

C'est pour cette raison que plusieurs chercheurs ont voulu remédier à la situation en créant des ressources lexicales décrivant les comporetements syntaxiques des unités de l'anglais. Ces ressources avaient pour but de servir toutes les branches du \ac{TAL} dont la \ac{GAT}. L'objet de ce mémoire est de pourvoir GenDR d'une couverture linguistique beaucoup plus grande que celle qu'il a présentement en y intégrant VerbNet qui est une base de données lexicales décrivant les comportements syntaxiques de 6\,394 verbes. Ainsi, ce mémoire répond à ces deux questions:

\begin{enumerate}
  \item \form{Comment implémenter une telle ressource dans un réalisateur profond à base de règles ?}
  \item \form{Est-ce que cette implémentation donne de bons résultats ?}
\end{enumerate}

Dans le premier chapitre, nous introduisons la \ac{GAT} et le pipeline classique qui la compose. Nous nous sommes arrêtés sur la réalisation linguistique qui est la dernière étape du pipeline. Ensuite nous avons souligné qu'il existait différents types d'approches pour effectuer la réalisation linguistique: à base de patrons, à base de règles et à base de statistiques. Ensuite, nous avons exploré les différents réalisateurs de surface et profonds. Notamment, nous avons parlé de SimpleNLG \citep{GattSimpleNLGRealisationEngine2009}, JSrealB \citep{MolinsJSrealBBilingualText2015} et RealPro \citep{LavoieFastPortableRealizer1997}qui sont des réalisateurs de surface. Puis, nous avons décrit des réalisateurs profonds: KMPL \cite{BatemanEnablingTechnologyMultilingual1997}, SURGE \citep{Elhadad98surge:a}, MARQUIS \citep{WannerMARQUISGENERATIONUSERTAILORED2010}, FORGe\citep{MilledemoFORGePompeu2017}.

Dans le deuxième chapitre, nous avons décrit en détails le réalisateur profond: GenDR \citep{lareau18}, un héritier de MARQUIS. Nous avons décrit l'architecture qui le composait et le logiciel MATE  (conçu pour la TST) qui offre un éditeur de graphes, de dictionnaire et de règles pour développer et tester une grammaire computationnelle. Ensuite nous avons expliqué quelques notions de base de la TST dont l'interface sémantique-syntaxe. Puisque GenDR opère au niveau de cette interface en mettant toutes ces forces à modéliser l'arborisation et la lexicalisation. Finalement, nous avons démontré le fonctionnement du réalisateur GenDR à l'aide d'un exemple décrivant l'intéraction des règles et dictionnaires pour réaliser du texte à partir d'un input sémantique. Nous avons aussi mentionné que GenDR contenait très peu d'information sur toutes les constructions possibles des verbes, mais imagine si on l'enrichie qu'est-ce que ça pourrait donner.

Dans le troisième chapitre, nous faisons un survol des ressources lexicales potentielles que nous envisageons pour intégrer à GenDR dans le but d'augmenter sa couverture et de lui permettre de réaliser des constructions syntaxiques variées en fonction des verbes. Nous décrivons notamment WordNet, FrameNet, XTAG, LCS, Comlex, Valex,et le VDE et finalement VerbNet, le grand gagnant. Cette ressource lexicale est basée sur les travaux de \cite{verb-classes.levin.1993}. Ce qui nous a le plus attiré de cette ressource est l'organisation des classes verbales ainsi que la large couverture de VerbNet plus de 6000 verbes, désambiguisés.

Dans le quatrième chapitre, nous avons procédé à l'extraction des données lexicales de VerbNet. Nous avons d'abord extrait les informations syntaxiques des classes verbales en conservant la hiérarchie pensée par VerbNet. Puis nous avons extrait les verbes associés à chaque classe verbale et nous les avons désambiguïsés avant de les rajouter à notre dictionnaire. Ensuite, nous avons procédé à la création du dictionnaire de patron de régime à partir des données extraites. Le tout a été fait par l'entremise de Python qui nous a permis de manipuler les fichiers de VerbNet qui sont encodés en XML.

Dans le cinquième chapitre, nous avons démontré comment nous avons adapté GenDR à l'utilisation d'un dictionnaire de patron de régime. Le nombre de verbe décrit par le réalisateur passait de passe de 500 à 6394, puis nous avons complètement changé l'utilisation des patrons de régime avec la venue du dictionnaire de \ac{GP}. Cela a permi à GenDR d'avoir une couverture beaucoup plus large avec les lexèmes et de couvrir une énorme quantité de constructions syntaxiques possibles en anglais. Par le fait même on règle le problème des gps multilpes et on agrandi la couverture de GenDR. 
	
Dans le sixième chapitre, on a d'abord créé les scripts nous permettant de générer les structures de bases pour évaluer GenDR. Le résultat nous donne 978 structures sémantiques dont nous avons manuellement encodé le contenu. 50 ont été choisies aléatoirement pour faire l'évaluation. On a évalué le rappel avec une technique similaire à BLEU. Ensuite on a évalué la précision avec une évaluation humaine classique pour voir si les phrases générées étaient grammaticales et quel était le pourcentage de celle-ci sur le nombre de générées. GenDR performe à 100 pourcent partout rappel et précision. VerbNet nous fait faire des erreurs de précisions (manque de gp, manque d'entrée et GenDR guess fait n'importe quoi, prépositions pour le mm actant, ça donne des phrases incohérentes) VerbNet excellent pour le rappel, mais y'a des incompatibilités sémantiques entre la TST et VerbNet.  

Le travail que nous avons fait apporte plusieurs contributions importantes à la recherche en \ac{GAT}. Nous avons démontré comment s'implémenterait une ressource lexicale comme VerbNet dans un réalisateur profond à base de règles. Nous avons par le fait même démontré qu'avec une ressource comme Python nous pouvons extraire et manipuler les données d'un dictionnaire pour les implémenter dans un réalisateur. Nous avons montré qu'il est possible de prendre une ressource relativement neutre d'un point de vue théorique et d'adapter les données pour une utilisation dans un autre cadre théorique sans que ce ne soit trop encombrant. C'est ainsi que nous avons créé un dictionnaire de patron de régime codé en \emph{Sens-Texte}. Cela pourrait être utile à d'autres réalisateurs qui voudraient s'inspirer de cette théorie. Ou bien pour des systèmes n'utilisant pas les rôles thématiques. Nous avons montré qu'il est possible de doter un réalisateur profond d'une immense couverture grâce à de telles ressources et que leur implémentation donne déjà de bons résultats sans même avoir été modifié. 80\% sans retouches, mais on pourrait l'adapter à nos besoins et aller chercher une meilleure précision. Une autre contribution de cette recherche est que nous avons par le fait même évaluer la capacité d'utiliser VerbNet précisément comme dictionnaire verbal pour un réalisateur profond en GAT. Les avantages et les inconvénients de cette ressource. Notamment, dans 20\% des phrases générées contenait des incongruïtés.

Finalement, ce projet de recherche ouvre la porte à GenDR à se doter d'autres ressources lexicales similaires pour améliorer se couverture. Notamment, nous pourrions implémenter les régimes des noms, grâce aux autres ressources (comme FrameNet \cite{FillmoreBackgroundFramenet2003a}). Nous pourrions aussi aller chercher les gps manquant dans d'autres ressources que nous avons répertoriés. De plus, comme il existe des VerbNet dans d'autres langues (francais, portugais, italien et polonais), on aurait avantage à aller les chercher, ce sera facile vu qu'on a déjà le frame d'importation. Et comme GenDr est multilingue ça vient rejoindre le but. D'ailleurs, une recherche a déjà porté sur l'exportation des classes de VN à d'autres langues et il semble que les résultats sont positifs et que c'est un système qui peut très bien s'appliquer à des langues autres qu'à l'anglais \citep{Majewska2017}, preuve :

